{'start_training__RL': {'training_type': 'RL', 'algorithm_name': 'TD3_INTER', 'save_every': 1, 'max_epochs': 1, 'additional_algorithm_kwargs': {'run_name': 'test', 'run_id': 0, 'checkpoint_every': 10, 'device1': 'cuda:0', 'device2': 'cuda:1', 'discount': 0.95, 'tau': 0.2, 'noise': 0.3, 'exp_decay_const': 0.2, 'logger_name': 'WandbLogger'}}}
>>> =================Epoch 1=================
Run No. 1
Episode Length = 94
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1266,  1.1195,  1.1216,  1.1285,  1.1301,  1.1297,  1.1278,  1.1335,
         1.1273,  1.1291,  1.1159,  1.1327,  1.1302,  1.1295,  1.1233,  1.1232,
         1.1207,  1.1242,  1.1309,  1.1345,  1.1271,  1.1237,  1.1265,  1.1163,
         1.1315,  1.1353,  1.1366,  1.1339,  1.1370,  1.1330,  1.1315,  1.1360,
         1.1323,  1.1302,  1.1329,  1.1325,  1.1332,  1.1313,  1.1301,  1.1186,
         1.1173,  1.1228,  1.1229, -5.0000,  0.0000,  0.0000,  0.0000,  0.1279,
         1.1260,  1.1266,  1.1331,  1.0000], device='cuda:0')
target_q_episode tensor([17.2454, 17.1004, 16.9478, 16.7872, 16.6181, 16.4401, 16.2527, 16.0555,
        15.8479, 15.6294, 15.3994, 15.1572, 14.9023, 14.6340, 14.3516, 14.0543,
        13.7414, 13.4120, 13.0653, 12.7003, 12.3161, 11.9117, 11.4860, 11.0379,
        10.5662, 10.0696,  9.5470,  8.9968,  8.4177,  7.8081,  7.1664,  6.4910,
         5.7800,  5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555, -0.3627,
        -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([17.2454, 17.1004, 16.9478, 16.7872, 16.6181, 16.4401, 16.2527, 16.0555,
        15.8479, 15.6294, 15.3994, 15.1572, 14.9023, 14.6340, 14.3516, 14.0543,
        13.7414, 13.4120, 13.0653, 12.7003, 12.3161, 11.9117, 11.4860, 11.0379,
        10.5662, 10.0696,  9.5470,  8.9968,  8.4177,  7.8081,  7.1664,  6.4910,
         5.7800,  5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555, -0.3627,
        -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 0.0839, -0.3268,  0.0040],
        [ 0.0778, -0.2862,  0.0073],
        [ 0.0882, -0.2948,  0.0041],
        [ 0.0839, -0.2834,  0.0121],
        [ 0.0885, -0.3298,  0.0055],
        [ 0.0878, -0.3115,  0.0059],
        [ 0.0873, -0.3056,  0.0065],
        [ 0.0833, -0.2851,  0.0095],
        [ 0.0728, -0.2319,  0.0909],
        [ 0.0596, -0.1929,  0.1479],
        [ 0.0650, -0.2338,  0.0705],
        [ 0.0665, -0.1882,  0.0725],
        [ 0.0760, -0.2412,  0.0267],
        [ 0.0672, -0.2196,  0.0471],
        [ 0.0761, -0.2503,  0.0218],
        [ 0.0861, -0.3042,  0.0048],
        [ 0.0802, -0.2238,  0.0297],
        [ 0.0891, -0.3270,  0.0067],
        [ 0.0882, -0.3195,  0.0081],
        [ 0.0893, -0.3256,  0.0080],
        [ 0.0892, -0.3344,  0.0055],
        [ 0.0897, -0.3340,  0.0051],
        [ 0.0873, -0.3292,  0.0122],
        [ 0.0837, -0.2713,  0.0416],
        [ 0.0835, -0.3029,  0.0137],
        [ 0.0890, -0.3301,  0.0099],
        [ 0.0871, -0.3284,  0.0098],
        [ 0.0899, -0.3369,  0.0070],
        [ 0.0862, -0.3204,  0.0272],
        [ 0.0873, -0.3589,  0.0131],
        [ 0.0917, -0.3626,  0.0081],
        [ 0.0852, -0.2897,  0.0397],
        [ 0.0919, -0.3673,  0.0082],
        [ 0.0942, -0.3853,  0.0045],
        [ 0.0951, -0.3880,  0.0036],
        [ 0.0975, -0.3959,  0.0008],
        [ 0.0957, -0.3936,  0.0027],
        [ 0.0969, -0.3856,  0.0030],
        [ 0.0942, -0.3752,  0.0052],
        [ 0.0935, -0.3679,  0.0077],
        [ 0.0840, -0.3283,  0.0460],
        [ 0.0676, -0.2255,  0.2634],
        [ 0.0725, -0.2760,  0.0162],
        [ 0.0758, -0.2372,  0.0149],
        [ 0.0804, -0.3222,  0.0079],
        [ 0.0794, -0.2613,  0.0152],
        [ 0.0845, -0.3423,  0.0040],
        [ 0.0825, -0.3047,  0.0067],
        [ 0.0818, -0.3131,  0.0059],
        [ 0.0816, -0.3103,  0.0080],
        [ 0.0862, -0.3497,  0.0050],
        [ 0.0762, -0.2662,  0.0292],
        [ 0.0791, -0.2491,  0.0200],
        [ 0.0821, -0.2946,  0.0145],
        [ 0.0819, -0.3155,  0.0103],
        [ 0.0861, -0.3391,  0.0061],
        [ 0.0845, -0.3326,  0.0081],
        [ 0.0748, -0.2808,  0.0298],
        [ 0.0823, -0.2326,  0.0366],
        [ 0.0782, -0.1782,  0.0426],
        [ 0.0839, -0.1816,  0.0258],
        [ 0.0853, -0.1348,  0.0185],
        [ 0.0828, -0.2538,  0.0227],
        [ 0.0901, -0.3552,  0.0030],
        [ 0.0859, -0.3075,  0.0124],
        [ 0.0799, -0.2592,  0.0510],
        [ 0.0773, -0.1474,  0.0309],
        [ 0.0883, -0.2389,  0.0187],
        [ 0.0831, -0.2685,  0.0266],
        [ 0.0740, -0.2647,  0.0672],
        [ 0.0765, -0.2644,  0.0507],
        [ 0.0784, -0.2628,  0.0541],
        [ 0.0882, -0.3363,  0.0093],
        [ 0.0831, -0.3281,  0.0232],
        [ 0.0851, -0.3599,  0.0134],
        [ 0.0860, -0.3415,  0.0083],
        [ 0.0836, -0.2622,  0.0590],
        [ 0.0831, -0.3429,  0.0242],
        [ 0.0915, -0.3564,  0.0133],
        [ 0.0933, -0.3907,  0.0052],
        [ 0.0961, -0.3912,  0.0029],
        [ 0.0921, -0.3698,  0.0093],
        [ 0.0886, -0.3487,  0.0140],
        [ 0.0943, -0.3858,  0.0092],
        [ 0.0932, -0.3915,  0.0053],
        [ 0.0963, -0.3969,  0.0017],
        [ 0.0959, -0.3980,  0.0020],
        [ 0.0976, -0.3833,  0.0062],
        [ 0.0950, -0.3882,  0.0184],
        [ 0.0952, -0.3887,  0.0146],
        [ 0.0905, -0.3599,  0.0260],
        [ 0.0844, -0.3557,  0.0538],
        [ 0.0795, -0.3460,  0.0512],
        [ 0.0756, -0.3346,  0.1229]], device='cuda:0', grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 2
Episode Length = 81
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1320,  1.1362,  1.1264,  1.1251,  1.1306,  1.1359,  1.1306,  1.1302,
         1.1259,  1.1259,  1.1258, -5.0000,  0.0000,  0.0000,  0.0000,  0.1332,
         1.1272,  1.1332,  1.1313,  1.1286,  1.1279,  1.1291,  1.1344,  1.1401,
         1.1406,  1.1378,  1.1359,  1.1271, -7.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1413,  1.1388,  1.1433,  1.1351,  1.1360,  1.1321,
         1.1361,  1.1373,  1.0000], device='cuda:0')
target_q_episode tensor([ 5.7800,  5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555, -0.3627,
        -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         5.4103,  4.6424,  3.8341,  2.9833,  2.0876,  1.1449,  0.1525, -0.8921,
        -1.9917, -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,
         2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 4.9375,  4.3255,  3.6787,  2.9995,  2.2858,  1.5345,  0.7416, -0.0921,
        -0.9703, -1.8939, -2.8662, -5.0000,  0.0000,  0.0000,  0.0000,  0.0242,
         4.6339,  4.0063,  3.3442,  2.6471,  1.9137,  1.1420,  0.3305, -0.5237,
        -1.4239, -2.3720, -3.3699, -4.4215, -7.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0256,  5.7178,  5.1469,  4.5435,  3.9102,  3.2426,
         2.5414,  1.8027,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.2901e-02, -3.6030e-01,  2.3951e-03],
        [ 9.3561e-02, -3.6479e-01,  2.0955e-03],
        [ 9.3469e-02, -3.6373e-01,  2.9391e-03],
        [ 9.7236e-02, -3.9094e-01,  3.2514e-04],
        [ 9.6516e-02, -3.8906e-01,  6.9183e-04],
        [ 9.5982e-02, -3.8688e-01,  7.4416e-04],
        [ 9.6703e-02, -3.8476e-01,  4.7556e-04],
        [ 9.6622e-02, -3.8472e-01,  7.6643e-04],
        [ 9.7552e-02, -3.8975e-01,  3.5003e-04],
        [ 9.5050e-02, -3.8178e-01,  1.5700e-03],
        [ 9.6796e-02, -3.8593e-01,  9.1034e-04],
        [ 9.7279e-02, -3.8701e-01,  6.5938e-04],
        [ 9.8053e-02, -3.9053e-01,  2.3255e-04],
        [ 9.7631e-02, -3.9111e-01,  4.1172e-04],
        [ 9.7752e-02, -3.9025e-01,  3.0237e-04],
        [ 9.8655e-02, -3.9330e-01,  1.2708e-04],
        [ 9.8315e-02, -3.9246e-01,  2.8038e-04],
        [ 9.8382e-02, -3.8954e-01,  3.8615e-04],
        [ 9.8592e-02, -3.9338e-01,  2.1291e-04],
        [ 9.7277e-02, -3.8928e-01,  7.8022e-04],
        [ 9.7309e-02, -3.8455e-01,  1.6172e-03],
        [ 9.7849e-02, -3.9488e-01,  7.9483e-04],
        [ 9.7582e-02, -3.9230e-01,  1.0081e-03],
        [ 9.7772e-02, -3.8854e-01,  1.4530e-03],
        [ 9.5769e-02, -3.8846e-01,  2.4111e-03],
        [ 9.3197e-02, -3.7146e-01,  1.1949e-02],
        [ 8.8939e-02, -3.5615e-01,  3.1410e-02],
        [ 8.9885e-02, -3.5285e-01,  3.1373e-02],
        [ 9.2006e-02, -3.8086e-01,  1.1456e-02],
        [ 9.4089e-02, -3.7964e-01,  8.3725e-03],
        [ 9.4612e-02, -3.7665e-01,  8.1961e-03],
        [ 8.5129e-02, -3.6341e-01,  5.1589e-02],
        [ 9.3041e-02, -3.7572e-01,  2.3673e-02],
        [ 7.3878e-02, -2.7118e-01,  3.2590e-01],
        [ 6.2614e-02, -2.2966e-01,  4.9886e-01],
        [ 5.6666e-02, -2.3977e-01,  4.9152e-01],
        [ 5.6581e-02, -2.4398e-01,  5.0620e-01],
        [ 4.8573e-02, -2.2526e-01,  5.8938e-01],
        [ 9.2495e-02, -3.7490e-01,  1.3946e-03],
        [ 9.3790e-02, -3.8105e-01,  1.4095e-03],
        [ 8.7103e-02, -3.2692e-01,  1.0524e-02],
        [ 9.1433e-02, -3.4541e-01,  4.1419e-03],
        [ 9.6617e-02, -3.8870e-01,  7.4002e-04],
        [ 9.2073e-02, -3.8630e-01,  4.3093e-03],
        [ 9.4013e-02, -3.8043e-01,  3.3249e-03],
        [ 9.6559e-02, -3.8910e-01,  4.1145e-04],
        [ 9.7089e-02, -3.9068e-01,  4.5648e-04],
        [ 9.6081e-02, -3.8992e-01,  1.5100e-03],
        [ 9.1936e-02, -3.8060e-01,  3.9996e-03],
        [ 9.2620e-02, -3.8520e-01,  6.7520e-03],
        [ 9.0978e-02, -3.8445e-01,  7.8456e-03],
        [ 9.6571e-02, -3.8935e-01,  1.6545e-03],
        [ 9.5434e-02, -3.5835e-01,  2.4032e-03],
        [ 9.2657e-02, -3.4511e-01,  1.0006e-02],
        [ 9.3346e-02, -3.3214e-01,  1.7867e-02],
        [ 9.4774e-02, -3.5525e-01,  4.6082e-03],
        [ 9.7226e-02, -3.8428e-01,  8.5574e-04],
        [ 9.8518e-02, -3.9103e-01,  1.8787e-04],
        [ 9.5802e-02, -3.8636e-01,  2.5657e-03],
        [ 8.8152e-02, -3.6182e-01,  3.3614e-02],
        [ 9.1089e-02, -3.7905e-01,  1.1807e-02],
        [ 9.2386e-02, -3.7675e-01,  1.0604e-02],
        [ 9.2064e-02, -3.7650e-01,  7.2347e-03],
        [ 9.1854e-02, -3.5385e-01,  8.7834e-03],
        [ 8.7667e-02, -3.4712e-01,  2.6162e-02],
        [ 8.7967e-02, -3.7568e-01,  2.0304e-02],
        [ 9.2180e-02, -3.8588e-01,  1.1633e-02],
        [ 8.6162e-02, -3.2611e-01,  3.0974e-02],
        [ 9.0620e-02, -3.4414e-01,  3.2931e-02],
        [ 9.2348e-02, -3.5446e-01,  1.6694e-02],
        [ 9.6349e-02, -3.9604e-01,  4.5473e-03],
        [ 9.5133e-02, -3.9364e-01,  1.4824e-02],
        [ 9.1942e-02, -3.8477e-01,  2.3082e-02],
        [ 9.5801e-02, -3.9328e-01,  5.0861e-03],
        [ 9.0731e-02, -3.8882e-01,  1.1844e-02],
        [ 8.7485e-02, -3.7640e-01,  2.4408e-02],
        [ 8.8895e-02, -3.8991e-01,  3.8262e-02],
        [ 8.5072e-02, -3.7497e-01,  5.1645e-02],
        [ 8.9321e-02, -3.7863e-01,  4.2668e-02],
        [ 8.0645e-02, -3.4270e-01,  1.0859e-01],
        [ 6.7541e-02, -3.0184e-01,  2.6303e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 3
Episode Length = 100
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1293,  1.1363,  1.1329,  1.1389,  1.1345,  1.1372,  1.1347,  1.1350,
         1.1366,  1.1320,  1.1299,  1.1350,  1.1294,  1.1328,  1.1288,  1.1222,
         1.1262,  1.1342,  1.1330,  1.1270,  1.1335,  1.1394,  1.1352,  1.1352,
         1.1364,  1.1345,  1.1277,  1.1306, -8.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1330,  1.1333,  1.1324,  1.1313,  1.1299,
         1.1255,  1.1264, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1248,
         1.1251,  1.1295,  1.1358,  1.1396,  1.1394,  1.1324,  1.1320,  1.1342,
         1.1304,  1.0000], device='cuda:0')
target_q_episode tensor([13.3408, 12.9904, 12.6214, 12.2331, 11.8243, 11.3940, 10.9411, 10.4643,
         9.9624,  9.4341,  8.8780,  8.2926,  7.6765,  7.0278,  6.3451,  5.6264,
         4.8699,  4.0736,  3.2354,  2.3530,  1.4242,  0.4466, -0.5826, -1.6659,
        -2.8062, -4.0065, -5.2700, -6.6000, -8.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.8876, -0.1183, -1.1772, -2.2917,
        -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,  2.8525,
         1.9500,  1.0000], device='cuda:0')
target_q tensor([ 9.3150,  9.0823,  8.8339,  8.5755,  8.3001,  8.0125,  7.7081,  7.3886,
         7.0527,  6.6971,  6.3236,  5.9329,  5.5180,  5.0844,  4.6254,  4.1415,
         3.6357,  3.1046,  2.5423,  1.9488,  1.3284,  0.6750, -0.0163, -0.7424,
        -1.5064, -2.3116, -3.1608, -4.0514, -8.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0439,  0.9686,  0.2940, -0.4161, -1.1637,
        -1.9516, -2.7792, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0411,
         5.7504,  5.3294,  4.8868,  4.4199,  3.9271,  3.4061,  2.8600,  2.2860,
         1.6798,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 0.0464, -0.2303,  0.1385],
        [ 0.0420, -0.1814,  0.1676],
        [ 0.0847, -0.3650,  0.0089],
        [ 0.0831, -0.3525,  0.0120],
        [ 0.0889, -0.3742,  0.0056],
        [ 0.0641, -0.2593,  0.1022],
        [ 0.0589, -0.2320,  0.0930],
        [ 0.0760, -0.2797,  0.0382],
        [ 0.0795, -0.3201,  0.0294],
        [ 0.0786, -0.3028,  0.0320],
        [ 0.0833, -0.3251,  0.0229],
        [ 0.0812, -0.3248,  0.0253],
        [ 0.0781, -0.3156,  0.0547],
        [ 0.0851, -0.3343,  0.0099],
        [ 0.0833, -0.3310,  0.0126],
        [ 0.0854, -0.3404,  0.0121],
        [ 0.0886, -0.3614,  0.0098],
        [ 0.0873, -0.3518,  0.0126],
        [ 0.0931, -0.3790,  0.0052],
        [ 0.0909, -0.3522,  0.0089],
        [ 0.0920, -0.3695,  0.0062],
        [ 0.0894, -0.3684,  0.0106],
        [ 0.0914, -0.3758,  0.0054],
        [ 0.0898, -0.3687,  0.0090],
        [ 0.0917, -0.3760,  0.0093],
        [ 0.0890, -0.3625,  0.0143],
        [ 0.0832, -0.3492,  0.0350],
        [ 0.0842, -0.3359,  0.0487],
        [ 0.0797, -0.3392,  0.0589],
        [ 0.0817, -0.3207,  0.0527],
        [ 0.0854, -0.3434,  0.0383],
        [ 0.0883, -0.3527,  0.0223],
        [ 0.0901, -0.3681,  0.0189],
        [ 0.0874, -0.3416,  0.0463],
        [ 0.0871, -0.3580,  0.0447],
        [ 0.0821, -0.3311,  0.1137],
        [ 0.0839, -0.3511,  0.0969],
        [ 0.0795, -0.2864,  0.1364],
        [ 0.0756, -0.2995,  0.1969],
        [ 0.0680, -0.2540,  0.3325],
        [ 0.0683, -0.2945,  0.2686],
        [ 0.0665, -0.2755,  0.2713],
        [ 0.0586, -0.2631,  0.0968],
        [ 0.0263, -0.0965,  0.3316],
        [ 0.0352, -0.1255,  0.2304],
        [ 0.0485, -0.2037,  0.1257],
        [ 0.0546, -0.2227,  0.0918],
        [ 0.0413, -0.0940,  0.2410],
        [ 0.0419, -0.1725,  0.2108],
        [ 0.0424, -0.1565,  0.2468],
        [ 0.0408, -0.1458,  0.2764],
        [ 0.0427, -0.1584,  0.1804],
        [ 0.0727, -0.2981,  0.0273],
        [ 0.0741, -0.2989,  0.0391],
        [ 0.0756, -0.2736,  0.0416],
        [ 0.0791, -0.2931,  0.0276],
        [ 0.0826, -0.3048,  0.0259],
        [ 0.0811, -0.2819,  0.0244],
        [ 0.0871, -0.3398,  0.0215],
        [ 0.0878, -0.3865,  0.0099],
        [ 0.0933, -0.3933,  0.0044],
        [ 0.0923, -0.3886,  0.0099],
        [ 0.0912, -0.3897,  0.0054],
        [ 0.0906, -0.3917,  0.0045],
        [ 0.0907, -0.3734,  0.0185],
        [ 0.0913, -0.2927,  0.0099],
        [ 0.0841, -0.3020,  0.0189],
        [ 0.0863, -0.2844,  0.0199],
        [ 0.0838, -0.2646,  0.0410],
        [ 0.0882, -0.2780,  0.0157],
        [ 0.0821, -0.2522,  0.0312],
        [ 0.0855, -0.2410,  0.0432],
        [ 0.0783, -0.1883,  0.0665],
        [ 0.0898, -0.1235,  0.0191],
        [ 0.0932, -0.2037,  0.0139],
        [ 0.0917, -0.1302,  0.0144],
        [ 0.0931, -0.1747,  0.0132],
        [ 0.0954, -0.1899,  0.0085],
        [ 0.0935, -0.2254,  0.0131],
        [ 0.0863, -0.2292,  0.0418],
        [ 0.0900, -0.3034,  0.0298],
        [ 0.0896, -0.3095,  0.0266],
        [ 0.0924, -0.3062,  0.0139],
        [ 0.0834, -0.3232,  0.0444],
        [ 0.0909, -0.3722,  0.0336],
        [ 0.0948, -0.3866,  0.0179],
        [ 0.0921, -0.3797,  0.0374],
        [ 0.0935, -0.3864,  0.0204],
        [ 0.0840, -0.2796,  0.0480],
        [ 0.0802, -0.2406,  0.0841],
        [ 0.0864, -0.3103,  0.0341],
        [ 0.0805, -0.3375,  0.0914],
        [ 0.0858, -0.3720,  0.0330],
        [ 0.0859, -0.3636,  0.0369],
        [ 0.0833, -0.3499,  0.1020],
        [ 0.0798, -0.3715,  0.0785],
        [ 0.0724, -0.3462,  0.1084],
        [ 0.0744, -0.3333,  0.1473],
        [ 0.0783, -0.3349,  0.1704],
        [ 0.0718, -0.3214,  0.1709]], device='cuda:0', grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 4
Episode Length = 81
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([1.1419, 1.1440, 1.1490, 1.1470, 1.1304, 1.1355, 1.1340, 1.1361, 1.1392,
        1.1428, 1.1394, 1.1368, 1.1360, 1.1417, 1.1393, 1.1456, 1.1455, 1.1429,
        1.1419, 1.1424, 1.1408, 1.1386, 1.1390, 1.1392, 1.1432, 1.1456, 1.1473,
        1.1479, 1.1387, 1.1477, 1.1400, 1.1500, 1.1468, 1.1440, 1.1475, 1.1499,
        1.1418, 1.1448, 1.1412, 1.1395, 1.1415, 1.1446, 1.0000],
       device='cuda:0')
target_q_episode tensor([17.7963, 17.6804, 17.5583, 17.4298, 17.2945, 17.1521, 17.0022, 16.8444,
        16.6783, 16.5035, 16.3195, 16.1258, 15.9219, 15.7072, 15.4813, 15.2435,
        14.9931, 14.7296, 14.4522, 14.1602, 13.8529, 13.5293, 13.1888, 12.8303,
        12.4529, 12.0557, 11.6376, 11.1975, 10.7342, 10.2465,  9.7332,  9.1928,
         8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,
         2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([10.2820, 10.2193, 10.1546, 10.0832, 10.0014,  9.9256,  9.8426,  9.7570,
         9.6673,  9.5729,  9.4704,  9.3629,  9.2506,  9.1354,  9.0104,  8.8827,
         8.7452,  8.5994,  8.4468,  8.2867,  8.1173,  7.9388,  7.7521,  7.5554,
         7.3501,  7.1332,  6.9045,  6.6632,  6.4048,  6.1412,  5.8560,  5.5640,
         5.2504,  4.9205,  4.5762,  4.2132,  3.8263,  3.4242,  2.9979,  2.5502,
         2.0805,  1.5866,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.3434e-02, -3.6605e-01,  2.9919e-03],
        [ 9.4548e-02, -3.7803e-01,  1.6429e-03],
        [ 9.4514e-02, -3.7340e-01,  3.4331e-03],
        [ 9.5333e-02, -3.9019e-01,  1.0727e-03],
        [ 9.5784e-02, -3.9168e-01,  1.2929e-03],
        [ 9.6035e-02, -3.8811e-01,  8.7795e-04],
        [ 9.7892e-02, -3.9409e-01,  3.0303e-04],
        [ 9.5872e-02, -3.8953e-01,  1.6306e-03],
        [ 9.6345e-02, -3.9289e-01,  1.1707e-03],
        [ 9.5481e-02, -3.8798e-01,  1.1454e-03],
        [ 9.7527e-02, -3.8815e-01,  5.8424e-04],
        [ 9.8071e-02, -3.9300e-01,  3.9798e-04],
        [ 9.7607e-02, -3.9288e-01,  4.8536e-04],
        [ 9.7416e-02, -3.9226e-01,  7.0998e-04],
        [ 9.7568e-02, -3.9252e-01,  6.2063e-04],
        [ 9.8291e-02, -3.9295e-01,  3.6260e-04],
        [ 9.8926e-02, -3.9573e-01,  1.7655e-04],
        [ 9.7933e-02, -3.9064e-01,  9.0033e-04],
        [ 9.8060e-02, -3.9018e-01,  8.1381e-04],
        [ 9.7416e-02, -3.8744e-01,  1.2362e-03],
        [ 9.7499e-02, -3.9289e-01,  1.2572e-03],
        [ 9.7505e-02, -3.9357e-01,  9.8419e-04],
        [ 9.7513e-02, -3.9007e-01,  1.1467e-03],
        [ 9.6820e-02, -3.9109e-01,  2.3990e-03],
        [ 9.7009e-02, -3.9181e-01,  1.9013e-03],
        [ 9.2255e-02, -3.7447e-01,  1.8401e-02],
        [ 8.9982e-02, -3.6508e-01,  3.6745e-02],
        [ 8.2631e-02, -3.0918e-01,  9.2896e-02],
        [ 8.8469e-02, -3.5924e-01,  5.4208e-02],
        [ 9.3001e-02, -3.8160e-01,  1.0194e-02],
        [ 8.9489e-02, -3.5983e-01,  2.5567e-02],
        [ 8.2031e-02, -3.6754e-01,  3.8942e-02],
        [ 9.1497e-02, -3.7561e-01,  2.7609e-02],
        [ 6.9198e-02, -2.8391e-01,  3.0780e-01],
        [ 6.1526e-02, -2.5414e-01,  4.4259e-01],
        [ 5.3983e-02, -2.2955e-01,  4.7488e-01],
        [ 5.1706e-02, -2.2233e-01,  5.2147e-01],
        [ 4.8723e-02, -2.3564e-01,  5.6351e-01],
        [ 9.1563e-02, -3.5287e-01,  4.7799e-03],
        [ 9.0481e-02, -3.5100e-01,  5.7995e-03],
        [ 9.3285e-02, -3.6825e-01,  3.8123e-03],
        [ 8.1425e-02, -2.9703e-01,  3.5825e-02],
        [ 7.8262e-02, -3.3263e-01,  4.8459e-02],
        [ 7.1039e-02, -2.8829e-01,  7.4796e-02],
        [ 8.7998e-02, -3.1218e-01,  1.8034e-02],
        [ 9.5678e-02, -3.8364e-01,  1.0289e-03],
        [ 8.9926e-02, -3.7717e-01,  1.4641e-02],
        [ 9.5226e-02, -3.8500e-01,  4.2244e-03],
        [ 9.7146e-02, -3.9340e-01,  6.9976e-04],
        [ 9.6791e-02, -3.8784e-01,  1.1175e-03],
        [ 9.5419e-02, -3.8250e-01,  1.6843e-03],
        [ 9.4762e-02, -3.8822e-01,  2.6644e-03],
        [ 9.7264e-02, -3.9534e-01,  7.7224e-04],
        [ 9.7023e-02, -3.9176e-01,  1.0199e-03],
        [ 9.8201e-02, -3.9272e-01,  5.5069e-04],
        [ 9.3894e-02, -3.6474e-01,  6.8036e-03],
        [ 9.3941e-02, -3.4074e-01,  1.7135e-02],
        [ 9.3349e-02, -3.5597e-01,  9.7092e-03],
        [ 9.2552e-02, -3.6053e-01,  7.3948e-03],
        [ 9.7856e-02, -3.8827e-01,  5.4771e-04],
        [ 9.8514e-02, -3.9363e-01,  2.5788e-04],
        [ 9.5015e-02, -3.8806e-01,  4.9422e-03],
        [ 9.5153e-02, -3.8662e-01,  5.6495e-03],
        [ 9.4380e-02, -3.7958e-01,  1.0068e-02],
        [ 9.6725e-02, -3.9032e-01,  1.9191e-03],
        [ 9.3674e-02, -3.7168e-01,  9.2285e-03],
        [ 8.7516e-02, -3.6148e-01,  3.5939e-02],
        [ 8.5475e-02, -3.4681e-01,  2.9047e-02],
        [ 8.8601e-02, -3.6580e-01,  3.1505e-02],
        [ 9.2454e-02, -3.7807e-01,  2.2708e-02],
        [ 8.8587e-02, -3.8612e-01,  1.9216e-02],
        [ 8.8275e-02, -3.8130e-01,  2.5089e-02],
        [ 9.5448e-02, -3.9762e-01,  4.4493e-03],
        [ 9.0328e-02, -3.7832e-01,  2.3634e-02],
        [ 8.8872e-02, -3.8231e-01,  2.3401e-02],
        [ 8.9924e-02, -3.7373e-01,  4.3410e-02],
        [ 8.2321e-02, -3.5961e-01,  8.4809e-02],
        [ 8.5163e-02, -3.8490e-01,  5.5805e-02],
        [ 8.7411e-02, -3.8435e-01,  5.1602e-02],
        [ 7.5755e-02, -3.4383e-01,  1.0051e-01],
        [ 5.9486e-02, -2.4232e-01,  4.8824e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 5
Episode Length = 92
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1443,  1.1431,  1.1530,  1.1521,  1.1453,  1.1396,  1.1403,  1.1478,
         1.1553,  1.1537,  1.1476,  1.1327, -3.0000,  0.0000,  0.1423,  1.1433,
         1.1437,  1.1418,  1.1422,  1.1377,  1.1434,  1.1527,  1.1575,  1.1458,
         1.1478,  1.1471,  1.1546,  1.1510,  1.1474,  1.1525,  1.1451,  1.1474,
         1.1502,  1.1528,  1.1507,  1.1410, -4.0000,  0.0000,  0.0000,  0.1426,
         1.1429,  1.1473,  1.1271, -3.0000,  0.0000,  0.1366,  1.1461,  1.1437,
         1.1453,  1.0000], device='cuda:0')
target_q_episode tensor([ 7.5717,  6.9176,  6.2291,  5.5043,  4.7413,  3.9382,  3.0929,  2.2030,
         1.2664,  0.2804, -0.7575, -1.8500, -3.0000,  0.0000,  0.0000, 11.8265,
        11.3963, 10.9435, 10.4669,  9.9651,  9.4370,  8.8810,  8.2958,  7.6798,
         7.0314,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,  2.3578,  1.4293,
         0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,
         0.2804, -0.7575, -1.8500, -3.0000,  0.0000,  0.0000,  3.7099,  2.8525,
         1.9500,  1.0000], device='cuda:0')
target_q tensor([ 4.0323,  3.7377,  3.4338,  3.1077,  2.7611,  2.3971,  2.0177,  1.6219,
         1.2052,  0.7613,  0.2916, -0.2075, -3.0000,  0.0000,  0.0784,  5.9436,
         5.7505,  5.5460,  5.3321,  5.1041,  4.8700,  4.6253,  4.3650,  4.0817,
         3.7915,  3.4843,  3.1657,  2.8239,  2.4642,  2.0904,  1.6900,  1.2740,
         0.8364,  0.3756, -0.1123, -0.6298, -4.0000,  0.0000,  0.0000,  0.0786,
         0.7553,  0.2914, -0.2106, -3.0000,  0.0000,  0.0752,  2.2981,  1.9115,
         1.5069,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 0.0754, -0.2925,  0.0150],
        [ 0.0804, -0.3284,  0.0105],
        [ 0.0806, -0.2982,  0.0174],
        [ 0.0814, -0.3173,  0.0174],
        [ 0.0873, -0.3604,  0.0086],
        [ 0.0863, -0.3319,  0.0117],
        [ 0.0822, -0.3114,  0.0237],
        [ 0.0777, -0.3033,  0.0318],
        [ 0.0576, -0.1933,  0.1612],
        [ 0.0545, -0.1926,  0.2174],
        [ 0.0618, -0.2445,  0.0941],
        [ 0.0636, -0.2412,  0.0765],
        [ 0.0660, -0.2024,  0.0736],
        [ 0.0715, -0.2401,  0.0379],
        [ 0.0758, -0.2587,  0.0229],
        [ 0.0757, -0.2620,  0.0230],
        [ 0.0811, -0.2671,  0.0236],
        [ 0.0778, -0.2876,  0.0337],
        [ 0.0887, -0.3426,  0.0076],
        [ 0.0857, -0.3319,  0.0126],
        [ 0.0892, -0.3418,  0.0080],
        [ 0.0892, -0.3501,  0.0092],
        [ 0.0894, -0.3669,  0.0088],
        [ 0.0894, -0.3420,  0.0283],
        [ 0.0860, -0.3561,  0.0172],
        [ 0.0850, -0.3455,  0.0203],
        [ 0.0876, -0.3540,  0.0114],
        [ 0.0899, -0.3342,  0.0142],
        [ 0.0874, -0.3496,  0.0227],
        [ 0.0900, -0.3836,  0.0105],
        [ 0.0839, -0.3397,  0.0450],
        [ 0.0781, -0.3086,  0.0563],
        [ 0.0862, -0.3679,  0.0337],
        [ 0.0970, -0.3971,  0.0019],
        [ 0.0957, -0.3956,  0.0055],
        [ 0.0971, -0.3980,  0.0025],
        [ 0.0960, -0.3955,  0.0039],
        [ 0.0973, -0.3951,  0.0029],
        [ 0.0936, -0.3828,  0.0072],
        [ 0.0909, -0.3832,  0.0161],
        [ 0.0756, -0.3263,  0.1410],
        [ 0.0664, -0.2668,  0.2999],
        [ 0.0327, -0.0586,  0.2844],
        [ 0.0363, -0.1104,  0.2169],
        [ 0.0684, -0.2839,  0.0441],
        [ 0.0532, -0.1820,  0.0913],
        [ 0.0371, -0.1233,  0.2813],
        [ 0.0503, -0.1789,  0.1477],
        [ 0.0656, -0.2625,  0.0346],
        [ 0.0694, -0.3066,  0.0488],
        [ 0.0741, -0.2738,  0.0307],
        [ 0.0413, -0.1257,  0.2496],
        [ 0.0701, -0.3144,  0.0496],
        [ 0.0775, -0.2941,  0.0226],
        [ 0.0853, -0.3443,  0.0192],
        [ 0.0777, -0.2800,  0.0203],
        [ 0.0738, -0.2994,  0.0472],
        [ 0.0803, -0.2644,  0.0362],
        [ 0.0774, -0.1987,  0.0415],
        [ 0.0814, -0.2249,  0.0219],
        [ 0.0784, -0.2276,  0.0380],
        [ 0.0802, -0.1353,  0.0392],
        [ 0.0795, -0.1691,  0.0406],
        [ 0.0826, -0.3009,  0.0293],
        [ 0.0770, -0.1610,  0.0726],
        [ 0.0863, -0.3499,  0.0086],
        [ 0.0854, -0.2743,  0.0214],
        [ 0.0841, -0.3141,  0.0308],
        [ 0.0776, -0.2958,  0.0813],
        [ 0.0738, -0.3003,  0.0765],
        [ 0.0883, -0.3766,  0.0165],
        [ 0.0744, -0.2931,  0.0846],
        [ 0.0720, -0.2579,  0.0684],
        [ 0.0876, -0.3630,  0.0174],
        [ 0.0834, -0.3498,  0.0371],
        [ 0.0907, -0.3768,  0.0160],
        [ 0.0880, -0.3750,  0.0272],
        [ 0.0909, -0.3896,  0.0161],
        [ 0.0895, -0.3799,  0.0265],
        [ 0.0779, -0.2665,  0.0679],
        [ 0.0817, -0.3162,  0.0652],
        [ 0.0979, -0.3983,  0.0023],
        [ 0.0946, -0.3934,  0.0062],
        [ 0.0925, -0.3871,  0.0148],
        [ 0.0783, -0.3554,  0.1102],
        [ 0.0847, -0.3750,  0.0595],
        [ 0.0888, -0.3874,  0.0356],
        [ 0.0885, -0.3670,  0.0442],
        [ 0.0834, -0.3434,  0.0886],
        [ 0.0753, -0.3111,  0.1904],
        [ 0.0790, -0.3372,  0.0849],
        [ 0.0668, -0.3034,  0.2251]], device='cuda:0', grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 6
Episode Length = 82
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1654,  1.1654,  1.1450,  1.1570,  1.1553,  1.1577,  1.1624,  1.1673,
         1.1731,  1.1669,  1.1649,  1.1614,  1.1609,  1.1613,  1.1608,  1.1651,
         1.1635,  1.1635,  1.1614,  1.1613,  1.1648,  1.1576,  1.1560,  1.1583,
         1.1605,  1.1609,  1.1666,  1.1676,  1.1621,  1.1592,  1.1595,  1.1490,
         1.1646,  1.1612,  1.1649,  1.1699,  1.1708,  1.1598,  1.1481, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([16.6181, 16.4401, 16.2527, 16.0555, 15.8479, 15.6294, 15.3994, 15.1572,
        14.9023, 14.6340, 14.3516, 14.0543, 13.7414, 13.4120, 13.0653, 12.7003,
        12.3161, 11.9117, 11.4860, 11.0379, 10.5662, 10.0696,  9.5470,  8.9968,
         8.4177,  7.8081,  7.1664,  6.4910,  5.7800,  5.0316,  4.2438,  3.4145,
         2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 6.8501,  6.7847,  6.7028,  6.6379,  6.5604,  6.4815,  6.3999,  6.3139,
         6.2238,  6.1212,  6.0160,  5.9044,  5.7890,  5.6681,  5.5402,  5.4086,
         5.2663,  5.1175,  4.9596,  4.7947,  4.6234,  4.4362,  4.2429,  4.0419,
         3.8303,  3.6063,  3.3738,  3.1260,  2.8609,  2.5837,  2.2941,  1.9824,
         1.6712,  1.3310,  0.9775,  0.6061,  0.2124, -0.2095, -0.6538, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.3081e-02, -3.6963e-01,  3.2058e-03],
        [ 9.4413e-02, -3.7330e-01,  2.1143e-03],
        [ 9.5135e-02, -3.7442e-01,  1.9247e-03],
        [ 9.3849e-02, -3.7681e-01,  2.4679e-03],
        [ 9.4904e-02, -3.8151e-01,  1.3456e-03],
        [ 9.5548e-02, -3.8724e-01,  7.2762e-04],
        [ 9.3624e-02, -3.7317e-01,  1.8627e-03],
        [ 9.4917e-02, -3.7853e-01,  1.2487e-03],
        [ 9.4682e-02, -3.6986e-01,  1.4948e-03],
        [ 9.6880e-02, -3.8510e-01,  5.9894e-04],
        [ 9.6446e-02, -3.8147e-01,  7.6726e-04],
        [ 9.7453e-02, -3.8890e-01,  5.9074e-04],
        [ 9.7657e-02, -3.8798e-01,  4.0987e-04],
        [ 9.7389e-02, -3.8256e-01,  9.2000e-04],
        [ 9.8595e-02, -3.9164e-01,  1.5715e-04],
        [ 9.7791e-02, -3.8613e-01,  3.7885e-04],
        [ 9.8616e-02, -3.8699e-01,  2.0799e-04],
        [ 9.8242e-02, -3.8951e-01,  3.0324e-04],
        [ 9.7561e-02, -3.8521e-01,  5.1582e-04],
        [ 9.7398e-02, -3.8727e-01,  6.4772e-04],
        [ 9.6503e-02, -3.8121e-01,  1.5420e-03],
        [ 9.7665e-02, -3.8991e-01,  7.3898e-04],
        [ 9.4596e-02, -3.7613e-01,  3.2319e-03],
        [ 9.6225e-02, -3.8385e-01,  1.8980e-03],
        [ 9.4594e-02, -3.7682e-01,  5.2378e-03],
        [ 8.8041e-02, -3.3371e-01,  2.3761e-02],
        [ 9.0086e-02, -3.4706e-01,  1.6041e-02],
        [ 8.5192e-02, -2.8214e-01,  4.3139e-02],
        [ 9.2577e-02, -3.8501e-01,  1.2746e-02],
        [ 9.3649e-02, -3.8557e-01,  7.8734e-03],
        [ 8.8607e-02, -3.3307e-01,  2.7714e-02],
        [ 8.3163e-02, -3.6462e-01,  3.2686e-02],
        [ 9.3233e-02, -3.7240e-01,  1.4697e-02],
        [ 7.0113e-02, -2.4851e-01,  2.1849e-01],
        [ 6.4469e-02, -2.4449e-01,  2.9396e-01],
        [ 5.7743e-02, -1.9798e-01,  3.1646e-01],
        [ 6.0303e-02, -2.2702e-01,  2.4614e-01],
        [ 5.1879e-02, -1.9596e-01,  4.6116e-01],
        [ 9.1578e-02, -3.5732e-01,  6.3115e-03],
        [ 9.4677e-02, -3.7459e-01,  2.5691e-03],
        [ 8.4569e-02, -3.3918e-01,  1.6878e-02],
        [ 7.4220e-02, -3.2074e-01,  2.9490e-02],
        [ 7.8446e-02, -3.0524e-01,  2.7950e-02],
        [ 8.0165e-02, -2.8325e-01,  4.3249e-02],
        [ 9.3730e-02, -3.8113e-01,  1.9938e-03],
        [ 9.3754e-02, -3.8035e-01,  1.2497e-03],
        [ 9.6430e-02, -3.7541e-01,  1.3561e-03],
        [ 8.7502e-02, -2.7584e-01,  2.6898e-02],
        [ 8.1929e-02, -3.0367e-01,  3.2378e-02],
        [ 8.1506e-02, -3.0109e-01,  1.9595e-02],
        [ 8.1275e-02, -3.0605e-01,  3.0334e-02],
        [ 9.3561e-02, -3.6803e-01,  2.3171e-03],
        [ 9.6419e-02, -3.8754e-01,  5.8311e-04],
        [ 9.7154e-02, -3.8697e-01,  4.2295e-04],
        [ 9.7686e-02, -3.9148e-01,  4.3595e-04],
        [ 9.8358e-02, -3.9259e-01,  3.4755e-04],
        [ 9.5683e-02, -3.6291e-01,  1.3951e-03],
        [ 9.7596e-02, -3.9165e-01,  5.8442e-04],
        [ 9.7715e-02, -3.8776e-01,  4.8345e-04],
        [ 9.4467e-02, -3.6161e-01,  3.0817e-03],
        [ 9.7780e-02, -3.8700e-01,  5.8019e-04],
        [ 9.5107e-02, -3.8182e-01,  4.8274e-03],
        [ 9.1518e-02, -3.7415e-01,  1.2337e-02],
        [ 9.2758e-02, -3.8183e-01,  7.3179e-03],
        [ 9.5649e-02, -3.8934e-01,  1.7219e-03],
        [ 8.9944e-02, -3.1840e-01,  1.1626e-02],
        [ 8.5504e-02, -3.0074e-01,  4.3354e-02],
        [ 8.5163e-02, -3.4607e-01,  2.6194e-02],
        [ 8.7177e-02, -3.5254e-01,  1.4135e-02],
        [ 8.9938e-02, -3.7297e-01,  1.4765e-02],
        [ 9.1423e-02, -3.7171e-01,  2.7895e-02],
        [ 8.5417e-02, -3.6999e-01,  7.4472e-02],
        [ 8.7079e-02, -3.7695e-01,  2.7701e-02],
        [ 9.7201e-02, -3.9791e-01,  1.8106e-03],
        [ 8.6636e-02, -3.8118e-01,  1.3299e-02],
        [ 8.5001e-02, -3.4834e-01,  3.8204e-02],
        [ 8.0894e-02, -3.5109e-01,  9.3351e-02],
        [ 8.0253e-02, -3.6931e-01,  5.3462e-02],
        [ 7.9144e-02, -3.8128e-01,  7.2962e-02],
        [ 8.5681e-02, -3.8067e-01,  4.9139e-02],
        [ 8.9180e-02, -3.8664e-01,  1.8179e-02],
        [ 8.1695e-02, -3.2949e-01,  6.4369e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 7
Episode Length = 99
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1691,  1.1621,  1.1482,  1.1500,  1.1472,  1.1520,  1.1528,  1.1528,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1668,  1.1839,
         1.1838,  1.1767,  1.1588,  1.1570,  1.1630,  1.1818,  1.1863,  1.1624,
         1.1504,  1.1599,  1.1653,  1.1693,  1.1806,  1.1636,  1.1650,  1.1651,
         1.1632,  1.1672,  1.1684,  1.1699,  1.1617,  1.1532, -4.0000,  0.0000,
         0.0000,  0.1538,  1.1428,  1.1526,  1.1522, -6.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1574,  1.1523,  1.1584, -2.0000,  0.1666,  1.1615,
         1.0000], device='cuda:0')
target_q_episode tensor([ 2.0876,  1.1449,  0.1525, -0.8921, -1.9917, -3.1491, -4.3675, -5.6500,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 12.6234,
        12.2352, 11.8265, 11.3963, 10.9435, 10.4669,  9.9651,  9.4370,  8.8810,
         8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000, -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1450, -0.9000, -2.0000,  0.0000,  1.9500,
         1.0000], device='cuda:0')
target_q tensor([ 1.4458,  1.1569,  0.8483,  0.5350,  0.2018, -0.1434, -0.5099, -0.8961,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1165,  4.6294,
         4.5124,  4.3843,  4.2423,  4.1047,  3.9652,  3.8273,  3.6713,  3.4872,
         3.3026,  3.1236,  2.9321,  2.7293,  2.5208,  2.2811,  2.0424,  1.7900,
         1.5230,  1.2461,  0.9526,  0.6437,  0.3118, -0.0375, -4.0000,  0.0000,
         0.0000,  0.1075,  0.1083, -0.2382, -0.6105, -6.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1100,  0.8489,  0.5384, -2.0000,  0.1164,  1.3990,
         1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 0.0656, -0.2302,  0.0282],
        [ 0.0732, -0.2756,  0.0179],
        [ 0.0854, -0.3127,  0.0079],
        [ 0.0780, -0.2542,  0.0233],
        [ 0.0822, -0.3126,  0.0157],
        [ 0.0819, -0.2932,  0.0136],
        [ 0.0735, -0.2269,  0.0237],
        [ 0.0789, -0.2322,  0.0210],
        [ 0.0678, -0.2118,  0.0648],
        [ 0.0555, -0.1079,  0.1394],
        [ 0.0538, -0.1282,  0.1347],
        [ 0.0679, -0.1825,  0.0390],
        [ 0.0728, -0.1732,  0.0254],
        [ 0.0713, -0.1808,  0.0405],
        [ 0.0760, -0.2505,  0.0157],
        [ 0.0751, -0.1980,  0.0210],
        [ 0.0852, -0.2271,  0.0092],
        [ 0.0854, -0.2585,  0.0125],
        [ 0.0890, -0.3118,  0.0071],
        [ 0.0906, -0.3229,  0.0054],
        [ 0.0862, -0.2754,  0.0108],
        [ 0.0884, -0.3229,  0.0078],
        [ 0.0879, -0.3423,  0.0107],
        [ 0.0848, -0.2985,  0.0393],
        [ 0.0849, -0.3379,  0.0168],
        [ 0.0820, -0.3117,  0.0275],
        [ 0.0897, -0.3671,  0.0066],
        [ 0.0886, -0.3429,  0.0095],
        [ 0.0873, -0.3624,  0.0125],
        [ 0.0894, -0.3763,  0.0100],
        [ 0.0859, -0.3122,  0.0259],
        [ 0.0695, -0.2125,  0.0716],
        [ 0.0778, -0.3081,  0.0595],
        [ 0.0958, -0.3957,  0.0026],
        [ 0.0927, -0.3903,  0.0061],
        [ 0.0962, -0.3959,  0.0021],
        [ 0.0948, -0.3910,  0.0037],
        [ 0.0937, -0.3838,  0.0093],
        [ 0.0876, -0.3475,  0.0202],
        [ 0.0831, -0.3441,  0.0346],
        [ 0.0666, -0.2629,  0.1615],
        [ 0.0533, -0.1314,  0.3664],
        [ 0.0603, -0.1932,  0.0518],
        [ 0.0455, -0.1008,  0.0917],
        [ 0.0682, -0.2586,  0.0271],
        [ 0.0661, -0.2234,  0.0437],
        [ 0.0746, -0.3435,  0.0290],
        [ 0.0840, -0.3691,  0.0137],
        [ 0.0885, -0.3856,  0.0060],
        [ 0.0760, -0.3255,  0.0246],
        [ 0.0853, -0.3689,  0.0139],
        [ 0.0881, -0.3580,  0.0099],
        [ 0.0760, -0.3223,  0.0260],
        [ 0.0798, -0.3629,  0.0174],
        [ 0.0812, -0.3358,  0.0214],
        [ 0.0891, -0.3797,  0.0110],
        [ 0.0878, -0.3798,  0.0060],
        [ 0.0810, -0.1255,  0.0235],
        [ 0.0761, -0.2265,  0.0310],
        [ 0.0839, -0.2985,  0.0169],
        [ 0.0817, -0.2257,  0.0199],
        [ 0.0793, -0.0940,  0.0234],
        [ 0.0786, -0.1426,  0.0512],
        [ 0.0795, -0.0379,  0.0594],
        [ 0.0834, -0.1640,  0.0235],
        [ 0.0812, -0.3303,  0.0152],
        [ 0.0855, -0.2826,  0.0239],
        [ 0.0845, -0.2964,  0.0219],
        [ 0.0845, -0.3105,  0.0291],
        [ 0.0832, -0.3060,  0.0375],
        [ 0.0704, -0.2118,  0.1165],
        [ 0.0885, -0.3440,  0.0119],
        [ 0.0816, -0.2795,  0.0442],
        [ 0.0797, -0.3493,  0.0253],
        [ 0.0883, -0.3609,  0.0075],
        [ 0.0847, -0.3456,  0.0144],
        [ 0.0882, -0.3647,  0.0255],
        [ 0.0817, -0.3093,  0.0591],
        [ 0.0876, -0.3771,  0.0140],
        [ 0.0704, -0.2840,  0.1348],
        [ 0.0699, -0.3275,  0.1128],
        [ 0.0747, -0.2948,  0.1068],
        [ 0.0658, -0.2914,  0.1353],
        [ 0.0809, -0.3450,  0.0684],
        [ 0.0771, -0.2724,  0.1319],
        [ 0.0739, -0.2955,  0.1025],
        [ 0.0857, -0.3789,  0.0220],
        [ 0.0821, -0.3221,  0.1062],
        [ 0.0718, -0.3580,  0.0714],
        [ 0.0697, -0.2364,  0.0778],
        [ 0.0735, -0.2389,  0.0780],
        [ 0.0869, -0.3622,  0.0521],
        [ 0.0880, -0.3867,  0.0211],
        [ 0.0849, -0.3808,  0.0205],
        [ 0.0792, -0.3692,  0.0334],
        [ 0.0858, -0.3875,  0.0130],
        [ 0.0839, -0.3822,  0.0392],
        [ 0.0676, -0.2139,  0.1264],
        [ 0.0536, -0.2134,  0.2198]], device='cuda:0', grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 8
Episode Length = 81
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1941,  1.2023,  1.1908,  1.1902,  1.1940,  1.1950,  1.1905,  1.1846,
         1.1885,  1.1980,  1.2065,  1.2070,  1.1987,  1.2007,  1.2018,  1.2032,
         1.2082,  1.2044,  1.1986,  1.1861,  1.1821,  1.1821,  1.1929,  1.1995,
         1.1904,  1.1793,  1.1892,  1.1658,  1.1846,  1.1765,  1.1676,  1.1712,
        -4.0000,  0.0000,  0.0000,  0.1980,  1.1797,  1.1736,  1.1718,  1.1938,
         1.1918,  1.1972,  1.0000], device='cuda:0')
target_q_episode tensor([15.3509, 15.1062, 14.8487, 14.5775, 14.2922, 13.9917, 13.6755, 13.3426,
        12.9923, 12.6234, 12.2352, 11.8265, 11.3963, 10.9435, 10.4669,  9.9651,
         9.4370,  8.8810,  8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,
         4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000,
        -4.0000,  0.0000,  0.0000,  0.0000,  6.0333,  5.2982,  4.5244,  3.7099,
         2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 4.6851,  4.6310,  4.5588,  4.4915,  4.4239,  4.3506,  4.2693,  4.1827,
         4.0992,  4.0155,  3.9262,  3.8257,  3.7134,  3.6033,  3.4865,  3.3638,
         3.2374,  3.0974,  2.9487,  2.7875,  2.6245,  2.4562,  2.2872,  2.1056,
         1.9025,  1.6874,  1.4774,  1.2308,  1.0039,  0.7441,  0.4703,  0.1919,
        -4.0000,  0.0000,  0.0000,  0.1492,  2.3766,  2.1907,  1.9985,  1.8143,
         1.6013,  1.3829,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.3078e-02, -3.3721e-01,  2.3673e-03],
        [ 9.0029e-02, -3.0471e-01,  5.0184e-03],
        [ 9.1907e-02, -3.4746e-01,  3.8265e-03],
        [ 9.3214e-02, -3.6334e-01,  1.7670e-03],
        [ 9.1373e-02, -3.3954e-01,  2.7998e-03],
        [ 9.6375e-02, -3.8388e-01,  5.8612e-04],
        [ 9.7136e-02, -3.8427e-01,  3.1385e-04],
        [ 9.6066e-02, -3.7504e-01,  6.3819e-04],
        [ 9.5194e-02, -3.6085e-01,  9.1708e-04],
        [ 9.7099e-02, -3.7654e-01,  3.3265e-04],
        [ 9.7012e-02, -3.7492e-01,  4.6569e-04],
        [ 9.6993e-02, -3.8378e-01,  3.8043e-04],
        [ 9.5967e-02, -3.5768e-01,  7.4786e-04],
        [ 9.8256e-02, -3.8799e-01,  1.5232e-04],
        [ 9.7451e-02, -3.7970e-01,  3.8454e-04],
        [ 9.8049e-02, -3.8398e-01,  1.8758e-04],
        [ 9.7882e-02, -3.7341e-01,  4.1813e-04],
        [ 9.8547e-02, -3.7981e-01,  1.4997e-04],
        [ 9.5830e-02, -3.5332e-01,  1.6214e-03],
        [ 9.7505e-02, -3.7764e-01,  4.3145e-04],
        [ 9.6000e-02, -3.7437e-01,  1.1266e-03],
        [ 9.8082e-02, -3.8819e-01,  4.4855e-04],
        [ 9.5805e-02, -3.7432e-01,  1.4495e-03],
        [ 9.4993e-02, -3.6451e-01,  1.9740e-03],
        [ 9.5509e-02, -3.7495e-01,  1.7491e-03],
        [ 9.1051e-02, -2.9983e-01,  1.1342e-02],
        [ 8.9465e-02, -3.1939e-01,  1.0744e-02],
        [ 8.3506e-02, -2.1469e-01,  3.0488e-02],
        [ 8.9167e-02, -3.3863e-01,  1.4487e-02],
        [ 8.9171e-02, -2.9395e-01,  1.1894e-02],
        [ 9.2031e-02, -2.8751e-01,  6.9240e-03],
        [ 8.2479e-02, -3.4488e-01,  2.2003e-02],
        [ 9.2039e-02, -3.2548e-01,  1.4993e-02],
        [ 6.9620e-02, -2.0608e-01,  1.2782e-01],
        [ 6.7115e-02, -1.9352e-01,  1.5224e-01],
        [ 6.4432e-02, -1.7512e-01,  1.8965e-01],
        [ 6.3991e-02, -1.8772e-01,  1.6149e-01],
        [ 5.4780e-02, -1.8084e-01,  3.2574e-01],
        [ 8.5984e-02, -3.1543e-01,  5.3591e-03],
        [ 8.9828e-02, -3.5820e-01,  2.4754e-03],
        [ 8.9553e-02, -2.8157e-01,  1.0175e-02],
        [ 9.3171e-02, -3.2005e-01,  2.3198e-03],
        [ 9.6525e-02, -3.8601e-01,  4.2260e-04],
        [ 9.6275e-02, -3.6874e-01,  5.8055e-04],
        [ 9.7536e-02, -3.8509e-01,  3.0005e-04],
        [ 9.4452e-02, -3.5447e-01,  9.3383e-04],
        [ 9.5583e-02, -3.7088e-01,  1.3751e-03],
        [ 9.8144e-02, -3.8789e-01,  1.8692e-04],
        [ 9.8168e-02, -3.9283e-01,  2.0835e-04],
        [ 9.5888e-02, -3.6257e-01,  1.3004e-03],
        [ 9.1770e-02, -2.8958e-01,  4.6180e-03],
        [ 9.0860e-02, -3.2520e-01,  7.4488e-03],
        [ 9.5084e-02, -3.1412e-01,  2.3990e-03],
        [ 9.3739e-02, -3.5758e-01,  1.7336e-03],
        [ 9.5739e-02, -3.6693e-01,  1.1384e-03],
        [ 9.0804e-02, -2.7942e-01,  1.1651e-02],
        [ 8.6337e-02, -2.5012e-01,  9.5506e-03],
        [ 8.7502e-02, -2.0075e-01,  1.9514e-02],
        [ 9.6864e-02, -3.7113e-01,  4.7439e-04],
        [ 9.2929e-02, -3.4559e-01,  4.1324e-03],
        [ 9.3219e-02, -3.4430e-01,  4.4221e-03],
        [ 9.1898e-02, -3.4119e-01,  4.9891e-03],
        [ 9.5779e-02, -3.6032e-01,  2.9294e-03],
        [ 8.8513e-02, -3.2880e-01,  1.2892e-02],
        [ 8.8470e-02, -3.3347e-01,  1.4141e-02],
        [ 8.9226e-02, -3.3247e-01,  7.4058e-03],
        [ 9.5988e-02, -3.8737e-01,  2.2895e-03],
        [ 8.0227e-02, -2.4760e-01,  2.8204e-02],
        [ 7.8024e-02, -2.5290e-01,  4.5283e-02],
        [ 8.1945e-02, -2.9091e-01,  1.6718e-02],
        [ 9.4851e-02, -3.8513e-01,  8.0997e-03],
        [ 8.0078e-02, -3.2863e-01,  3.9982e-02],
        [ 9.1053e-02, -3.8491e-01,  1.4495e-02],
        [ 9.7604e-02, -3.9846e-01,  8.0878e-04],
        [ 8.9764e-02, -3.7502e-01,  1.5371e-02],
        [ 8.7011e-02, -3.7550e-01,  2.0667e-02],
        [ 8.5092e-02, -3.7756e-01,  2.0148e-02],
        [ 8.4706e-02, -2.9034e-01,  3.4496e-02],
        [ 6.7201e-02, -1.9388e-01,  1.1760e-01],
        [ 6.0753e-02, -1.8097e-01,  1.8506e-01],
        [ 6.6808e-02, -2.3019e-01,  1.0386e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 9
Episode Length = 100
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1967,  1.2020,  1.2088,  1.1969,  1.1828,  1.1820,  1.2057,  1.2174,
         1.1885,  1.1650,  1.2110,  1.2002,  1.1866,  1.1645, -4.0000,  0.0000,
         0.0000,  0.2022,  1.1836,  1.1749,  1.1734,  1.1783,  1.1800,  1.1748,
         1.1926,  1.1990,  1.1911,  1.1599,  1.1818,  1.1882,  1.1807,  1.1727,
         1.1689,  1.1760,  1.1875,  1.1797,  1.1787,  1.1747,  1.1811,  1.1697,
         1.1678,  1.1744,  1.1820,  1.1821,  1.1815,  1.1717,  1.1583,  1.1548,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1756,  1.1696,
         1.1687,  1.0000], device='cuda:0')
target_q_episode tensor([ 8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000, 14.2048, 13.8997, 13.5787, 13.2407, 12.8850, 12.5105,
        12.1163, 11.7014, 11.2646, 10.8048, 10.3209,  9.8115,  9.2752,  8.7108,
         8.1166,  7.4911,  6.8328,  6.1398,  5.4103,  4.6424,  3.8341,  2.9833,
         2.0876,  1.1449,  0.1525, -0.8921, -1.9917, -3.1491, -4.3675, -5.6500,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.8525,
         1.9500,  1.0000], device='cuda:0')
target_q tensor([ 2.6300,  2.5099,  2.3844,  2.2370,  2.0808,  1.9274,  1.7856,  1.6257,
         1.4246,  1.2184,  1.0577,  0.8414,  0.6119,  0.3641, -4.0000,  0.0000,
         0.0000,  0.1613,  3.8125,  3.7440,  3.6780,  3.6136,  3.5432,  3.4634,
         3.3981,  3.3194,  3.2249,  3.1071,  3.0270,  2.9292,  2.8150,  2.6946,
         2.5716,  2.4510,  2.3273,  2.1811,  2.0331,  1.8748,  1.7167,  1.5359,
         1.3535,  1.1684,  0.9741,  0.7633,  0.5409,  0.2994,  0.0427, -0.2190,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1401,  1.5093,
         1.3265,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 0.0519, -0.0756,  0.1094],
        [ 0.0610, -0.1639,  0.0631],
        [ 0.0816, -0.2964,  0.0096],
        [ 0.0833, -0.3300,  0.0065],
        [ 0.0874, -0.3324,  0.0048],
        [ 0.0691, -0.1823,  0.0405],
        [ 0.0589, -0.0799,  0.0444],
        [ 0.0658, -0.1010,  0.0341],
        [ 0.0723, -0.1393,  0.0297],
        [ 0.0732, -0.1166,  0.0330],
        [ 0.0764, -0.1796,  0.0206],
        [ 0.0739, -0.1314,  0.0228],
        [ 0.0767, -0.1332,  0.0228],
        [ 0.0789, -0.1708,  0.0100],
        [ 0.0807, -0.2344,  0.0093],
        [ 0.0872, -0.2939,  0.0033],
        [ 0.0930, -0.3408,  0.0008],
        [ 0.0940, -0.3427,  0.0011],
        [ 0.0909, -0.2873,  0.0028],
        [ 0.0910, -0.2961,  0.0025],
        [ 0.0911, -0.3064,  0.0037],
        [ 0.0905, -0.3367,  0.0037],
        [ 0.0909, -0.3205,  0.0023],
        [ 0.0897, -0.3031,  0.0045],
        [ 0.0923, -0.3261,  0.0035],
        [ 0.0915, -0.3494,  0.0028],
        [ 0.0937, -0.3534,  0.0020],
        [ 0.0908, -0.3502,  0.0054],
        [ 0.0909, -0.3173,  0.0048],
        [ 0.0926, -0.3155,  0.0046],
        [ 0.0891, -0.2874,  0.0111],
        [ 0.0881, -0.2773,  0.0087],
        [ 0.0890, -0.2789,  0.0080],
        [ 0.0921, -0.3353,  0.0062],
        [ 0.0855, -0.2906,  0.0263],
        [ 0.0839, -0.2264,  0.0346],
        [ 0.0852, -0.3063,  0.0318],
        [ 0.0824, -0.2684,  0.0458],
        [ 0.0780, -0.1784,  0.0801],
        [ 0.0757, -0.2336,  0.0732],
        [ 0.0716, -0.2159,  0.1148],
        [ 0.0698, -0.2069,  0.1073],
        [ 0.0467, -0.0326,  0.1166],
        [ 0.0580, -0.1775,  0.0785],
        [ 0.0846, -0.3133,  0.0041],
        [ 0.0653, -0.2162,  0.0334],
        [ 0.0582, -0.0937,  0.0788],
        [ 0.0718, -0.2558,  0.0141],
        [ 0.0777, -0.2253,  0.0160],
        [ 0.0631, -0.0966,  0.0656],
        [ 0.0802, -0.3280,  0.0085],
        [ 0.0828, -0.2039,  0.0068],
        [ 0.0918, -0.3688,  0.0025],
        [ 0.0921, -0.3718,  0.0010],
        [ 0.0634, -0.1176,  0.0450],
        [ 0.0742, -0.1172,  0.0223],
        [ 0.0871, -0.1594,  0.0073],
        [ 0.0933, -0.3583,  0.0029],
        [ 0.0831,  0.0602,  0.0139],
        [ 0.0866, -0.1598,  0.0071],
        [ 0.0874, -0.1458,  0.0074],
        [ 0.0835, -0.0089,  0.0160],
        [ 0.0859,  0.1243,  0.0083],
        [ 0.0873, -0.2003,  0.0138],
        [ 0.0915,  0.0596,  0.0046],
        [ 0.0810, -0.1077,  0.0154],
        [ 0.0792,  0.0654,  0.0226],
        [ 0.0771, -0.0520,  0.0360],
        [ 0.0880, -0.3453,  0.0032],
        [ 0.0801, -0.0705,  0.0293],
        [ 0.0879, -0.3166,  0.0107],
        [ 0.0724, -0.1638,  0.0605],
        [ 0.0813, -0.3303,  0.0263],
        [ 0.0823, -0.3140,  0.0131],
        [ 0.0776, -0.1512,  0.0258],
        [ 0.0885,  0.1733,  0.0119],
        [ 0.0858,  0.0411,  0.0230],
        [ 0.0903, -0.3556,  0.0080],
        [ 0.0835, -0.2893,  0.0159],
        [ 0.0918, -0.3527,  0.0047],
        [ 0.0897, -0.3524,  0.0084],
        [ 0.0900, -0.3614,  0.0072],
        [ 0.0826, -0.2946,  0.0222],
        [ 0.0858, -0.3040,  0.0160],
        [ 0.0814, -0.2597,  0.0368],
        [ 0.0852, -0.3475,  0.0203],
        [ 0.0827, -0.2995,  0.0244],
        [ 0.0784, -0.2510,  0.0472],
        [ 0.0813, -0.2946,  0.0276],
        [ 0.0827, -0.2645,  0.0172],
        [ 0.0947, -0.3849,  0.0053],
        [ 0.0908, -0.3791,  0.0122],
        [ 0.0933, -0.3695,  0.0129],
        [ 0.0798, -0.2563,  0.0444],
        [ 0.0831, -0.1856,  0.0228],
        [ 0.0874, -0.1345,  0.0141],
        [ 0.0821, -0.2238,  0.0453],
        [ 0.0847, -0.1896,  0.0172],
        [ 0.0803, -0.1775,  0.0398],
        [ 0.0768, -0.3027,  0.0560]], device='cuda:0', grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 10
Episode Length = 82
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.2006,   1.2047,   1.1967,   1.1865,   1.1731,   1.1616,   1.1547,
          1.1463, -10.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.1612,   1.1794,   1.1888,   1.2012,
          1.1903,   1.1881,   1.1944,   1.1934,   1.1848,  -8.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1996,   1.1743,
          1.1796,   1.1674,   1.1610,   1.1592,  -5.0000,   0.0000,   0.0000,
          0.0000,   0.0000], device='cuda:0')
target_q_episode tensor([  0.0974,  -0.9501,  -2.0528,  -3.2134,  -4.4352,  -5.7213,  -7.0750,
         -8.5000, -10.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   1.4242,   0.4466,  -0.5826,
         -1.6659,  -2.8062,  -4.0065,  -5.2700,  -6.6000,  -8.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.6555,
         -0.3627,  -1.4344,  -2.5625,  -3.7500,  -5.0000,   0.0000,   0.0000,
          0.0000,   0.0000], device='cuda:0')
target_q tensor([  1.0182,   0.8485,   0.6595,   0.4592,   0.2461,   0.0239,  -0.2056,
         -0.4482, -10.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.1346,   1.2198,   1.0661,   0.9064,
          0.7182,   0.5278,   0.3347,   0.1250,  -0.1020,  -8.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1666,   1.0885,
          0.9247,   0.7373,   0.5455,   0.3477,  -5.0000,   0.0000,   0.0000,
          0.0000,   0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.1857e-02, -3.1664e-01,  3.4038e-03],
        [ 9.3481e-02, -3.1033e-01,  1.8852e-03],
        [ 9.3276e-02, -3.2638e-01,  2.2793e-03],
        [ 9.5583e-02, -3.7021e-01,  5.9181e-04],
        [ 9.4685e-02, -3.7040e-01,  9.0617e-04],
        [ 9.8102e-02, -3.7375e-01,  1.1411e-04],
        [ 9.7540e-02, -3.6807e-01,  1.8492e-04],
        [ 9.7596e-02, -3.7139e-01,  1.8099e-04],
        [ 9.6880e-02, -3.6404e-01,  1.6585e-04],
        [ 9.6935e-02, -3.6047e-01,  4.0677e-04],
        [ 9.8068e-02, -3.7214e-01,  1.3819e-04],
        [ 9.8201e-02, -3.7514e-01,  1.6394e-04],
        [ 9.7439e-02, -3.5823e-01,  2.8870e-04],
        [ 9.8368e-02, -3.7504e-01,  1.2267e-04],
        [ 9.6738e-02, -3.4473e-01,  6.4227e-04],
        [ 9.8791e-02, -3.7762e-01,  6.4105e-05],
        [ 9.8607e-02, -3.6125e-01,  1.1051e-04],
        [ 9.8675e-02, -3.6500e-01,  8.6337e-05],
        [ 9.8324e-02, -3.6820e-01,  1.6415e-04],
        [ 9.7907e-02, -3.8302e-01,  2.1607e-04],
        [ 9.6413e-02, -3.5390e-01,  9.2074e-04],
        [ 9.7749e-02, -3.6935e-01,  2.4763e-04],
        [ 9.7948e-02, -3.7670e-01,  2.5186e-04],
        [ 9.8092e-02, -3.7477e-01,  2.4420e-04],
        [ 9.7863e-02, -3.8061e-01,  3.4681e-04],
        [ 9.2779e-02, -3.0989e-01,  4.4822e-03],
        [ 9.5325e-02, -3.1781e-01,  1.9786e-03],
        [ 9.2976e-02, -2.4710e-01,  5.2871e-03],
        [ 9.2915e-02, -3.5892e-01,  5.5974e-03],
        [ 9.4901e-02, -3.6895e-01,  2.2515e-03],
        [ 9.3639e-02, -3.4504e-01,  2.4153e-03],
        [ 8.9951e-02, -3.6248e-01,  4.9018e-03],
        [ 9.2839e-02, -3.2565e-01,  7.1243e-03],
        [ 8.0751e-02, -2.0809e-01,  4.4084e-02],
        [ 7.1674e-02, -1.9947e-01,  1.1957e-01],
        [ 7.4114e-02, -1.6805e-01,  9.1237e-02],
        [ 7.0233e-02, -1.7900e-01,  1.1005e-01],
        [ 6.5816e-02, -2.0562e-01,  1.7680e-01],
        [ 9.3767e-02, -3.4660e-01,  1.5841e-03],
        [ 9.3728e-02, -3.2648e-01,  1.9269e-03],
        [ 9.2923e-02, -3.4070e-01,  1.5519e-03],
        [ 9.7762e-02, -3.8031e-01,  1.6999e-04],
        [ 9.4550e-02, -3.5165e-01,  1.4737e-03],
        [ 8.3130e-02, -2.9281e-01,  1.2298e-02],
        [ 8.5655e-02, -3.5283e-01,  1.0207e-02],
        [ 8.2107e-02, -3.4497e-01,  1.6068e-02],
        [ 8.2772e-02, -3.0786e-01,  2.2961e-02],
        [ 7.3632e-02, -2.9710e-01,  3.2806e-02],
        [ 8.5344e-02, -3.2113e-01,  1.3922e-02],
        [ 7.3792e-02, -2.3553e-01,  5.5267e-02],
        [ 9.2650e-02, -3.3812e-01,  5.3738e-03],
        [ 8.8143e-02, -1.0626e-01,  1.0361e-02],
        [ 9.2567e-02, -3.1741e-01,  2.2582e-03],
        [ 8.8416e-02, -3.1984e-01,  6.0763e-03],
        [ 8.6599e-02, -2.9412e-01,  1.3128e-02],
        [ 7.7805e-02, -2.3434e-01,  2.7095e-02],
        [ 8.3756e-02, -3.0285e-01,  1.5933e-02],
        [ 8.4965e-02, -3.2523e-01,  8.4649e-03],
        [ 9.1173e-02, -2.6678e-01,  6.5310e-03],
        [ 9.3101e-02, -2.4377e-01,  1.7930e-03],
        [ 9.3577e-02, -3.3879e-01,  2.0321e-03],
        [ 9.2350e-02, -3.3613e-01,  5.6809e-03],
        [ 9.1566e-02, -3.0572e-01,  4.6477e-03],
        [ 9.6975e-02, -3.5360e-01,  3.7104e-04],
        [ 9.6035e-02, -3.4487e-01,  6.3518e-04],
        [ 9.1915e-02, -3.5327e-01,  3.7777e-03],
        [ 9.5415e-02, -3.7062e-01,  1.8155e-03],
        [ 9.2702e-02, -3.1086e-01,  3.3422e-03],
        [ 9.2661e-02, -3.4311e-01,  2.6813e-03],
        [ 9.3468e-02, -2.5725e-01,  3.2487e-03],
        [ 9.5396e-02, -3.7559e-01,  4.3772e-03],
        [ 9.6225e-02, -3.9230e-01,  2.0378e-03],
        [ 8.8472e-02, -3.2977e-01,  9.9666e-03],
        [ 8.4441e-02, -3.4874e-01,  2.7098e-02],
        [ 8.3746e-02, -3.4130e-01,  2.9793e-02],
        [ 8.5215e-02, -3.6968e-01,  9.6670e-03],
        [ 7.9725e-02, -3.1589e-01,  2.5605e-02],
        [ 8.5785e-02, -3.5227e-01,  8.7189e-03],
        [ 8.6240e-02, -3.5790e-01,  1.3923e-02],
        [ 9.1536e-02, -3.7147e-01,  5.0467e-03],
        [ 8.6899e-02, -2.0820e-01,  8.7881e-03],
        [ 6.9008e-02, -7.6172e-02,  9.5328e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Saving checkpoint
Run No. 11
Episode Length = 92
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1880,  1.1841,  1.1540,  1.1557,  1.1513,  1.1522,  1.1497, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1569,  1.1544,  1.1916,  1.2016,
         1.1939,  1.1724,  1.1861,  1.1900,  1.1800,  1.1789,  1.1822,  1.1802,
         1.1650,  1.1626, -5.0000,  0.0000,  0.0000,  0.0000,  0.1765,  1.1724,
         1.1723,  1.1667,  1.1672,  1.1622,  1.1540,  1.1521, -8.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1457,  1.1483,  1.1419,
         1.1505,  1.0000], device='cuda:0')
target_q_episode tensor([ 1.8432,  0.8876, -0.1183, -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  7.1664,  6.4910,  5.7800,
         5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344,
        -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4466,
        -0.5826, -1.6659, -2.8062, -4.0065, -5.2700, -6.6000, -8.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.7099,  2.8525,
         1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.2767,  1.1440,  0.9818,  0.8400,  0.6854,  0.5273,  0.3580, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1357,  1.9680,  1.9088,  1.8212,
         1.7133,  1.5881,  1.4877,  1.3729,  1.2399,  1.1081,  0.9731,  0.8263,
         0.6605,  0.4977, -5.0000,  0.0000,  0.0000,  0.0000,  0.1526,  1.0742,
         0.9348,  0.7834,  0.6295,  0.4627,  0.2846,  0.1030, -8.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1260,  1.4949,  1.3734,
         1.2587,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.1162e-02, -2.0840e-01,  6.1212e-03],
        [ 7.7939e-02, -1.3087e-01,  7.0486e-03],
        [ 7.9312e-02, -1.9787e-01,  1.0208e-02],
        [ 7.8389e-02, -1.7130e-01,  1.7710e-02],
        [ 6.9711e-02, -1.6714e-01,  2.9220e-02],
        [ 8.1370e-02, -1.9489e-01,  1.0386e-02],
        [ 7.9496e-02, -1.8035e-01,  1.1179e-02],
        [ 8.0891e-02, -2.0049e-01,  1.0148e-02],
        [ 6.9565e-02, -8.7582e-02,  2.3571e-02],
        [ 6.7699e-02,  7.8856e-03,  4.7075e-02],
        [ 6.8797e-02,  1.3594e-03,  3.7055e-02],
        [ 6.9934e-02, -2.6812e-02,  3.6770e-02],
        [ 7.5721e-02,  2.3016e-02,  1.9213e-02],
        [ 7.3972e-02,  3.3898e-02,  1.7802e-02],
        [ 8.2453e-02, -6.3400e-02,  6.2693e-03],
        [ 8.0145e-02, -3.9863e-02,  8.7374e-03],
        [ 8.8915e-02, -8.8295e-02,  3.3086e-03],
        [ 8.5772e-02, -1.3233e-01,  7.2280e-03],
        [ 8.8211e-02, -2.1580e-01,  3.5801e-03],
        [ 9.0421e-02, -2.5625e-01,  2.1681e-03],
        [ 8.7548e-02, -2.1107e-01,  6.6044e-03],
        [ 8.9096e-02, -1.9436e-01,  3.4235e-03],
        [ 9.1211e-02, -3.2732e-01,  2.4125e-03],
        [ 8.6792e-02, -2.5931e-01,  1.6112e-02],
        [ 8.8750e-02, -3.0757e-01,  3.7398e-03],
        [ 8.6338e-02, -2.6497e-01,  9.5659e-03],
        [ 9.0606e-02, -3.4129e-01,  1.9079e-03],
        [ 9.5376e-02, -3.5144e-01,  1.0441e-03],
        [ 9.3175e-02, -3.4972e-01,  2.6367e-03],
        [ 9.0292e-02, -3.6414e-01,  3.1399e-03],
        [ 8.7158e-02, -2.2032e-01,  1.7384e-02],
        [ 7.4417e-02, -1.1865e-01,  3.1091e-02],
        [ 8.0111e-02, -2.2051e-01,  3.3190e-02],
        [ 9.7746e-02, -3.9597e-01,  3.5214e-04],
        [ 9.6920e-02, -3.9073e-01,  6.8361e-04],
        [ 9.7546e-02, -3.8952e-01,  8.3351e-04],
        [ 9.3160e-02, -3.5796e-01,  3.9328e-03],
        [ 9.5991e-02, -3.6422e-01,  2.2375e-03],
        [ 9.2062e-02, -3.0381e-01,  5.3266e-03],
        [ 8.7540e-02, -3.0595e-01,  1.6348e-02],
        [ 7.2487e-02, -2.4513e-01,  5.8090e-02],
        [ 5.4534e-02, -1.1825e-01,  3.1920e-01],
        [ 5.2420e-02,  3.8089e-02,  9.2920e-02],
        [ 4.1608e-02,  2.3619e-02,  1.2467e-01],
        [ 7.3322e-02, -1.3221e-01,  1.5997e-02],
        [ 8.1991e-02, -2.9073e-01,  7.3323e-03],
        [ 8.9429e-02, -3.6359e-01,  4.3218e-03],
        [ 8.6154e-02, -3.5231e-01,  8.2830e-03],
        [ 9.1152e-02, -3.7217e-01,  3.6453e-03],
        [ 9.0946e-02, -3.7478e-01,  3.0271e-03],
        [ 8.7814e-02, -3.4763e-01,  5.2476e-03],
        [ 9.1373e-02, -3.1484e-01,  4.4172e-03],
        [ 7.2772e-02, -3.2661e-02,  3.2595e-02],
        [ 8.8276e-02, -2.7814e-01,  8.4034e-03],
        [ 8.4672e-02, -2.4945e-01,  1.2302e-02],
        [ 8.8226e-02, -2.9894e-01,  6.8567e-03],
        [ 9.0619e-02, -3.2084e-01,  4.4802e-03],
        [ 8.6945e-02, -2.9373e-01,  4.5085e-03],
        [ 7.8775e-02, -2.3919e-01,  1.0537e-02],
        [ 7.6087e-02, -1.2197e-01,  2.7127e-02],
        [ 8.6339e-02, -2.8962e-01,  1.0864e-02],
        [ 7.9869e-02, -7.5246e-02,  1.6276e-02],
        [ 8.4336e-02, -1.5175e-01,  1.0605e-02],
        [ 8.6725e-02, -2.2453e-01,  1.0360e-02],
        [ 8.1622e-02, -1.2223e-01,  1.8731e-02],
        [ 7.8129e-02, -1.3875e-01,  2.5028e-02],
        [ 8.3729e-02, -8.5964e-02,  1.2078e-02],
        [ 8.3102e-02, -1.5680e-01,  2.0872e-02],
        [ 8.6415e-02, -1.7556e-01,  1.4092e-02],
        [ 8.3769e-02, -7.5880e-02,  1.8104e-02],
        [ 8.2171e-02, -2.1032e-01,  1.7390e-02],
        [ 8.5390e-02, -2.8499e-01,  1.9161e-02],
        [ 7.9627e-02, -2.2464e-01,  2.1309e-02],
        [ 8.6559e-02, -1.9745e-01,  1.8032e-02],
        [ 8.7124e-02, -3.4279e-01,  6.7607e-03],
        [ 8.8980e-02, -2.7390e-01,  3.9317e-03],
        [ 9.5671e-02, -3.7395e-01,  2.0294e-03],
        [ 9.3405e-02, -3.6482e-01,  3.1609e-03],
        [ 8.8319e-02, -3.7364e-01,  7.2970e-03],
        [ 9.0036e-02, -3.5179e-01,  9.3363e-03],
        [ 9.4725e-02, -3.8016e-01,  2.7303e-03],
        [ 9.6279e-02, -3.6837e-01,  1.3962e-03],
        [ 9.2831e-02, -3.4095e-01,  5.0225e-03],
        [ 9.3043e-02, -3.6806e-01,  3.1793e-03],
        [ 9.0722e-02, -3.6125e-01,  9.5439e-03],
        [ 8.1458e-02, -2.6311e-01,  6.3198e-02],
        [ 7.8390e-02, -2.5085e-01,  2.8695e-02],
        [ 7.8031e-02, -3.1391e-01,  3.3732e-02],
        [ 7.7000e-02, -2.4186e-01,  6.5429e-02],
        [ 6.0479e-02, -1.6977e-01,  1.3996e-01],
        [ 6.2284e-02, -2.0166e-01,  1.1147e-01],
        [ 8.6802e-02, -3.7411e-01,  1.6118e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 12
Episode Length = 89
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1796,  1.1855,  1.1820,  1.1907,  1.1930,  1.1954,  1.2039, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1630,  1.1588,  1.1481,  1.1475,
         1.1500,  1.1463,  1.1480, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1814,  1.1760,  1.1739,  1.1643,  1.1571,  1.1729,  1.1607,  1.1729,
         1.1561,  1.1364, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1594,
         1.1664,  1.1920,  1.1863,  1.1771,  1.1643,  1.1576,  1.1837,  1.1822,
         1.1831,  1.1818,  1.0000], device='cuda:0')
target_q_episode tensor([ 1.8432,  0.8876, -0.1183, -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.8876, -0.1183, -1.1772,
        -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  3.6135,  2.7511,  1.8432,  0.8876, -0.1183, -1.1772, -2.2917,
        -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,
         2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.2531,  1.1525,  1.0379,  0.9283,  0.8069,  0.6790,  0.5497, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1449,  1.1287,  1.0078,  0.8899,
         0.7686,  0.6353,  0.5000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1613,  1.4461,  1.3487,  1.2395,  1.1273,  1.0299,  0.9017,  0.7890,
         0.6441,  0.4897, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1418,
         1.9928,  1.9491,  1.8742,  1.7925,  1.7038,  1.6164,  1.5539,  1.4622,
         1.3681,  1.2669,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.4215e-02, -2.9466e-01,  1.7060e-03],
        [ 9.6482e-02, -3.2811e-01,  7.4631e-04],
        [ 9.7165e-02, -3.5998e-01,  4.5151e-04],
        [ 9.6990e-02, -3.6500e-01,  3.8719e-04],
        [ 9.7469e-02, -3.6266e-01,  1.7253e-04],
        [ 9.7750e-02, -3.6327e-01,  1.2875e-04],
        [ 9.8804e-02, -3.7630e-01,  4.3243e-05],
        [ 9.7329e-02, -3.6698e-01,  1.7428e-04],
        [ 9.7731e-02, -3.4368e-01,  1.6284e-04],
        [ 9.8812e-02, -3.7520e-01,  4.9978e-05],
        [ 9.8771e-02, -3.7575e-01,  9.2030e-05],
        [ 9.9057e-02, -3.7905e-01,  5.1409e-05],
        [ 9.8840e-02, -3.7773e-01,  7.9513e-05],
        [ 9.9440e-02, -3.8066e-01,  1.1683e-05],
        [ 9.9146e-02, -3.6928e-01,  2.7984e-05],
        [ 9.8805e-02, -3.5184e-01,  7.8648e-05],
        [ 9.9065e-02, -3.3970e-01,  5.6058e-05],
        [ 9.9213e-02, -3.6692e-01,  3.8415e-05],
        [ 9.9179e-02, -3.7749e-01,  3.3498e-05],
        [ 9.9297e-02, -3.7701e-01,  2.3544e-05],
        [ 9.8936e-02, -3.7813e-01,  7.7933e-05],
        [ 9.8262e-02, -3.4230e-01,  1.6773e-04],
        [ 9.8668e-02, -3.7636e-01,  8.9616e-05],
        [ 9.8998e-02, -3.8273e-01,  5.3555e-05],
        [ 9.8153e-02, -3.7085e-01,  2.3583e-04],
        [ 9.5499e-02, -3.2303e-01,  1.5839e-03],
        [ 9.8437e-02, -3.7153e-01,  2.6268e-04],
        [ 9.6803e-02, -3.3198e-01,  8.9657e-04],
        [ 9.5851e-02, -3.7209e-01,  1.5407e-03],
        [ 9.6723e-02, -3.6145e-01,  9.5785e-04],
        [ 9.2246e-02, -2.6818e-01,  5.1600e-03],
        [ 8.9593e-02, -3.3300e-01,  7.9623e-03],
        [ 9.6808e-02, -3.5050e-01,  1.2804e-03],
        [ 8.0558e-02, -1.6485e-01,  3.8402e-02],
        [ 8.3527e-02, -1.6184e-01,  3.6027e-02],
        [ 7.5651e-02, -1.1212e-01,  8.5301e-02],
        [ 7.2285e-02, -1.5040e-01,  9.9266e-02],
        [ 6.5679e-02, -1.6399e-01,  1.5835e-01],
        [ 9.5484e-02, -3.4613e-01,  6.1527e-04],
        [ 9.7421e-02, -3.7956e-01,  1.7643e-04],
        [ 9.6401e-02, -3.7448e-01,  2.4813e-04],
        [ 9.7288e-02, -3.7733e-01,  1.6794e-04],
        [ 9.5122e-02, -3.3602e-01,  1.1422e-03],
        [ 9.5749e-02, -3.2914e-01,  1.0487e-03],
        [ 9.4111e-02, -2.3923e-01,  1.6266e-03],
        [ 8.6961e-02, -5.8854e-02,  1.0870e-02],
        [ 8.1780e-02, -2.0791e-01,  2.3989e-02],
        [ 8.7755e-02, -1.5581e-01,  9.4289e-03],
        [ 8.8532e-02, -2.8781e-01,  5.9398e-03],
        [ 8.1217e-02, -2.6503e-01,  2.4483e-02],
        [ 8.5389e-02, -3.1515e-01,  8.7353e-03],
        [ 7.9079e-02, -2.4070e-01,  2.1421e-02],
        [ 7.6069e-02, -2.0914e-01,  3.8762e-02],
        [ 7.8786e-02, -2.5294e-01,  2.7024e-02],
        [ 8.2692e-02, -2.6473e-01,  2.7041e-02],
        [ 8.1918e-02, -2.7518e-01,  3.8476e-02],
        [ 7.9482e-02, -2.2317e-01,  4.1867e-02],
        [ 7.9875e-02, -1.5218e-01,  3.1737e-02],
        [ 7.4011e-02, -2.3035e-01,  4.9539e-02],
        [ 8.2014e-02, -2.8407e-01,  3.1871e-02],
        [ 8.3090e-02, -2.9743e-01,  2.4266e-02],
        [ 7.3628e-02, -1.5435e-01,  4.3654e-02],
        [ 9.2115e-02, -2.9323e-01,  7.8988e-03],
        [ 9.6384e-02, -3.2876e-01,  7.3716e-04],
        [ 8.9287e-02, -2.0567e-01,  3.9276e-03],
        [ 9.0968e-02, -2.4352e-01,  4.2904e-03],
        [ 9.5320e-02, -3.2937e-01,  1.6848e-03],
        [ 9.1818e-02, -2.6423e-01,  2.8264e-03],
        [ 9.2691e-02, -3.3028e-01,  4.2692e-03],
        [ 8.8522e-02, -2.7673e-01,  5.2778e-03],
        [ 9.5986e-02, -3.8197e-01,  1.5184e-03],
        [ 9.4184e-02, -3.7178e-01,  4.1172e-03],
        [ 9.6591e-02, -3.6037e-01,  2.9189e-03],
        [ 9.7064e-02, -3.8829e-01,  2.2141e-03],
        [ 9.5337e-02, -3.6880e-01,  2.3987e-03],
        [ 9.7545e-02, -3.9290e-01,  5.2434e-04],
        [ 9.6991e-02, -3.8874e-01,  1.0551e-03],
        [ 9.4367e-02, -3.4876e-01,  2.9861e-03],
        [ 9.2657e-02, -3.6667e-01,  6.6137e-03],
        [ 8.1039e-02, -1.9985e-01,  2.9612e-02],
        [ 8.1755e-02, -2.5008e-01,  2.8070e-02],
        [ 8.6857e-02, -3.0956e-01,  1.1076e-02],
        [ 8.5731e-02, -2.9596e-01,  1.5959e-02],
        [ 8.0752e-02, -2.4205e-01,  1.8377e-02],
        [ 8.3839e-02, -2.9682e-01,  1.3180e-02],
        [ 7.2884e-02, -1.4520e-01,  4.6213e-02],
        [ 6.6585e-02, -5.8971e-02,  1.0214e-01],
        [ 6.3719e-02, -9.2610e-02,  1.1093e-01],
        [ 6.3397e-02, -5.0285e-02,  9.5098e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 13
Episode Length = 96
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1772,   1.1853,   1.1651,   1.1719,   1.1462,   1.1375,   1.1365,
          1.1356,  -7.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.1715,   1.1703,   1.1700,   1.1665,   1.1551,   1.1685,   1.1663,
          1.1659,   1.1646,   1.1635,   1.1626,  -7.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.1633,   1.1521,   1.1402,   1.1446,
          1.1301, -10.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.1440,   1.1435,   1.1504,   1.1655,
          1.1592,   1.1581,   1.1446,   1.1456,   1.0000], device='cuda:0')
target_q_episode tensor([  2.0876,   1.1449,   0.1525,  -0.8921,  -1.9917,  -3.1491,  -4.3675,
         -5.6500,  -7.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   3.8341,   2.9833,   2.0876,   1.1449,   0.1525,  -0.8921,
         -1.9917,  -3.1491,  -4.3675,  -5.6500,  -7.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,  -4.4352,  -5.7213,  -7.0750,
         -8.5000, -10.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   6.7316,   6.0333,   5.2982,
          4.5244,   3.7099,   2.8525,   1.9500,   1.0000], device='cuda:0')
target_q tensor([  1.2598,   1.1816,   1.0732,   0.9847,   0.8616,   0.7486,   0.6372,
          0.5200,  -7.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.1559,   1.4120,   1.3345,   1.2501,   1.1542,   1.0763,   0.9796,
          0.8794,   0.7733,   0.6617,   0.5446,  -7.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.1485,   0.6452,   0.5178,   0.3989,
          0.2565, -10.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.1309,   1.6504,   1.5933,   1.5404,
          1.4644,   1.3896,   1.2995,   1.2186,   1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 6.4662e-02, -2.0744e-02,  5.4991e-02],
        [ 5.1424e-02, -1.0024e-01,  1.0925e-01],
        [ 8.4272e-02, -2.6990e-01,  5.1857e-03],
        [ 8.5692e-02, -2.6056e-01,  3.8865e-03],
        [ 8.9130e-02, -3.0752e-01,  2.4361e-03],
        [ 7.2432e-02, -1.7037e-01,  2.1553e-02],
        [ 7.9300e-02,  6.9234e-03,  7.3009e-03],
        [ 7.7884e-02, -8.1298e-02,  1.3276e-02],
        [ 8.2244e-02, -1.1268e-01,  7.4669e-03],
        [ 8.0807e-02, -6.1293e-02,  1.0205e-02],
        [ 8.7687e-02, -8.8914e-02,  6.3238e-03],
        [ 8.4585e-02, -3.3443e-02,  7.3590e-03],
        [ 7.9322e-02,  2.0023e-02,  1.3574e-02],
        [ 8.5163e-02, -1.3050e-01,  5.0065e-03],
        [ 8.3620e-02, -1.3798e-01,  9.8248e-03],
        [ 8.8145e-02, -8.8807e-02,  2.3121e-03],
        [ 9.2545e-02, -2.2385e-01,  1.3916e-03],
        [ 9.1030e-02, -1.8895e-01,  1.2799e-03],
        [ 9.3224e-02, -2.3107e-01,  1.6306e-03],
        [ 9.2444e-02, -1.9540e-01,  1.9491e-03],
        [ 9.1363e-02, -2.3269e-01,  2.6319e-03],
        [ 9.4839e-02, -3.2124e-01,  8.1947e-04],
        [ 9.4416e-02, -2.7332e-01,  9.0194e-04],
        [ 9.0051e-02, -1.7850e-01,  4.6667e-03],
        [ 9.4202e-02, -2.2262e-01,  1.7182e-03],
        [ 9.4197e-02, -3.2050e-01,  1.4690e-03],
        [ 9.3371e-02, -2.4741e-01,  2.1092e-03],
        [ 9.0612e-02, -2.0693e-01,  4.5407e-03],
        [ 9.2512e-02, -2.6477e-01,  2.6277e-03],
        [ 9.3003e-02, -2.5517e-01,  3.2726e-03],
        [ 8.7433e-02, -2.0439e-01,  8.5450e-03],
        [ 9.2214e-02, -2.7032e-01,  2.8600e-03],
        [ 8.4997e-02, -7.6159e-02,  1.3952e-02],
        [ 8.9876e-02, -2.3539e-01,  6.1736e-03],
        [ 9.2475e-02, -3.1836e-01,  4.3221e-03],
        [ 8.9515e-02, -2.5356e-01,  1.5300e-02],
        [ 8.8370e-02, -2.5379e-01,  1.5911e-02],
        [ 8.2406e-02, -1.8398e-01,  3.5496e-02],
        [ 7.8755e-02, -1.6852e-01,  4.2189e-02],
        [ 7.5038e-02, -1.1791e-01,  6.0072e-02],
        [ 6.5922e-02, -1.3417e-01,  1.5005e-01],
        [ 7.2935e-02, -1.2225e-01,  1.1080e-01],
        [ 8.1757e-02, -2.2390e-01,  5.8668e-03],
        [ 8.7984e-02, -3.0409e-01,  2.8251e-03],
        [ 8.2921e-02, -2.8172e-01,  4.3871e-03],
        [ 6.3370e-02, -6.4248e-02,  4.1687e-02],
        [ 7.7544e-02, -1.4928e-01,  1.2203e-02],
        [ 8.4455e-02, -1.8949e-01,  4.0772e-03],
        [ 9.4877e-02, -3.5620e-01,  1.4611e-03],
        [ 9.0118e-02, -3.4302e-01,  3.6126e-03],
        [ 8.8605e-02, -3.5534e-01,  4.4095e-03],
        [ 9.4629e-02, -3.7104e-01,  6.0108e-04],
        [ 9.6974e-02, -3.9142e-01,  2.9239e-04],
        [ 9.2156e-02, -3.3593e-01,  4.2427e-03],
        [ 8.3810e-02, -1.1313e-01,  6.5537e-03],
        [ 8.7438e-02,  1.7153e-02,  3.7795e-03],
        [ 7.7701e-02, -7.2007e-02,  1.7757e-02],
        [ 8.8878e-02, -1.2652e-01,  3.8587e-03],
        [ 7.8762e-02,  3.7270e-03,  1.4735e-02],
        [ 8.8637e-02, -1.2215e-01,  5.8196e-03],
        [ 8.7181e-02,  8.1784e-03,  6.1579e-03],
        [ 8.9832e-02, -1.3875e-01,  3.9435e-03],
        [ 8.8067e-02, -1.3923e-01,  4.8470e-03],
        [ 8.6843e-02, -1.4776e-01,  4.4888e-03],
        [ 8.7523e-02, -1.1610e-01,  6.2155e-03],
        [ 8.7121e-02, -1.9027e-01,  6.5152e-03],
        [ 8.4565e-02, -1.5370e-01,  1.5443e-02],
        [ 8.6450e-02, -1.4100e-01,  7.0689e-03],
        [ 9.2851e-02, -3.1747e-01,  2.9983e-03],
        [ 9.3572e-02, -3.0307e-01,  1.2318e-03],
        [ 9.0845e-02, -2.6820e-01,  3.3304e-03],
        [ 9.1834e-02, -3.0504e-01,  2.0531e-03],
        [ 9.1604e-02, -2.3676e-01,  1.4875e-03],
        [ 9.2730e-02, -3.1000e-01,  2.4592e-03],
        [ 9.2412e-02, -3.1498e-01,  3.2552e-03],
        [ 9.3007e-02, -3.2982e-01,  2.8965e-03],
        [ 8.7309e-02, -1.2195e-01,  1.1337e-02],
        [ 8.7913e-02, -1.7431e-01,  1.2889e-02],
        [ 9.6275e-02, -3.1581e-01,  1.8690e-03],
        [ 9.7559e-02, -3.8860e-01,  5.1603e-04],
        [ 9.9015e-02, -3.9354e-01,  6.4582e-05],
        [ 9.8430e-02, -3.5687e-01,  7.6187e-04],
        [ 9.2346e-02, -2.6743e-02,  4.7601e-03],
        [ 8.4387e-02, -2.4056e-01,  3.7412e-02],
        [ 9.0884e-02, -2.8595e-01,  6.6656e-03],
        [ 8.9758e-02, -2.5911e-01,  1.2384e-02],
        [ 9.0460e-02, -3.1824e-01,  9.4640e-03],
        [ 8.4090e-02,  7.3747e-02,  2.0601e-02],
        [ 9.0876e-02, -2.9608e-01,  1.2760e-02],
        [ 8.4306e-02, -1.9913e-01,  1.9265e-02],
        [ 9.1847e-02, -2.7717e-01,  8.2283e-03],
        [ 8.6043e-02, -1.8256e-01,  1.7862e-02],
        [ 7.8514e-02, -2.7686e-01,  4.6150e-02],
        [ 7.6826e-02, -2.3350e-02,  3.4133e-02],
        [ 7.5911e-02,  4.3976e-02,  4.3440e-02],
        [ 7.0530e-02, -1.9198e-01,  1.3015e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 14
Episode Length = 78
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1512,  1.1372,  1.1252,  1.1226,  1.1249, -6.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1655,  1.1629,  1.1664,  1.1683,  1.1669,  1.1624,
         1.1606, -4.0000,  0.0000,  0.0000,  0.1511,  1.1523,  1.1507,  1.1574,
         1.1582,  1.1376,  1.1212,  1.1343,  1.1318, -4.0000,  0.0000,  0.0000,
         0.1574,  1.1435,  1.1462,  1.1368,  1.1325,  1.1355,  1.1220,  1.0000],
       device='cuda:0')
target_q_episode tensor([-0.1183, -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600,
        -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  4.0779,  3.2399,  2.3578,
         1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,
         0.0000,  6.0333,  5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000],
       device='cuda:0')
target_q tensor([ 1.0570,  0.9653,  0.8714,  0.7819,  0.6922, -6.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1532,  1.2517,  1.1859,  1.1151,  1.0374,  0.9528,
         0.8665, -4.0000,  0.0000,  0.0000,  0.1399,  1.3696,  1.3059,  1.2466,
         1.1784,  1.0867,  0.9950,  0.9268,  0.8398, -4.0000,  0.0000,  0.0000,
         0.1457,  1.5067,  1.4546,  1.3884,  1.3239,  1.2630,  1.1835,  1.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.5611e-02, -2.5648e-01,  9.0227e-04],
        [ 9.4232e-02, -2.0913e-01,  1.5752e-03],
        [ 9.6477e-02, -2.6829e-01,  7.8142e-04],
        [ 9.6432e-02, -3.3155e-01,  4.6143e-04],
        [ 9.7602e-02, -3.5866e-01,  1.5941e-04],
        [ 9.8214e-02, -3.5493e-01,  1.0952e-04],
        [ 9.8147e-02, -3.3240e-01,  1.0517e-04],
        [ 9.8770e-02, -3.5327e-01,  6.6161e-05],
        [ 9.8433e-02, -3.4793e-01,  8.5711e-05],
        [ 9.8813e-02, -3.5739e-01,  5.0366e-05],
        [ 9.8536e-02, -3.2487e-01,  7.9274e-05],
        [ 9.8774e-02, -3.5701e-01,  6.6012e-05],
        [ 9.8611e-02, -3.2078e-01,  8.5473e-05],
        [ 9.9136e-02, -3.6503e-01,  4.5836e-05],
        [ 9.9336e-02, -3.6894e-01,  2.1011e-05],
        [ 9.9442e-02, -3.7966e-01,  1.0908e-05],
        [ 9.8977e-02, -3.4271e-01,  3.9309e-05],
        [ 9.8166e-02, -2.8833e-01,  1.5688e-04],
        [ 9.8234e-02, -2.8471e-01,  1.1894e-04],
        [ 9.8353e-02, -3.2754e-01,  1.4830e-04],
        [ 9.8261e-02, -3.2303e-01,  1.5590e-04],
        [ 9.9026e-02, -3.6735e-01,  5.0396e-05],
        [ 9.8690e-02, -3.5534e-01,  8.2463e-05],
        [ 9.8385e-02, -3.6397e-01,  9.7543e-05],
        [ 9.7916e-02, -3.1969e-01,  2.0289e-04],
        [ 9.6438e-02, -3.2369e-01,  1.1089e-03],
        [ 9.9029e-02, -3.7832e-01,  1.3039e-04],
        [ 9.8426e-02, -3.7518e-01,  2.2319e-04],
        [ 9.7750e-02, -3.6187e-01,  5.4139e-04],
        [ 9.6607e-02, -3.0938e-01,  1.0641e-03],
        [ 9.6263e-02, -3.4156e-01,  9.6023e-04],
        [ 9.3909e-02, -3.7460e-01,  1.6747e-03],
        [ 9.6622e-02, -3.4067e-01,  1.8398e-03],
        [ 8.3129e-02, -1.2728e-01,  3.8433e-02],
        [ 7.5425e-02, -9.7777e-02,  7.9165e-02],
        [ 7.2018e-02, -5.1559e-02,  1.0579e-01],
        [ 6.7711e-02, -9.2837e-02,  1.1777e-01],
        [ 6.4793e-02, -7.5815e-02,  1.8676e-01],
        [ 9.4030e-02, -2.6277e-01,  1.6425e-03],
        [ 8.7219e-02, -1.3214e-01,  5.5565e-03],
        [ 9.4190e-02, -3.0441e-01,  9.6619e-04],
        [ 8.9745e-02, -3.2866e-01,  3.0040e-03],
        [ 8.3751e-02, -2.8681e-01,  9.8563e-03],
        [ 8.0074e-02, -2.4054e-01,  1.3521e-02],
        [ 8.5368e-02, -3.2456e-01,  7.8439e-03],
        [ 8.7233e-02, -3.2208e-01,  7.5170e-03],
        [ 9.8551e-02, -3.2387e-01,  9.2179e-05],
        [ 9.5335e-02, -8.2416e-02,  1.5816e-03],
        [ 9.5302e-02, -1.1480e-01,  2.3706e-03],
        [ 9.6434e-02, -1.7153e-01,  7.2718e-04],
        [ 9.1631e-02,  1.1026e-01,  3.7487e-03],
        [ 9.4608e-02, -8.4323e-02,  1.0602e-03],
        [ 9.7622e-02, -2.4226e-02,  3.2073e-04],
        [ 9.0979e-02,  2.9346e-02,  4.6495e-03],
        [ 8.9253e-02, -3.1297e-03,  7.1526e-03],
        [ 9.6089e-02, -1.9270e-01,  1.2067e-03],
        [ 9.8899e-02, -2.4484e-01,  1.4365e-04],
        [ 9.5399e-02, -1.8911e-01,  1.2450e-03],
        [ 9.8910e-02, -3.6729e-01,  3.3528e-05],
        [ 9.8285e-02, -3.4067e-01,  1.6272e-04],
        [ 9.9162e-02, -3.7918e-01,  4.7803e-05],
        [ 9.8236e-02, -3.4072e-01,  1.3611e-04],
        [ 9.7607e-02, -2.2675e-01,  2.5719e-04],
        [ 9.7884e-02, -3.3488e-01,  3.0217e-04],
        [ 9.8320e-02, -3.3448e-01,  4.1941e-04],
        [ 9.8390e-02, -3.6998e-01,  5.1427e-04],
        [ 9.8080e-02, -3.5288e-01,  3.9649e-04],
        [ 9.8536e-02, -3.8619e-01,  4.5645e-04],
        [ 9.5451e-02, -3.2530e-01,  1.4162e-03],
        [ 9.8805e-02, -3.9383e-01,  2.9179e-04],
        [ 9.9382e-02, -3.9815e-01,  1.2812e-04],
        [ 9.4883e-02, -3.5720e-01,  2.4470e-03],
        [ 9.1816e-02, -3.5036e-01,  8.7872e-03],
        [ 9.0191e-02, -3.5601e-01,  7.3531e-03],
        [ 8.9627e-02, -3.5057e-01,  7.2263e-03],
        [ 8.8102e-02, -3.3136e-01,  1.2797e-02],
        [ 9.2143e-02, -3.6313e-01,  7.1719e-03],
        [ 8.6577e-02, -3.4030e-01,  1.1066e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 15
Episode Length = 99
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1359,  1.1155,  1.1229,  1.1274,  1.1294,  1.1231,  1.1332,  1.1539,
        -9.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1417,  1.1465,  1.1612,  1.1397,  1.1246,  1.1380,  1.1513,  1.1433,
         1.1415,  1.1432,  1.1436,  1.1389,  1.1363,  1.1310,  1.1375,  1.1416,
         1.1379,  1.1438,  1.1405,  1.1395,  1.1359,  1.1340,  1.1371,  1.1133,
         1.1127,  1.1149, -8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1137,  1.1102,  1.1211,  1.1213, -4.0000,  0.0000,  0.0000,
         0.0000], device='cuda:0')
target_q_episode tensor([ 0.7608, -0.2518, -1.3177, -2.4396, -3.6207, -4.8639, -6.1725, -7.5500,
        -9.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000, 12.2331, 11.8243, 11.3940, 10.9411, 10.4643,  9.9624,  9.4341,
         8.8780,  8.2926,  7.6765,  7.0278,  6.3451,  5.6264,  4.8699,  4.0736,
         3.2354,  2.3530,  1.4242,  0.4466, -0.5826, -1.6659, -2.8062, -4.0065,
        -5.2700, -6.6000, -8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,
         0.0000], device='cuda:0')
target_q tensor([ 1.1131,  1.0323,  0.9745,  0.9105,  0.8406,  0.7590,  0.6889,  0.6247,
        -9.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1331,  1.8206,  1.8097,  1.7633,  1.7216,  1.7051,  1.6871,  1.6475,
         1.6119,  1.5779,  1.5409,  1.4970,  1.4531,  1.4043,  1.3644,  1.3199,
         1.2654,  1.2173,  1.1578,  1.0974,  1.0314,  0.9637,  0.8973,  0.8020,
         0.7246,  0.6457, -8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1067,  1.0076,  0.9520,  0.8828, -4.0000,  0.0000,  0.0000,
         0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.5166e-02, -8.2688e-02,  1.2369e-02],
        [ 8.4410e-02, -1.8810e-01,  4.4673e-03],
        [ 8.5704e-02, -1.6141e-01,  3.5246e-03],
        [ 7.4258e-02, -1.2190e-02,  1.8423e-02],
        [ 8.2115e-02, -6.8402e-02,  8.3570e-03],
        [ 8.5161e-02, -1.9041e-01,  5.0820e-03],
        [ 8.5559e-02, -1.5620e-01,  6.7004e-03],
        [ 8.8296e-02, -1.4680e-01,  3.6061e-03],
        [ 7.2591e-02,  7.0746e-02,  2.3823e-02],
        [ 7.0144e-02,  1.0178e-01,  3.7181e-02],
        [ 7.8471e-02,  1.4480e-01,  1.9186e-02],
        [ 7.5836e-02,  1.1862e-01,  1.4748e-02],
        [ 8.1668e-02,  1.1119e-01,  8.7613e-03],
        [ 8.0460e-02,  1.2215e-01,  9.4859e-03],
        [ 8.1848e-02,  6.1913e-02,  8.3677e-03],
        [ 8.5222e-02,  1.3827e-01,  5.1579e-03],
        [ 8.9023e-02,  3.4200e-02,  2.9431e-03],
        [ 8.8312e-02,  5.2138e-02,  4.2665e-03],
        [ 9.1914e-02, -1.4166e-01,  1.3326e-03],
        [ 9.1519e-02, -2.6189e-02,  1.9292e-03],
        [ 8.7397e-02, -7.1013e-02,  7.3612e-03],
        [ 8.8981e-02, -6.0413e-02,  3.5767e-03],
        [ 9.3035e-02, -2.6347e-01,  1.9045e-03],
        [ 9.1997e-02, -1.6223e-01,  6.1843e-03],
        [ 8.4426e-02, -1.5230e-01,  1.1011e-02],
        [ 8.9525e-02, -2.0114e-01,  5.4998e-03],
        [ 9.1479e-02, -2.9783e-01,  1.2194e-03],
        [ 9.6569e-02, -2.0264e-01,  3.3790e-04],
        [ 9.6152e-02, -3.6822e-01,  7.9560e-04],
        [ 9.5047e-02, -3.7818e-01,  1.1053e-03],
        [ 8.6180e-02, -5.9724e-02,  1.2844e-02],
        [ 8.0377e-02,  4.6205e-04,  2.0160e-02],
        [ 8.4482e-02, -1.7873e-01,  2.3851e-02],
        [ 9.6478e-02, -3.7642e-01,  6.3634e-04],
        [ 9.4786e-02, -3.6194e-01,  1.9805e-03],
        [ 9.6567e-02, -3.6933e-01,  1.1986e-03],
        [ 9.3536e-02, -3.4465e-01,  3.3671e-03],
        [ 8.9062e-02, -1.6588e-01,  1.8334e-02],
        [ 8.6777e-02, -2.6709e-02,  1.2238e-02],
        [ 7.9386e-02, -9.2845e-02,  3.6940e-02],
        [ 6.6664e-02, -1.2023e-01,  7.3113e-02],
        [ 4.6565e-02,  2.5508e-02,  3.5984e-01],
        [ 5.8992e-02,  6.6939e-02,  6.6384e-02],
        [ 5.5506e-02,  1.2751e-01,  5.3776e-02],
        [ 9.2378e-02, -3.0631e-01,  3.0146e-03],
        [ 9.3266e-02, -3.6525e-01,  1.0332e-03],
        [ 9.2676e-02, -3.6035e-01,  1.6585e-03],
        [ 9.1869e-02, -3.4677e-01,  1.6489e-03],
        [ 9.3647e-02, -2.8838e-01,  1.6488e-03],
        [ 9.2725e-02, -2.9478e-01,  2.9756e-03],
        [ 6.9748e-02, -1.3188e-02,  3.6584e-02],
        [ 7.5182e-02, -8.7113e-02,  2.6752e-02],
        [ 8.9324e-02, -3.0273e-01,  2.6780e-03],
        [ 8.4931e-02,  8.1255e-03,  6.4726e-03],
        [ 9.5905e-02, -3.3542e-01,  4.9964e-04],
        [ 8.3996e-02, -3.1931e-01,  4.7023e-03],
        [ 9.5735e-02, -3.7597e-01,  5.1558e-04],
        [ 9.0536e-02, -2.9313e-01,  2.3872e-03],
        [ 9.2158e-02, -3.4961e-01,  1.8697e-03],
        [ 9.4210e-02, -3.4196e-01,  2.7925e-03],
        [ 8.7269e-02,  2.2738e-02,  6.5171e-03],
        [ 9.4279e-02, -2.0075e-01,  1.1847e-03],
        [ 8.9150e-02, -6.6434e-02,  6.5151e-03],
        [ 9.3614e-02, -2.5390e-01,  4.6905e-03],
        [ 8.6260e-02,  5.5201e-02,  7.8611e-03],
        [ 9.0755e-02, -4.5577e-02,  4.5035e-03],
        [ 8.6466e-02, -1.4880e-01,  1.1330e-02],
        [ 9.1618e-02, -2.5316e-01,  6.6087e-03],
        [ 8.9927e-02, -2.3976e-01,  4.1371e-03],
        [ 9.2112e-02, -2.6979e-01,  4.6676e-03],
        [ 8.5827e-02, -1.9092e-01,  1.0831e-02],
        [ 7.6023e-02, -6.8676e-02,  1.7473e-02],
        [ 8.1873e-02, -2.2385e-01,  1.9411e-02],
        [ 8.1342e-02, -2.0973e-01,  1.7594e-02],
        [ 8.3198e-02, -2.1902e-01,  1.5506e-02],
        [ 7.9320e-02, -1.0845e-01,  1.4124e-02],
        [ 9.1425e-02, -2.5423e-01,  5.8059e-03],
        [ 9.5255e-02, -3.2666e-01,  2.8075e-03],
        [ 9.6239e-02, -3.7102e-01,  9.9400e-04],
        [ 9.7273e-02, -3.8011e-01,  1.1741e-03],
        [ 9.3518e-02, -3.8553e-01,  1.5596e-03],
        [ 9.0751e-02, -3.2707e-01,  9.5199e-03],
        [ 7.9133e-02,  3.2955e-02,  2.9844e-02],
        [ 7.6940e-02, -2.1608e-01,  3.7672e-02],
        [ 9.5301e-02, -3.3136e-01,  2.4329e-03],
        [ 9.7078e-02, -3.6758e-01,  1.6038e-03],
        [ 8.9498e-02, -2.6427e-01,  1.0029e-02],
        [ 8.4974e-02, -2.2854e-01,  2.8016e-02],
        [ 8.1872e-02, -1.4595e-01,  3.8445e-02],
        [ 9.2561e-02, -3.4677e-01,  2.3877e-03],
        [ 9.0023e-02, -3.0956e-01,  3.0223e-03],
        [ 9.1396e-02, -2.1337e-01,  6.1873e-03],
        [ 7.2683e-02,  9.6061e-02,  6.8643e-02],
        [ 7.5203e-02, -2.0485e-01,  4.7405e-02],
        [ 6.9200e-02, -1.8305e-01,  8.1482e-02],
        [ 8.3389e-02, -2.9510e-01,  1.3998e-02],
        [ 8.0966e-02, -2.3515e-01,  2.8328e-02],
        [ 6.7831e-02, -2.5562e-01,  9.8965e-02],
        [ 7.0239e-02, -1.5042e-01,  6.2197e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 16
Episode Length = 83
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1333,   1.1369,   1.1376,   1.1441,   1.1399,   1.1414,   1.1344,
        -10.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.1081,   1.1046,   1.1175,   1.1188,   1.1215,
          1.1215,   1.1217,   1.1315,   1.1316,   1.1346,   1.1303,   1.1315,
          1.1402,   1.1304,   1.1320,   1.1302,   1.1287,   1.1325,   1.1351,
          1.1259,   1.1285,   1.1171,   1.1113,  -6.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000], device='cuda:0')
target_q_episode tensor([ -0.9501,  -2.0528,  -3.2134,  -4.4352,  -5.7213,  -7.0750,  -8.5000,
        -10.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,  11.5881,  11.1454,  10.6794,  10.1888,
          9.6724,   9.1289,   8.5567,   7.9544,   7.3205,   6.6531,   5.9506,
          5.2112,   4.4328,   3.6135,   2.7511,   1.8432,   0.8876,  -0.1183,
         -1.1772,  -2.2917,  -3.4650,  -4.7000,  -6.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000], device='cuda:0')
target_q tensor([  1.0296,   0.9781,   0.9210,   0.8663,   0.7983,   0.7323,   0.6547,
        -10.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.1027,   1.6265,   1.6167,   1.5948,   1.5729,
          1.5472,   1.5204,   1.5012,   1.4712,   1.4426,   1.4053,   1.3714,
          1.3429,   1.2949,   1.2555,   1.2109,   1.1643,   1.1203,   1.0727,
          1.0113,   0.9582,   0.8889,   0.8220,  -6.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.2396e-02, -3.1354e-02,  2.0071e-03],
        [ 9.2151e-02, -7.3634e-02,  2.8827e-03],
        [ 9.1964e-02, -7.5153e-03,  2.8648e-03],
        [ 9.3265e-02, -1.6213e-01,  1.3526e-03],
        [ 9.7728e-02, -2.3648e-01,  1.5658e-04],
        [ 9.7813e-02, -2.8883e-01,  1.6174e-04],
        [ 9.8265e-02, -2.6758e-01,  6.8605e-05],
        [ 9.9013e-02, -2.7950e-01,  2.3514e-05],
        [ 9.8738e-02, -1.8449e-01,  4.3660e-05],
        [ 9.7770e-02, -1.5079e-01,  1.6001e-04],
        [ 9.7916e-02, -8.7678e-02,  1.3226e-04],
        [ 9.8575e-02, -2.9190e-01,  7.7665e-05],
        [ 9.9293e-02, -2.8910e-01,  1.3590e-05],
        [ 9.8472e-02, -2.4439e-01,  8.1062e-05],
        [ 9.8896e-02, -2.0566e-01,  4.3899e-05],
        [ 9.8641e-02, -1.8173e-01,  6.8814e-05],
        [ 9.8821e-02, -1.9922e-01,  6.0797e-05],
        [ 9.8579e-02, -1.8321e-01,  9.3400e-05],
        [ 9.7478e-02, -1.9288e-01,  2.0677e-04],
        [ 9.7401e-02, -8.3233e-02,  2.3064e-04],
        [ 9.6844e-02, -1.7507e-01,  4.0427e-04],
        [ 9.7853e-02, -1.9670e-01,  1.5965e-04],
        [ 9.8833e-02, -3.0308e-01,  5.8204e-05],
        [ 9.7673e-02, -1.6569e-01,  3.3113e-04],
        [ 9.7214e-02, -1.7105e-01,  3.2946e-04],
        [ 9.4997e-02, -1.9424e-01,  1.2472e-03],
        [ 9.7014e-02, -1.8635e-01,  3.5155e-04],
        [ 9.7998e-02, -2.6057e-01,  4.3038e-04],
        [ 9.7516e-02, -3.2870e-01,  5.1636e-04],
        [ 9.7996e-02, -3.3938e-01,  3.5900e-04],
        [ 9.4235e-02, -1.1673e-01,  2.1920e-03],
        [ 9.0163e-02, -2.4144e-01,  5.7457e-03],
        [ 9.3733e-02, -1.4862e-01,  5.9196e-03],
        [ 7.5835e-02, -1.5680e-03,  5.8819e-02],
        [ 7.1334e-02,  6.8957e-02,  9.0571e-02],
        [ 6.5867e-02,  4.4498e-02,  1.2151e-01],
        [ 6.2932e-02, -1.5544e-02,  1.5470e-01],
        [ 5.4889e-02,  2.5047e-03,  2.8941e-01],
        [ 8.8630e-02, -8.8950e-02,  3.9144e-03],
        [ 9.3863e-02, -2.5179e-01,  9.8628e-04],
        [ 9.4981e-02, -2.2409e-01,  6.9833e-04],
        [ 9.5985e-02, -2.1275e-01,  4.8396e-04],
        [ 9.2019e-02,  8.3576e-02,  4.1071e-03],
        [ 9.5542e-02,  1.1506e-01,  1.7267e-03],
        [ 9.0102e-02,  1.8442e-01,  6.5005e-03],
        [ 9.1620e-02,  1.2221e-02,  3.4989e-03],
        [ 9.3577e-02,  3.6433e-02,  3.0163e-03],
        [ 9.2880e-02,  1.2226e-01,  3.1714e-03],
        [ 9.0712e-02, -2.3031e-01,  5.2835e-03],
        [ 8.9498e-02, -9.1065e-02,  7.1915e-03],
        [ 8.5585e-02, -9.7819e-02,  1.2174e-02],
        [ 9.0540e-02, -2.4140e-01,  5.2837e-03],
        [ 8.2230e-02, -1.3301e-01,  8.2837e-03],
        [ 9.2388e-02, -2.3780e-02,  2.2500e-03],
        [ 9.3418e-02,  1.5184e-01,  1.5809e-03],
        [ 8.9577e-02, -1.9586e-01,  7.3736e-03],
        [ 7.4535e-02, -6.2331e-02,  4.2796e-02],
        [ 6.6575e-02,  3.3455e-02,  7.6312e-02],
        [ 6.6875e-02, -3.2283e-02,  6.2100e-02],
        [ 6.8479e-02,  5.0148e-02,  6.8763e-02],
        [ 7.3683e-02, -6.7279e-02,  5.8406e-02],
        [ 8.3902e-02, -2.1316e-01,  1.7900e-02],
        [ 8.9431e-02, -2.7747e-01,  7.5025e-03],
        [ 9.2978e-02, -3.3397e-02,  3.1532e-03],
        [ 9.2953e-02,  1.1755e-01,  1.9231e-03],
        [ 9.3545e-02, -1.0485e-02,  1.6727e-03],
        [ 9.5538e-02,  2.8554e-03,  7.8604e-04],
        [ 8.8925e-02, -9.6415e-03,  5.3016e-03],
        [ 9.7528e-02, -3.3014e-01,  5.0306e-04],
        [ 9.5458e-02, -2.1401e-01,  9.3031e-04],
        [ 9.8072e-02, -3.6290e-01,  1.0934e-03],
        [ 9.7737e-02, -3.6660e-01,  3.8210e-04],
        [ 9.7361e-02, -3.7570e-01,  3.8606e-04],
        [ 9.3496e-02, -2.8187e-01,  3.9521e-03],
        [ 8.6685e-02, -1.6105e-01,  1.7042e-02],
        [ 8.1796e-02, -2.1328e-01,  1.4191e-02],
        [ 9.1653e-02, -3.4350e-01,  3.3681e-03],
        [ 8.9848e-02, -3.3593e-01,  6.3525e-03],
        [ 7.7452e-02, -2.1855e-01,  3.5315e-02],
        [ 8.8249e-02, -1.8468e-01,  1.2400e-02],
        [ 8.2194e-02, -1.0044e-01,  2.5661e-02],
        [ 8.7355e-02, -2.9845e-01,  1.0722e-02],
        [ 8.8869e-02, -1.0561e-01,  1.0255e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 17
Episode Length = 97
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1252,   1.1207,   1.1157,   1.1215,   1.1295,   1.1378,   1.1256,
          1.1184,   1.1221,   1.1273,   1.1350,   1.1319,   1.1280,   1.1261,
          1.1237,   1.1281,   1.1296,   1.1303,   1.1394,   1.1358,   1.1301,
          1.1238,   1.1218,   1.1298,   1.1414,   1.1262,   1.1104,   1.1209,
          1.1280,   1.1228,   1.1212,   1.1204, -10.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1131,
          1.1217,   1.1260,   1.1340,   1.1356,   1.1220,   1.1070,  -7.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
       device='cuda:0')
target_q_episode tensor([ 14.1887,  13.8828,  13.5608,  13.2219,  12.8652,  12.4897,  12.0944,
         11.6783,  11.2403,  10.7793,  10.2940,   9.7832,   9.2454,   8.6794,
          8.0836,   7.4564,   6.7962,   6.1013,   5.3698,   4.5997,   3.7892,
          2.9360,   2.0379,   1.0925,   0.0974,  -0.9501,  -2.0528,  -3.2134,
         -4.4352,  -5.7213,  -7.0750,  -8.5000, -10.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.1525,  -0.8921,  -1.9917,  -3.1491,  -4.3675,  -5.6500,  -7.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
       device='cuda:0')
target_q tensor([  1.6577,   1.6409,   1.6229,   1.6148,   1.6079,   1.6005,   1.5727,
          1.5488,   1.5345,   1.5207,   1.5084,   1.4845,   1.4589,   1.4340,
          1.4074,   1.3861,   1.3606,   1.3329,   1.3118,   1.2770,   1.2385,
          1.1976,   1.1592,   1.1283,   1.0988,   1.0415,   0.9815,   0.9442,
          0.9012,   0.8439,   0.7871,   0.7282, -10.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1085,
          1.0822,   1.0437,   1.0065,   0.9610,   0.8982,   0.8316,  -7.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 0.0624,  0.0461,  0.0475],
        [ 0.0691,  0.0678,  0.0392],
        [ 0.0846, -0.1162,  0.0054],
        [ 0.0909, -0.1893,  0.0012],
        [ 0.0914, -0.1330,  0.0015],
        [ 0.0791,  0.0707,  0.0132],
        [ 0.0788,  0.0756,  0.0080],
        [ 0.0866, -0.0069,  0.0046],
        [ 0.0851,  0.0040,  0.0053],
        [ 0.0861,  0.1337,  0.0048],
        [ 0.0852,  0.2120,  0.0077],
        [ 0.0820,  0.0559,  0.0092],
        [ 0.0827,  0.2448,  0.0076],
        [ 0.0796,  0.1257,  0.0088],
        [ 0.0841,  0.1760,  0.0058],
        [ 0.0868,  0.0950,  0.0035],
        [ 0.0874,  0.1724,  0.0028],
        [ 0.0900,  0.0440,  0.0020],
        [ 0.0913,  0.0335,  0.0018],
        [ 0.0886,  0.2291,  0.0034],
        [ 0.0875,  0.0314,  0.0068],
        [ 0.0923,  0.0213,  0.0018],
        [ 0.0881, -0.0572,  0.0045],
        [ 0.0923,  0.0468,  0.0019],
        [ 0.0890,  0.0874,  0.0056],
        [ 0.0890, -0.0275,  0.0042],
        [ 0.0882,  0.0514,  0.0061],
        [ 0.0871,  0.1174,  0.0087],
        [ 0.0891,  0.0268,  0.0048],
        [ 0.0892, -0.0401,  0.0056],
        [ 0.0852,  0.0311,  0.0082],
        [ 0.0876,  0.0235,  0.0062],
        [ 0.0858,  0.0689,  0.0128],
        [ 0.0874,  0.0291,  0.0093],
        [ 0.0776,  0.0874,  0.0295],
        [ 0.0843,  0.0052,  0.0294],
        [ 0.0831,  0.0343,  0.0220],
        [ 0.0780,  0.0386,  0.0475],
        [ 0.0778,  0.0343,  0.0639],
        [ 0.0661,  0.0336,  0.1248],
        [ 0.0588,  0.0568,  0.1837],
        [ 0.0479,  0.0600,  0.2824],
        [ 0.0667,  0.1093,  0.0321],
        [ 0.0541,  0.1691,  0.0711],
        [ 0.0751,  0.1135,  0.0134],
        [ 0.0754,  0.1049,  0.0147],
        [ 0.0862,  0.0642,  0.0063],
        [ 0.0808, -0.0183,  0.0111],
        [ 0.0759,  0.1737,  0.0235],
        [ 0.0806, -0.0209,  0.0074],
        [ 0.0722,  0.0689,  0.0172],
        [ 0.0667,  0.0488,  0.0443],
        [ 0.0813,  0.0841,  0.0095],
        [ 0.0743,  0.0466,  0.0189],
        [ 0.0747,  0.1008,  0.0260],
        [ 0.0720,  0.1414,  0.0286],
        [ 0.0778,  0.1447,  0.0142],
        [ 0.0836,  0.1698,  0.0069],
        [ 0.0803,  0.2353,  0.0125],
        [ 0.0815,  0.1214,  0.0153],
        [ 0.0834,  0.2321,  0.0072],
        [ 0.0859,  0.2733,  0.0049],
        [ 0.0868,  0.0787,  0.0049],
        [ 0.0861,  0.0551,  0.0063],
        [ 0.0769,  0.1350,  0.0127],
        [ 0.0830,  0.2547,  0.0108],
        [ 0.0853,  0.1756,  0.0071],
        [ 0.0903,  0.0322,  0.0028],
        [ 0.0949,  0.0216,  0.0020],
        [ 0.0893,  0.1834,  0.0075],
        [ 0.0881, -0.0275,  0.0042],
        [ 0.0936, -0.0386,  0.0008],
        [ 0.0838,  0.0323,  0.0094],
        [ 0.0764,  0.2030,  0.0295],
        [ 0.0850,  0.3564,  0.0126],
        [ 0.0836,  0.3639,  0.0175],
        [ 0.0831,  0.2815,  0.0253],
        [ 0.0864, -0.0555,  0.0065],
        [ 0.0886,  0.0428,  0.0088],
        [ 0.0915, -0.3396,  0.0038],
        [ 0.0850, -0.2097,  0.0157],
        [ 0.0756, -0.1495,  0.0329],
        [ 0.0856, -0.3172,  0.0081],
        [ 0.0729,  0.0956,  0.0512],
        [ 0.0740,  0.0717,  0.0528],
        [ 0.0797, -0.0536,  0.0253],
        [ 0.0817,  0.0109,  0.0282],
        [ 0.0711,  0.0646,  0.0665],
        [ 0.0622,  0.1291,  0.0977],
        [ 0.0724,  0.1690,  0.0458],
        [ 0.0823,  0.3637,  0.0104],
        [ 0.0684,  0.0995,  0.0715],
        [ 0.0814,  0.0056,  0.0173],
        [ 0.0890, -0.3087,  0.0192],
        [ 0.0946, -0.3223,  0.0029],
        [ 0.0838, -0.2328,  0.0347],
        [ 0.0877, -0.0091,  0.0151]], device='cuda:0', grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 18
Episode Length = 87
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1186,  1.1180,  1.1178,  1.1220,  1.1216, -4.0000,  0.0000,  0.0000,
         0.1064,  1.1054,  1.1037,  1.1058,  1.1059,  1.1135,  1.1238,  1.1222,
         1.1188,  1.1175,  1.1165,  1.1157,  1.1175,  1.1186,  1.1140,  1.1107,
         1.1073,  1.1164, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1283,
         1.1205,  1.1124,  1.1211,  1.1177,  1.1140,  1.1255,  1.1218,  1.1223,
         1.1132,  1.1097,  1.1088,  1.1173,  1.1298,  1.1169,  1.1196,  1.1229,
         1.0000], device='cuda:0')
target_q_episode tensor([ 1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,
         0.0000,  9.1289,  8.5567,  7.9544,  7.3204,  6.6531,  5.9506,  5.2112,
         4.4328,  3.6135,  2.7511,  1.8432,  0.8876, -0.1183, -1.1772, -2.2917,
        -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        11.6376, 11.1975, 10.7342, 10.2465,  9.7332,  9.1928,  8.6240,  8.0253,
         7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,  2.8525,  1.9500,
         1.0000], device='cuda:0')
target_q tensor([ 1.1289,  1.0958,  1.0612,  1.0292,  0.9907, -4.0000,  0.0000,  0.0000,
         0.1028,  1.3732,  1.3524,  1.3343,  1.3133,  1.2984,  1.2848,  1.2586,
         1.2294,  1.2008,  1.1710,  1.1400,  1.1099,  1.0773,  1.0376,  0.9971,
         0.9547,  0.9223, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1240,
         1.4715,  1.4489,  1.4419,  1.4223,  1.4016,  1.3947,  1.3721,  1.3527,
         1.3228,  1.2974,  1.2732,  1.2568,  1.2431,  1.2034,  1.1775,  1.1505,
         1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.6092e-02,  2.3541e-01,  6.1651e-03],
        [ 8.9317e-02,  1.6670e-01,  3.8987e-03],
        [ 9.0173e-02,  1.4978e-01,  3.3244e-03],
        [ 9.2629e-02, -1.1700e-02,  1.6063e-03],
        [ 9.4591e-02,  3.0744e-02,  5.9009e-04],
        [ 9.3168e-02, -6.2225e-02,  1.1605e-03],
        [ 9.7766e-02, -4.0074e-02,  1.9306e-04],
        [ 9.6485e-02,  8.5337e-02,  2.5451e-04],
        [ 9.5650e-02,  1.9322e-01,  5.7393e-04],
        [ 9.5803e-02,  5.8360e-02,  3.9771e-04],
        [ 9.6700e-02,  2.0931e-01,  4.2015e-04],
        [ 9.6753e-02,  1.0194e-01,  2.8360e-04],
        [ 9.6240e-02,  1.0878e-01,  3.0941e-04],
        [ 9.7522e-02,  7.1466e-02,  1.5238e-04],
        [ 9.5775e-02,  1.5928e-01,  5.6380e-04],
        [ 9.7652e-02,  2.3193e-01,  2.2832e-04],
        [ 9.8126e-02,  1.9276e-01,  7.3314e-05],
        [ 9.5258e-02,  1.8966e-01,  6.5547e-04],
        [ 9.6727e-02,  1.6645e-01,  4.0162e-04],
        [ 9.4369e-02,  2.6002e-01,  1.0249e-03],
        [ 9.6719e-02,  8.6038e-02,  5.1427e-04],
        [ 9.8054e-02, -1.1373e-01,  2.0018e-04],
        [ 9.8282e-02,  1.0661e-01,  1.5748e-04],
        [ 9.6974e-02,  1.4421e-01,  3.1990e-04],
        [ 9.5233e-02,  3.5280e-02,  1.1168e-03],
        [ 9.3319e-02,  2.0053e-01,  1.6168e-03],
        [ 9.7073e-02,  7.4592e-02,  4.7672e-04],
        [ 9.6659e-02,  1.1360e-01,  6.9270e-04],
        [ 9.7710e-02, -1.3919e-01,  7.2706e-04],
        [ 9.5477e-02, -8.6173e-02,  1.7892e-03],
        [ 8.7859e-02,  6.3987e-02,  7.1272e-03],
        [ 9.0886e-02, -2.1421e-01,  3.4083e-03],
        [ 9.3058e-02, -1.0505e-01,  5.9934e-03],
        [ 7.4926e-02,  1.2516e-01,  5.0196e-02],
        [ 6.7882e-02,  1.2850e-01,  1.0119e-01],
        [ 6.0503e-02,  1.7006e-01,  1.6203e-01],
        [ 5.0890e-02,  6.6784e-02,  2.9864e-01],
        [ 4.0243e-02,  1.1501e-01,  3.7775e-01],
        [ 8.4989e-02,  5.1340e-02,  5.5265e-03],
        [ 9.3236e-02,  9.1650e-03,  6.4713e-04],
        [ 8.9766e-02,  1.6078e-01,  2.7278e-03],
        [ 9.4150e-02, -1.0029e-01,  8.8054e-04],
        [ 9.5189e-02, -1.4690e-02,  5.3030e-04],
        [ 9.6257e-02,  2.8096e-02,  4.6921e-04],
        [ 9.7737e-02, -5.9465e-02,  2.2590e-04],
        [ 9.4426e-02,  3.5180e-02,  1.2709e-03],
        [ 7.9290e-02, -4.9456e-02,  1.3852e-02],
        [ 8.8167e-02, -1.2322e-01,  5.4819e-03],
        [ 7.8696e-02,  4.0891e-02,  1.7343e-02],
        [ 7.7879e-02, -4.8045e-02,  2.2355e-02],
        [ 7.8749e-02, -3.8111e-02,  2.3027e-02],
        [ 6.7570e-02,  6.6294e-02,  4.4463e-02],
        [ 8.2379e-02, -6.3184e-02,  1.9461e-02],
        [ 8.4797e-02,  2.2406e-01,  1.0697e-02],
        [ 9.5859e-02,  2.2758e-01,  3.2234e-04],
        [ 8.6856e-02,  3.0588e-01,  4.3195e-03],
        [ 9.7155e-02,  2.6248e-01,  2.6280e-04],
        [ 9.3031e-02,  2.0735e-01,  1.6565e-03],
        [ 8.9416e-02,  2.6539e-01,  4.0892e-03],
        [ 8.9355e-02,  2.2950e-01,  5.1182e-03],
        [ 9.0363e-02,  8.1233e-02,  3.9339e-03],
        [ 8.6391e-02,  2.4397e-01,  8.0615e-03],
        [ 8.9895e-02,  2.0404e-01,  5.9437e-03],
        [ 8.4213e-02,  3.7583e-02,  1.2513e-02],
        [ 8.7851e-02, -2.8438e-02,  9.7268e-03],
        [ 9.0213e-02,  1.3729e-01,  3.0969e-03],
        [ 9.1745e-02,  2.7930e-01,  2.3651e-03],
        [ 9.2274e-02,  4.0213e-02,  2.3620e-03],
        [ 9.2114e-02,  1.9165e-01,  2.0873e-03],
        [ 9.4355e-02,  4.1247e-03,  9.4366e-04],
        [ 8.9930e-02,  3.8987e-03,  6.1342e-03],
        [ 9.1422e-02, -2.2460e-02,  5.6021e-03],
        [ 9.7146e-02, -1.4597e-01,  5.8520e-04],
        [ 9.6982e-02, -2.7328e-01,  6.7896e-04],
        [ 9.8350e-02, -1.9916e-01,  2.3794e-04],
        [ 9.5826e-02, -3.2952e-01,  1.3312e-03],
        [ 9.1565e-02, -1.0725e-01,  5.2966e-03],
        [ 8.8930e-02, -1.9259e-01,  7.5860e-03],
        [ 8.8243e-02, -2.6308e-01,  4.2940e-03],
        [ 7.4489e-02, -7.3632e-02,  6.0622e-02],
        [ 7.5757e-02, -1.3863e-01,  3.1754e-02],
        [ 8.1649e-02, -1.3095e-01,  1.2535e-02],
        [ 8.3999e-02,  1.0771e-01,  2.3343e-02],
        [ 8.7977e-02,  8.8831e-02,  4.6500e-03],
        [ 6.6054e-02,  8.8333e-02,  8.2709e-02],
        [ 7.0738e-02,  2.2324e-01,  5.6054e-02],
        [ 6.2009e-02,  1.5411e-01,  7.8196e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 19
Episode Length = 89
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1219,  1.1205,  1.1156,  1.1153,  1.1197,  1.1193,  1.1153,  1.1143,
         1.1183,  1.1192,  1.1239,  1.1239,  1.1229,  1.1171, -4.0000,  0.0000,
         0.0000,  0.1123,  1.1186,  1.1155,  1.1197,  1.1181,  1.1184,  1.1252,
         1.1231,  1.1288,  1.1248,  1.1085,  1.1089,  1.1196,  1.1295,  1.1251,
         1.1221,  1.1229,  1.1222,  1.1173, -3.0000,  0.0000,  0.0933,  1.1112,
         1.1220,  1.1156,  1.1190, -4.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q_episode tensor([ 8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000, 10.8641, 10.3832,  9.8771,  9.3443,  8.7835,  8.1931,
         7.5717,  6.9176,  6.2291,  5.5043,  4.7413,  3.9382,  3.0929,  2.2030,
         1.2664,  0.2804, -0.7575, -1.8500, -3.0000,  0.0000,  0.0000,  0.4519,
        -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q tensor([ 1.3180,  1.2998,  1.2772,  1.2583,  1.2429,  1.2219,  1.1962,  1.1724,
         1.1522,  1.1277,  1.1056,  1.0774,  1.0468,  1.0101, -4.0000,  0.0000,
         0.0000,  0.1092,  1.3849,  1.3687,  1.3590,  1.3429,  1.3278,  1.3184,
         1.2993,  1.2870,  1.2643,  1.2286,  1.2081,  1.1966,  1.1831,  1.1545,
         1.1261,  1.0999,  1.0709,  1.0362, -3.0000,  0.0000,  0.0907,  1.0932,
         1.0755,  1.0398,  1.0119, -4.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 0.0732,  0.1514,  0.0122],
        [ 0.0775,  0.0893,  0.0063],
        [ 0.0887,  0.1148,  0.0025],
        [ 0.0749,  0.1293,  0.0192],
        [ 0.0728,  0.1844,  0.0176],
        [ 0.0754,  0.1653,  0.0174],
        [ 0.0763,  0.1742,  0.0202],
        [ 0.0863,  0.0246,  0.0059],
        [ 0.0683,  0.2573,  0.0365],
        [ 0.0586,  0.1963,  0.0900],
        [ 0.0777,  0.2727,  0.0141],
        [ 0.0693,  0.2721,  0.0273],
        [ 0.0730,  0.2876,  0.0195],
        [ 0.0713,  0.2947,  0.0210],
        [ 0.0809,  0.3211,  0.0062],
        [ 0.0780,  0.3142,  0.0128],
        [ 0.0780,  0.3032,  0.0130],
        [ 0.0842,  0.1875,  0.0056],
        [ 0.0862,  0.2515,  0.0050],
        [ 0.0814,  0.2168,  0.0091],
        [ 0.0895,  0.2090,  0.0031],
        [ 0.0889,  0.2020,  0.0036],
        [ 0.0834,  0.2320,  0.0076],
        [ 0.0861,  0.2059,  0.0143],
        [ 0.0869,  0.0584,  0.0056],
        [ 0.0895,  0.0657,  0.0047],
        [ 0.0911, -0.0195,  0.0016],
        [ 0.0948,  0.1539,  0.0009],
        [ 0.0951, -0.1093,  0.0014],
        [ 0.0966, -0.3379,  0.0007],
        [ 0.0799,  0.2232,  0.0300],
        [ 0.0695,  0.2371,  0.0410],
        [ 0.0673,  0.1822,  0.0735],
        [ 0.0931, -0.2608,  0.0020],
        [ 0.0957, -0.3152,  0.0012],
        [ 0.0966, -0.3424,  0.0012],
        [ 0.0937, -0.2921,  0.0027],
        [ 0.0872,  0.0227,  0.0154],
        [ 0.0770,  0.2048,  0.0357],
        [ 0.0654,  0.0262,  0.0996],
        [ 0.0448,  0.1423,  0.1908],
        [ 0.0212,  0.1373,  0.5724],
        [ 0.0560,  0.2503,  0.0556],
        [ 0.0609,  0.1936,  0.0477],
        [ 0.0467,  0.1117,  0.1320],
        [ 0.0574,  0.1787,  0.0942],
        [ 0.0378,  0.2150,  0.1931],
        [ 0.0419,  0.1553,  0.1700],
        [ 0.0611,  0.1147,  0.0625],
        [ 0.0665,  0.1263,  0.0498],
        [ 0.0465,  0.1267,  0.1450],
        [ 0.0496,  0.2134,  0.1119],
        [ 0.0638,  0.2010,  0.0382],
        [ 0.0772,  0.0734,  0.0199],
        [ 0.0801, -0.0054,  0.0066],
        [ 0.0633,  0.2424,  0.0356],
        [ 0.0776,  0.1135,  0.0156],
        [ 0.0800,  0.2218,  0.0201],
        [ 0.0726,  0.0826,  0.0361],
        [ 0.0900,  0.0644,  0.0034],
        [ 0.0733,  0.2752,  0.0203],
        [ 0.0805,  0.2229,  0.0111],
        [ 0.0815,  0.2064,  0.0141],
        [ 0.0824,  0.1926,  0.0134],
        [ 0.0814,  0.0969,  0.0186],
        [ 0.0860,  0.0525,  0.0096],
        [ 0.0868,  0.1720,  0.0055],
        [ 0.0854,  0.1501,  0.0098],
        [ 0.0825,  0.1193,  0.0172],
        [ 0.0830,  0.2307,  0.0115],
        [ 0.0863,  0.1897,  0.0033],
        [ 0.0792,  0.0833,  0.0130],
        [ 0.0797,  0.1721,  0.0195],
        [ 0.0875,  0.1438,  0.0046],
        [ 0.0878,  0.1373,  0.0057],
        [ 0.0948, -0.1586,  0.0014],
        [ 0.0933,  0.0425,  0.0020],
        [ 0.0920, -0.1907,  0.0045],
        [ 0.0945, -0.3371,  0.0025],
        [ 0.0804, -0.1378,  0.0334],
        [ 0.0620,  0.0850,  0.1383],
        [ 0.0861, -0.2517,  0.0077],
        [ 0.0930, -0.2217,  0.0034],
        [ 0.0882, -0.2274,  0.0081],
        [ 0.0638,  0.0885,  0.1454],
        [ 0.0680,  0.2454,  0.0768],
        [ 0.0715,  0.2560,  0.0619],
        [ 0.0656,  0.2193,  0.0666],
        [ 0.0410,  0.0344,  0.2305]], device='cuda:0', grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 20
Episode Length = 85
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1115,  1.1137,  1.1070,  1.1010,  1.1039,  1.1060,  1.1056,  1.1098,
         1.1073,  1.1117,  1.1058,  1.1056, -5.0000,  0.0000,  0.0000,  0.0000,
         0.1094,  1.1050,  1.1114,  1.1124,  1.1122,  1.1148,  1.1154,  1.1146,
        -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1249,  1.1160,  1.1154,
         1.1139,  1.1080,  1.1120,  1.1138,  1.1167,  1.1186,  1.1159,  1.1139,
         1.1133,  1.1189,  1.1283, -4.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q_episode tensor([ 6.4910,  5.7800,  5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555,
        -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  1.8432,  0.8876, -0.1183, -1.1772, -2.2917, -3.4650, -4.7000,
        -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  7.6798,  7.0314,
         6.3488,  5.6303,  4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4518,
        -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q tensor([ 1.2318,  1.2180,  1.1948,  1.1713,  1.1556,  1.1381,  1.1172,  1.0996,
         1.0744,  1.0548,  1.0237,  0.9970, -5.0000,  0.0000,  0.0000,  0.0000,
         0.1069,  1.1215,  1.1064,  1.0849,  1.0610,  1.0386,  1.0129,  0.9845,
        -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1221,  1.2628,  1.2478,
         1.2310,  1.2092,  1.1962,  1.1801,  1.1642,  1.1463,  1.1229,  1.0991,
         1.0755,  1.0567,  1.0404, -4.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.0182e-02,  2.0098e-01,  1.4568e-02],
        [ 8.5828e-02,  2.9828e-01,  7.6379e-03],
        [ 8.5992e-02,  3.0180e-01,  7.9519e-03],
        [ 9.0176e-02,  1.7995e-01,  2.4885e-03],
        [ 9.0090e-02,  2.1406e-01,  1.6658e-03],
        [ 9.4578e-02,  2.3106e-01,  6.1145e-04],
        [ 9.4791e-02,  2.0883e-01,  6.0040e-04],
        [ 9.5555e-02,  2.6945e-01,  4.0653e-04],
        [ 9.5218e-02,  3.0005e-01,  6.5845e-04],
        [ 9.6506e-02,  2.5159e-01,  3.4297e-04],
        [ 9.5504e-02,  3.0484e-01,  5.3734e-04],
        [ 9.6210e-02,  2.6356e-01,  5.8225e-04],
        [ 9.6300e-02,  2.8213e-01,  3.7414e-04],
        [ 9.6795e-02,  2.4760e-01,  3.0097e-04],
        [ 9.7486e-02,  2.4474e-01,  2.3144e-04],
        [ 9.5826e-02,  2.9962e-01,  4.3404e-04],
        [ 9.6923e-02,  2.7526e-01,  2.3511e-04],
        [ 9.6062e-02,  3.1484e-01,  5.8636e-04],
        [ 9.6176e-02,  2.0055e-01,  8.1179e-04],
        [ 9.6734e-02,  1.7348e-01,  4.0713e-04],
        [ 9.4622e-02,  2.1675e-01,  1.8221e-03],
        [ 9.6511e-02,  1.0840e-01,  5.4455e-04],
        [ 9.7243e-02,  8.8549e-03,  3.5721e-04],
        [ 9.7020e-02, -1.0842e-01,  4.3562e-04],
        [ 9.7108e-02, -7.1347e-02,  3.9294e-04],
        [ 9.5548e-02,  1.3969e-01,  1.2394e-03],
        [ 9.8097e-02,  2.2812e-01,  3.2160e-04],
        [ 9.6115e-02,  2.1510e-01,  9.7969e-04],
        [ 9.6702e-02,  2.3513e-01,  7.2718e-04],
        [ 9.6282e-02,  7.0164e-02,  9.2456e-04],
        [ 9.4493e-02,  8.2579e-02,  2.3666e-03],
        [ 8.8026e-02, -6.5434e-03,  6.3160e-03],
        [ 8.3951e-02,  2.6893e-01,  2.6986e-02],
        [ 7.2058e-02,  1.7789e-01,  7.1747e-02],
        [ 5.6294e-02,  1.3449e-01,  2.2830e-01],
        [ 5.1930e-02,  1.8401e-01,  2.5591e-01],
        [ 3.6758e-02,  1.2516e-01,  3.8360e-01],
        [ 3.8216e-02,  1.6398e-01,  3.9316e-01],
        [ 7.3621e-02,  2.0703e-01,  1.8644e-02],
        [ 8.3262e-02,  2.5720e-01,  5.3944e-03],
        [ 8.6817e-02,  1.6621e-01,  4.9942e-03],
        [ 9.1242e-02,  2.3976e-01,  2.1094e-03],
        [ 7.1947e-02,  1.4914e-01,  2.5742e-02],
        [ 7.6404e-02,  7.4950e-02,  2.3824e-02],
        [ 7.1781e-02,  1.7725e-01,  2.6267e-02],
        [ 7.4634e-02,  1.4444e-01,  2.3653e-02],
        [ 5.7457e-02,  2.3921e-01,  6.8934e-02],
        [ 7.4947e-02,  1.9773e-01,  1.6572e-02],
        [ 6.7704e-02,  2.4731e-01,  4.0404e-02],
        [ 7.2090e-02,  2.7110e-01,  3.5345e-02],
        [ 7.4334e-02,  2.0338e-01,  2.1302e-02],
        [ 6.5935e-02,  2.2696e-01,  3.2196e-02],
        [ 7.6141e-02,  2.7358e-01,  2.4420e-02],
        [ 7.3529e-02,  2.8314e-01,  3.2588e-02],
        [ 7.3985e-02,  2.3398e-01,  3.9804e-02],
        [ 7.9963e-02,  2.4799e-01,  2.3367e-02],
        [ 7.3392e-02,  3.0794e-01,  4.3563e-02],
        [ 7.5394e-02,  2.8865e-01,  3.6620e-02],
        [ 8.9200e-02,  2.1858e-01,  4.1855e-03],
        [ 8.8075e-02,  3.2313e-01,  5.0972e-03],
        [ 9.5089e-02,  1.5030e-01,  5.8872e-04],
        [ 9.4222e-02,  3.7305e-01,  6.1542e-04],
        [ 9.2761e-02,  3.6059e-01,  1.7531e-03],
        [ 8.9696e-02,  2.6314e-01,  5.0812e-03],
        [ 8.8729e-02,  2.5335e-01,  2.5505e-03],
        [ 8.9168e-02,  3.1512e-01,  3.0159e-03],
        [ 9.0739e-02,  3.1082e-01,  3.4863e-03],
        [ 9.5121e-02,  2.3218e-02,  1.2144e-03],
        [ 9.0587e-02,  3.4197e-01,  4.0291e-03],
        [ 9.6338e-02,  1.3102e-03,  1.0890e-03],
        [ 9.5130e-02,  1.5434e-01,  1.0558e-03],
        [ 9.3813e-02,  1.9998e-01,  1.8390e-03],
        [ 9.4850e-02,  1.4277e-01,  1.6929e-03],
        [ 9.8901e-02, -3.1923e-01,  1.6153e-04],
        [ 9.2876e-02,  4.6513e-02,  3.1695e-03],
        [ 8.5729e-02,  1.7539e-01,  1.0670e-02],
        [ 8.3986e-02,  1.0772e-01,  9.5188e-03],
        [ 8.5126e-02, -8.2994e-02,  1.1493e-02],
        [ 8.4404e-02,  1.4167e-01,  1.2189e-02],
        [ 7.6919e-02,  1.0698e-01,  2.3609e-02],
        [ 6.7497e-02,  1.6928e-01,  9.6486e-02],
        [ 7.5021e-02,  1.1151e-01,  4.1485e-02],
        [ 7.9660e-02,  5.6730e-02,  2.1793e-02],
        [ 7.2851e-02,  1.3118e-01,  2.8519e-02],
        [ 7.6956e-02,  1.5725e-01,  1.2891e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Saving checkpoint
Run No. 21
Episode Length = 101
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1182,  1.1096,  1.1108,  1.1135,  1.1153,  1.1128,  1.1130,  1.1122,
         1.1148,  1.1123,  1.1159,  1.1128,  1.1154,  1.1154,  1.1123,  1.1084,
         1.1172,  1.1201,  1.1106,  1.1054,  1.1144,  1.1167,  1.1199,  1.1168,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1097,  1.1156,  1.1078,  1.1052,
         1.1025,  1.1071,  1.1061,  1.1014,  1.0997,  1.1047,  1.1050,  1.1018,
        -9.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1084,  1.1097,  1.1067,  1.1087,  1.1091,  1.1105, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([12.7003, 12.3161, 11.9117, 11.4860, 11.0379, 10.5662, 10.0696,  9.5470,
         8.9968,  8.4177,  7.8081,  7.1664,  6.4910,  5.7800,  5.0316,  4.2438,
         3.4145,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.5048,  2.6366,  1.7228,
         0.7608, -0.2518, -1.3177, -2.4396, -3.6207, -4.8639, -6.1725, -7.5500,
        -9.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.3303,  1.3149,  1.3086,  1.3034,  1.2970,  1.2859,  1.2771,  1.2667,
         1.2592,  1.2461,  1.2384,  1.2237,  1.2139,  1.2009,  1.1841,  1.1658,
         1.1593,  1.1462,  1.1200,  1.0971,  1.0874,  1.0700,  1.0524,  1.0276,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1077,  1.1594,  1.1358,  1.1166,
         1.0963,  1.0822,  1.0617,  1.0365,  1.0133,  0.9954,  0.9717,  0.9433,
        -9.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1064,  1.1014,  1.0798,  1.0621,  1.0419,  1.0215, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 5.5441e-02,  1.7460e-01,  7.7082e-02],
        [ 7.2351e-02,  2.4446e-01,  2.5701e-02],
        [ 8.4034e-02,  3.9903e-02,  5.7784e-03],
        [ 7.9297e-02,  1.8735e-01,  8.5272e-03],
        [ 8.1661e-02,  1.4751e-01,  7.5518e-03],
        [ 7.1609e-02,  1.8346e-01,  2.5766e-02],
        [ 6.9696e-02,  3.0629e-01,  2.4964e-02],
        [ 7.3180e-02,  1.7627e-01,  2.1840e-02],
        [ 7.2997e-02,  2.2243e-01,  2.7214e-02],
        [ 7.7229e-02,  2.4422e-01,  1.4941e-02],
        [ 7.9043e-02,  2.4475e-01,  1.0143e-02],
        [ 7.2186e-02,  2.6649e-01,  2.2846e-02],
        [ 7.4897e-02,  3.1784e-01,  1.5275e-02],
        [ 8.3832e-02,  3.0500e-01,  5.0721e-03],
        [ 8.0462e-02,  2.8183e-01,  9.6194e-03],
        [ 8.8463e-02,  2.8588e-01,  2.4815e-03],
        [ 8.8598e-02,  2.8058e-01,  2.1518e-03],
        [ 8.9119e-02,  2.8983e-01,  2.8375e-03],
        [ 8.7024e-02,  2.8118e-01,  4.9102e-03],
        [ 8.7699e-02,  2.1452e-01,  3.9867e-03],
        [ 8.8385e-02,  2.6451e-01,  4.0959e-03],
        [ 8.4630e-02,  2.4714e-01,  8.0229e-03],
        [ 8.3744e-02,  2.5905e-01,  8.2632e-03],
        [ 8.7919e-02,  1.8508e-01,  4.5848e-03],
        [ 8.5517e-02,  2.2410e-01,  7.8160e-03],
        [ 8.8381e-02,  2.5316e-01,  3.2119e-03],
        [ 8.5818e-02,  1.5004e-01,  7.4538e-03],
        [ 8.6460e-02,  2.4525e-01,  8.3012e-03],
        [ 8.4977e-02,  1.8204e-01,  8.9323e-03],
        [ 8.4700e-02,  1.9171e-01,  9.8543e-03],
        [ 8.6202e-02,  2.9294e-01,  5.5360e-03],
        [ 8.0929e-02,  2.8124e-01,  1.2346e-02],
        [ 8.2945e-02,  2.2303e-01,  1.5033e-02],
        [ 8.0392e-02,  2.8474e-01,  1.9655e-02],
        [ 7.7785e-02,  2.7906e-01,  2.5561e-02],
        [ 8.4005e-02,  2.8611e-01,  2.1778e-02],
        [ 7.5479e-02,  2.5252e-01,  4.4099e-02],
        [ 7.4545e-02,  2.3042e-01,  5.6134e-02],
        [ 6.7524e-02,  2.4032e-01,  7.5137e-02],
        [ 5.9406e-02,  2.2714e-01,  1.1506e-01],
        [ 4.0743e-02,  2.1829e-01,  2.4755e-01],
        [ 3.8583e-02,  1.3335e-01,  3.4183e-01],
        [ 6.4632e-02,  1.7556e-01,  4.0349e-02],
        [ 6.3480e-02,  1.6959e-01,  4.2728e-02],
        [ 7.0518e-02,  1.8424e-01,  2.5192e-02],
        [ 6.0794e-02,  3.0022e-01,  4.3308e-02],
        [ 7.9027e-02,  2.1532e-01,  8.8149e-03],
        [ 7.8692e-02,  1.9130e-01,  9.3288e-03],
        [ 6.4827e-02,  2.9979e-01,  2.5995e-02],
        [ 6.8904e-02,  3.1938e-01,  1.4224e-02],
        [ 7.7657e-02,  2.6519e-01,  1.2719e-02],
        [ 7.7647e-02,  2.5424e-01,  9.7300e-03],
        [ 7.9750e-02,  2.7013e-01,  8.4697e-03],
        [ 7.6057e-02,  2.4606e-01,  9.4995e-03],
        [ 6.0631e-02,  2.4794e-01,  4.7957e-02],
        [ 7.2096e-02,  2.6837e-01,  2.3406e-02],
        [ 6.5865e-02,  2.7261e-01,  3.2861e-02],
        [ 6.8845e-02,  2.9334e-01,  3.7475e-02],
        [ 7.8276e-02,  3.0945e-01,  1.7133e-02],
        [ 7.4338e-02,  3.3948e-01,  2.3536e-02],
        [ 7.1648e-02,  3.3129e-01,  2.2707e-02],
        [ 7.7642e-02,  3.4101e-01,  1.1940e-02],
        [ 7.6136e-02,  3.1828e-01,  1.2411e-02],
        [ 8.0284e-02,  3.2978e-01,  1.8222e-02],
        [ 8.6378e-02,  3.7667e-01,  5.5836e-03],
        [ 7.4214e-02,  3.3451e-01,  3.1089e-02],
        [ 8.4849e-02,  1.6539e-01,  5.4060e-03],
        [ 7.4352e-02,  1.7617e-01,  1.6437e-02],
        [ 8.0560e-02,  2.6448e-01,  1.0107e-02],
        [ 9.0732e-02,  3.1495e-01,  4.3096e-03],
        [ 9.2398e-02,  1.9515e-01,  2.4188e-03],
        [ 9.4989e-02,  2.1100e-01,  1.1170e-03],
        [ 9.7100e-02, -2.0451e-02,  5.2077e-04],
        [ 9.2978e-02,  1.0338e-01,  1.8807e-03],
        [ 9.1961e-02, -2.5393e-02,  4.1834e-03],
        [ 8.7623e-02,  5.2369e-02,  6.1458e-03],
        [ 8.8263e-02,  2.7291e-01,  6.6198e-03],
        [ 9.2503e-02,  1.9261e-02,  5.9625e-03],
        [ 9.4197e-02, -3.3949e-02,  2.9549e-03],
        [ 9.3470e-02,  1.0630e-01,  1.8289e-03],
        [ 9.4972e-02,  2.3414e-01,  1.3402e-03],
        [ 9.5376e-02,  9.2392e-02,  1.9031e-03],
        [ 9.7016e-02, -5.5272e-02,  5.0440e-04],
        [ 9.7130e-02,  2.0776e-01,  6.5050e-04],
        [ 9.7793e-02,  2.1848e-01,  3.1132e-04],
        [ 9.8379e-02, -1.4103e-01,  3.6240e-04],
        [ 9.5954e-02,  1.9232e-01,  1.7662e-03],
        [ 8.4249e-02,  2.1767e-01,  1.8750e-02],
        [ 8.4844e-02,  3.7918e-01,  1.0912e-02],
        [ 7.3970e-02,  1.8456e-01,  5.8120e-02],
        [ 6.1018e-02,  1.0036e-01,  1.2228e-01],
        [ 7.1999e-02,  5.9415e-02,  5.5702e-02],
        [ 5.8355e-02,  2.1562e-02,  8.4241e-02],
        [ 6.6512e-02, -8.9380e-03,  8.4676e-02],
        [ 6.7130e-02,  1.7344e-01,  6.2306e-02],
        [ 6.6103e-02,  1.0822e-01,  7.6449e-02],
        [ 7.3638e-02,  1.5580e-01,  5.0338e-02],
        [ 6.2243e-02,  1.7612e-01,  7.6404e-02],
        [ 8.0432e-02,  1.3808e-01,  3.1340e-02],
        [ 7.4916e-02,  3.7807e-01,  2.8366e-02],
        [ 4.9593e-02,  1.1645e-01,  2.8361e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 22
Episode Length = 76
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1178,  1.1147,  1.1171, -5.0000,  0.0000,  0.0000,  0.0000,  0.1144,
         1.1198,  1.1139,  1.1159,  1.1209,  1.1088,  1.1115,  1.1057,  1.1022,
         1.1045,  1.1169,  1.1214,  1.1186,  1.1131,  1.1028,  1.1131,  1.1099,
         1.1144,  1.1163,  1.1094,  1.1158,  1.1114,  1.1117,  1.1172,  1.1182,
         1.1166,  1.1174,  1.1133,  1.1146,  1.1186,  1.0000], device='cuda:0')
target_q_episode tensor([-1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        15.7072, 15.4813, 15.2435, 14.9931, 14.7296, 14.4522, 14.1602, 13.8529,
        13.5293, 13.1888, 12.8303, 12.4529, 12.0557, 11.6376, 11.1975, 10.7342,
        10.2465,  9.7332,  9.1928,  8.6240,  8.0253,  7.3950,  6.7316,  6.0333,
         5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.0795,  1.0596,  1.0441, -5.0000,  0.0000,  0.0000,  0.0000,  0.1127,
         1.3386,  1.3294,  1.3278,  1.3289,  1.3130,  1.3116,  1.3015,  1.2934,
         1.2908,  1.2980,  1.2970,  1.2885,  1.2772,  1.2608,  1.2643,  1.2542,
         1.2513,  1.2456,  1.2306,  1.2284,  1.2151,  1.2059,  1.2014,  1.1919,
         1.1793,  1.1685,  1.1522,  1.1407,  1.1311,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.7344e-02,  2.5329e-01,  4.3431e-03],
        [ 8.3509e-02,  3.1189e-01,  9.2866e-03],
        [ 9.0001e-02,  2.8556e-01,  5.0215e-03],
        [ 8.8508e-02,  2.4310e-01,  5.1386e-03],
        [ 9.2542e-02,  2.6792e-01,  1.2847e-03],
        [ 9.1506e-02,  2.4654e-01,  1.9158e-03],
        [ 9.5950e-02,  1.6713e-01,  5.4994e-04],
        [ 9.4805e-02,  2.6908e-01,  5.6595e-04],
        [ 9.4863e-02,  1.5588e-01,  7.3460e-04],
        [ 9.4763e-02,  2.8139e-01,  9.7442e-04],
        [ 9.6476e-02,  3.2321e-01,  3.7867e-04],
        [ 9.6724e-02,  2.8917e-01,  3.7435e-04],
        [ 9.5071e-02,  2.7269e-01,  1.0152e-03],
        [ 9.6739e-02,  2.8931e-01,  3.3012e-04],
        [ 9.4954e-02,  2.4140e-01,  6.9383e-04],
        [ 9.7152e-02,  2.0235e-01,  2.8795e-04],
        [ 9.6189e-02,  2.9566e-01,  7.0524e-04],
        [ 9.6456e-02,  1.6966e-01,  6.1670e-04],
        [ 9.5830e-02,  1.8230e-01,  7.2885e-04],
        [ 9.6342e-02,  1.1267e-01,  4.5946e-04],
        [ 9.6662e-02,  2.6733e-03,  6.7863e-04],
        [ 9.7318e-02, -7.2864e-02,  3.1587e-04],
        [ 9.8478e-02, -1.6297e-01,  1.0055e-04],
        [ 9.8434e-02, -2.4859e-01,  1.7157e-04],
        [ 9.7312e-02, -1.9637e-01,  7.5969e-04],
        [ 8.9817e-02,  2.3017e-01,  7.0791e-03],
        [ 9.7361e-02,  2.8723e-01,  3.4627e-04],
        [ 9.6875e-02,  1.7627e-01,  5.7656e-04],
        [ 9.6975e-02,  1.9048e-01,  1.2820e-03],
        [ 9.3774e-02,  1.2623e-01,  3.2976e-03],
        [ 9.3576e-02,  2.0983e-02,  4.8591e-03],
        [ 8.6724e-02,  6.1510e-02,  9.7824e-03],
        [ 7.6577e-02,  2.2429e-01,  5.5563e-02],
        [ 7.3278e-02,  2.6505e-01,  5.3614e-02],
        [ 5.3825e-02,  1.7194e-01,  1.9318e-01],
        [ 4.9139e-02,  1.8791e-01,  2.6029e-01],
        [ 4.9116e-02,  1.4136e-01,  2.2004e-01],
        [ 2.6747e-02,  1.3456e-01,  5.0601e-01],
        [ 7.8532e-02,  2.6346e-01,  1.1966e-02],
        [ 8.4236e-02,  2.4255e-01,  9.7627e-03],
        [ 8.1852e-02,  3.3369e-01,  1.1812e-02],
        [ 8.4018e-02,  3.1845e-01,  7.7983e-03],
        [ 7.6587e-02,  3.1980e-01,  1.5432e-02],
        [ 8.7675e-02,  3.5549e-01,  7.1547e-03],
        [ 9.2482e-02,  2.6266e-01,  1.9456e-03],
        [ 8.1518e-02,  1.8424e-01,  6.1670e-03],
        [ 8.1159e-02,  1.8662e-01,  1.8112e-02],
        [ 9.3565e-02,  2.4343e-01,  1.6905e-03],
        [ 9.2752e-02,  3.6470e-01,  2.4329e-03],
        [ 9.0478e-02,  3.7321e-01,  4.1601e-03],
        [ 8.9199e-02,  3.2724e-01,  3.2890e-03],
        [ 8.5601e-02,  3.3580e-01,  8.6025e-03],
        [ 7.7224e-02,  3.0263e-01,  2.2580e-02],
        [ 7.6959e-02,  3.1073e-01,  1.3301e-02],
        [ 8.8000e-02,  3.2564e-01,  6.1387e-03],
        [ 9.2768e-02,  3.8288e-01,  2.7697e-03],
        [ 9.7558e-02,  1.0054e-01,  2.9492e-04],
        [ 9.1112e-02,  3.4322e-01,  5.1668e-03],
        [ 8.7747e-02,  3.1459e-01,  5.2230e-03],
        [ 9.2398e-02,  1.8849e-01,  3.6130e-03],
        [ 9.5488e-02,  7.6213e-02,  1.4767e-03],
        [ 9.2718e-02,  9.9668e-02,  1.3805e-03],
        [ 9.5623e-02,  1.6835e-01,  1.1425e-03],
        [ 9.4910e-02,  1.9409e-01,  1.1427e-03],
        [ 9.6209e-02,  2.3264e-01,  9.2104e-04],
        [ 9.6535e-02,  1.9258e-01,  8.4153e-04],
        [ 8.8575e-02,  2.6859e-01,  6.6209e-03],
        [ 9.4389e-02,  1.1679e-01,  3.9567e-03],
        [ 9.5177e-02,  7.6773e-02,  2.1712e-03],
        [ 9.4316e-02, -2.1019e-02,  1.5922e-03],
        [ 9.3918e-02,  1.9221e-02,  2.1102e-03],
        [ 8.3975e-02, -3.0747e-02,  1.9959e-02],
        [ 8.4516e-02, -1.4310e-01,  1.4812e-02],
        [ 6.9115e-02, -5.2222e-02,  5.2390e-02],
        [ 6.0147e-02,  2.3984e-01,  9.1504e-02],
        [ 6.0568e-02,  2.4633e-01,  9.4432e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 23
Episode Length = 96
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1081,  1.1016,  1.1062,  1.1113,  1.1080, -8.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1214,  1.1130,  1.1117,  1.1038,
         1.1110,  1.1129,  1.1145,  1.1221,  1.1188,  1.1052,  1.1106,  1.1137,
         1.1220,  1.1203,  1.1225,  1.1186,  1.1220,  1.1174,  1.1097,  1.1069,
        -3.0000,  0.0000,  0.1244,  1.1147,  1.1189,  1.1024,  1.1048,  1.1095,
         1.1086,  1.1062,  1.1135,  1.1151,  1.1181,  1.1144, -8.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([-1.6659, -2.8062, -4.0065, -5.2700, -6.6000, -8.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 11.3209, 10.8641, 10.3832,
         9.8771,  9.3443,  8.7835,  8.1931,  7.5717,  6.9176,  6.2291,  5.5043,
         4.7413,  3.9382,  3.0929,  2.2030,  1.2664,  0.2804, -0.7575, -1.8500,
        -3.0000,  0.0000,  0.0000,  4.0736,  3.2354,  2.3530,  1.4242,  0.4466,
        -0.5826, -1.6659, -2.8062, -4.0065, -5.2700, -6.6000, -8.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.0741,  1.0536,  1.0435,  1.0330,  1.0134, -8.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1199,  1.2383,  1.2314,  1.2178,
         1.2187,  1.2139,  1.2086,  1.2089,  1.1980,  1.1766,  1.1735,  1.1676,
         1.1665,  1.1549,  1.1467,  1.1319,  1.1238,  1.1071,  1.0868,  1.0706,
        -3.0000,  0.0000,  0.1229,  1.1510,  1.1449,  1.1178,  1.1087,  1.1014,
         1.0878,  1.0722,  1.0654,  1.0523,  1.0397,  1.0197, -8.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 6.6507e-02,  1.2947e-01,  2.7057e-02],
        [ 7.3256e-02,  1.1493e-01,  1.6796e-02],
        [ 8.3456e-02,  1.1653e-01,  7.7730e-03],
        [ 7.2601e-02,  5.1497e-02,  3.4819e-02],
        [ 7.8897e-02,  6.6814e-02,  1.4678e-02],
        [ 8.3206e-02,  1.0787e-01,  9.2527e-03],
        [ 7.6653e-02,  1.3194e-01,  1.5921e-02],
        [ 8.4852e-02,  7.0560e-02,  4.5228e-03],
        [ 7.4876e-02,  2.3329e-01,  2.1271e-02],
        [ 7.5737e-02,  2.2002e-01,  1.8070e-02],
        [ 6.9029e-02,  2.3138e-01,  3.0145e-02],
        [ 6.9829e-02,  2.5676e-01,  2.5704e-02],
        [ 7.8807e-02,  2.9789e-01,  8.6687e-03],
        [ 7.8869e-02,  3.0958e-01,  7.9890e-03],
        [ 8.2126e-02,  3.2347e-01,  6.7946e-03],
        [ 8.7217e-02,  3.3154e-01,  4.2173e-03],
        [ 8.8766e-02,  3.2836e-01,  2.3031e-03],
        [ 9.1154e-02,  3.0230e-01,  2.2984e-03],
        [ 9.2094e-02,  2.8158e-01,  1.9002e-03],
        [ 8.8755e-02,  2.8595e-01,  3.5646e-03],
        [ 9.2517e-02,  3.0999e-01,  1.6652e-03],
        [ 9.1560e-02,  1.4667e-01,  1.4331e-03],
        [ 8.3695e-02,  2.6031e-01,  1.0338e-02],
        [ 8.5382e-02,  2.6385e-01,  1.2253e-02],
        [ 7.8013e-02,  1.6476e-01,  1.8013e-02],
        [ 8.9263e-02,  8.0707e-02,  8.1868e-03],
        [ 9.2014e-02, -6.9658e-03,  1.1852e-03],
        [ 9.2901e-02,  1.6766e-01,  2.6827e-03],
        [ 9.4249e-02, -1.0421e-01,  3.1475e-03],
        [ 9.7465e-02, -3.6199e-01,  4.3279e-04],
        [ 7.7083e-02,  2.0519e-01,  4.1273e-02],
        [ 6.7295e-02,  2.4309e-01,  5.4497e-02],
        [ 5.9948e-02,  1.8028e-01,  1.1826e-01],
        [ 9.6942e-02, -3.0467e-01,  3.4714e-04],
        [ 9.3567e-02, -2.2958e-01,  2.3790e-03],
        [ 9.5238e-02, -2.1920e-01,  1.3867e-03],
        [ 9.1146e-02, -1.0679e-01,  6.1575e-03],
        [ 8.3619e-02,  1.4610e-01,  2.4101e-02],
        [ 7.7239e-02,  2.5257e-01,  2.9580e-02],
        [ 6.2656e-02,  1.7059e-01,  1.2045e-01],
        [ 4.8483e-02,  6.1762e-02,  1.4709e-01],
        [ 1.2231e-02,  1.0155e-01,  6.9606e-01],
        [ 6.7769e-02,  6.9090e-02,  3.3866e-02],
        [ 6.4808e-02,  1.6431e-01,  4.7739e-02],
        [ 8.2378e-02,  3.7233e-02,  1.2685e-02],
        [ 6.5731e-02, -8.8671e-03,  4.2249e-02],
        [ 6.3502e-02,  2.0668e-01,  5.5886e-02],
        [ 6.8987e-02,  5.0649e-02,  4.9343e-02],
        [ 6.0206e-02,  8.0031e-02,  6.8481e-02],
        [ 7.8963e-02, -3.1947e-02,  1.1120e-02],
        [ 9.4026e-02, -2.0072e-01,  2.1703e-03],
        [ 7.8184e-02, -1.1604e-02,  1.2255e-02],
        [ 8.2644e-02,  3.8593e-02,  1.2461e-02],
        [ 9.1761e-02, -5.9652e-02,  3.5212e-03],
        [ 9.1087e-02,  6.1595e-02,  2.4543e-03],
        [ 8.6627e-02,  2.5319e-01,  7.7929e-03],
        [ 8.2036e-02,  3.3387e-01,  1.0075e-02],
        [ 7.9748e-02,  3.0525e-01,  9.7244e-03],
        [ 8.1851e-02,  3.2702e-01,  8.1758e-03],
        [ 8.7177e-02,  2.5492e-01,  6.9648e-03],
        [ 8.4723e-02,  6.0920e-02,  9.5099e-03],
        [ 9.1072e-02,  8.8582e-03,  4.9548e-03],
        [ 8.2734e-02,  3.0238e-01,  1.1698e-02],
        [ 8.6255e-02,  2.7437e-01,  5.0984e-03],
        [ 8.2821e-02,  2.9316e-01,  8.5490e-03],
        [ 9.1180e-02,  3.0808e-01,  1.8613e-03],
        [ 8.8135e-02,  2.6694e-01,  5.2763e-03],
        [ 9.1724e-02,  1.8650e-01,  1.9905e-03],
        [ 8.3908e-02,  2.6759e-01,  2.5430e-02],
        [ 7.8949e-02,  2.0781e-01,  5.8768e-02],
        [ 8.0880e-02,  1.5800e-01,  1.9125e-02],
        [ 8.6267e-02,  3.5724e-02,  1.4907e-02],
        [ 8.6352e-02, -9.8152e-03,  7.5736e-03],
        [ 7.5795e-02,  1.5093e-01,  1.1670e-02],
        [ 7.8404e-02, -4.8122e-02,  1.1716e-02],
        [ 8.6957e-02, -6.0970e-03,  5.7058e-03],
        [ 9.7128e-02, -1.6263e-01,  7.2849e-04],
        [ 9.5235e-02, -2.1251e-01,  2.2622e-03],
        [ 9.6484e-02, -3.1444e-01,  1.5242e-03],
        [ 8.5433e-02,  2.0752e-01,  1.5982e-02],
        [ 5.9769e-02,  1.7044e-01,  1.1273e-01],
        [ 6.9915e-02,  4.2981e-03,  9.5744e-02],
        [ 8.1326e-02, -1.2154e-01,  3.4323e-02],
        [ 7.7577e-02, -7.4136e-02,  5.4143e-02],
        [ 8.0981e-02, -2.5678e-01,  2.0327e-02],
        [ 7.5830e-02, -1.9733e-01,  3.4438e-02],
        [ 6.6002e-02,  1.0198e-01,  8.6034e-02],
        [ 6.9311e-02,  2.0880e-01,  6.3352e-02],
        [ 7.1810e-02,  1.0108e-01,  6.0149e-02],
        [ 6.5864e-02,  2.1849e-01,  6.2617e-02],
        [ 6.7633e-02,  2.1275e-01,  5.4746e-02],
        [ 6.5462e-02,  1.7605e-01,  5.3607e-02],
        [ 5.2080e-02,  1.2327e-01,  2.6446e-01],
        [ 6.8411e-02,  1.5425e-01,  7.3142e-02],
        [ 5.7617e-02,  1.0615e-01,  1.2185e-01],
        [ 6.3835e-02,  1.9829e-01,  7.6863e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 24
Episode Length = 82
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1049,  1.1027,  1.1027,  1.1055,  1.1058,  1.1173, -9.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1121,  1.1178,
         1.1137,  1.1107,  1.1155,  1.1161,  1.1144,  1.1136,  1.1151,  1.1163,
         1.1204,  1.1222,  1.1203,  1.1216,  1.1120,  1.1166,  1.1215,  1.1240,
         1.1204,  1.1169,  1.1084,  1.1211,  1.1223,  1.1202,  1.1147,  1.1039,
         1.1061,  1.1077,  1.1062,  1.0000], device='cuda:0')
target_q_episode tensor([-1.3177, -2.4396, -3.6207, -4.8639, -6.1725, -7.5500, -9.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 15.4813,
        15.2435, 14.9931, 14.7296, 14.4522, 14.1602, 13.8529, 13.5293, 13.1888,
        12.8303, 12.4529, 12.0557, 11.6376, 11.1975, 10.7342, 10.2465,  9.7332,
         9.1928,  8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,
         3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.0805,  1.0671,  1.0552,  1.0455,  1.0326,  1.0301, -9.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1110,  1.2622,
         1.2557,  1.2502,  1.2524,  1.2502,  1.2455,  1.2417,  1.2399,  1.2377,
         1.2381,  1.2361,  1.2303,  1.2273,  1.2134,  1.2133,  1.2133,  1.2106,
         1.2016,  1.1924,  1.1780,  1.1841,  1.1787,  1.1696,  1.1567,  1.1383,
         1.1323,  1.1252,  1.1147,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.7849e-02,  2.2836e-01,  5.3495e-03],
        [ 8.9861e-02,  1.9490e-01,  5.2481e-03],
        [ 9.3441e-02,  2.3436e-01,  3.2730e-03],
        [ 8.9850e-02,  1.5606e-01,  4.1031e-03],
        [ 9.3325e-02,  7.4670e-02,  2.1058e-03],
        [ 9.4232e-02,  1.3453e-01,  1.1058e-03],
        [ 9.7846e-02,  9.4608e-02,  2.1192e-04],
        [ 9.6148e-02,  1.2349e-01,  4.8012e-04],
        [ 9.8205e-02,  1.1067e-01,  2.1055e-04],
        [ 9.7668e-02,  1.1424e-01,  1.7771e-04],
        [ 9.8519e-02,  4.0952e-02,  1.6379e-04],
        [ 9.8205e-02,  1.0707e-01,  2.3419e-04],
        [ 9.8341e-02,  7.9724e-02,  1.8418e-04],
        [ 9.7877e-02,  2.5788e-02,  2.9278e-04],
        [ 9.7490e-02,  5.0699e-02,  3.3373e-04],
        [ 9.7917e-02,  8.3432e-02,  2.5663e-04],
        [ 9.8639e-02,  4.3327e-02,  1.2538e-04],
        [ 9.8889e-02, -7.4672e-02,  7.5072e-05],
        [ 9.8596e-02, -1.2861e-01,  1.2562e-04],
        [ 9.9160e-02, -2.5888e-01,  5.9217e-05],
        [ 9.8986e-02, -2.7993e-01,  1.0306e-04],
        [ 9.9370e-02, -3.0415e-01,  3.1948e-05],
        [ 9.9312e-02, -3.4794e-01,  6.4939e-05],
        [ 9.9572e-02, -3.8015e-01,  1.0759e-05],
        [ 9.9793e-02, -3.8825e-01,  6.8247e-06],
        [ 9.7730e-02, -1.8218e-01,  4.6447e-04],
        [ 9.8419e-02,  1.6855e-02,  2.7138e-04],
        [ 9.9006e-02, -1.3475e-01,  1.4344e-04],
        [ 9.8799e-02, -4.6886e-02,  3.0798e-04],
        [ 9.8239e-02, -2.5879e-01,  2.5970e-04],
        [ 9.4918e-02, -1.2162e-01,  2.2716e-03],
        [ 9.1611e-02, -8.6128e-02,  4.2550e-03],
        [ 8.2489e-02,  2.0151e-01,  4.1269e-02],
        [ 7.2312e-02,  1.9489e-01,  8.2319e-02],
        [ 6.6925e-02,  1.8151e-01,  1.1572e-01],
        [ 5.2952e-02,  1.3490e-01,  2.5668e-01],
        [ 5.0642e-02,  1.5105e-01,  2.8069e-01],
        [ 3.3464e-02,  1.3665e-01,  4.8102e-01],
        [ 9.0907e-02, -6.4619e-02,  3.2829e-03],
        [ 7.8953e-02,  3.8499e-02,  1.6262e-02],
        [ 7.9553e-02, -5.0229e-02,  2.1201e-02],
        [ 7.2888e-02, -1.4211e-02,  3.6401e-02],
        [ 6.5766e-02,  1.9030e-01,  4.7785e-02],
        [ 5.9717e-02,  1.2413e-01,  6.6314e-02],
        [ 6.0599e-02,  1.5605e-01,  8.9328e-02],
        [ 7.9506e-02,  1.5248e-02,  1.8112e-02],
        [ 7.4681e-02,  1.1491e-01,  2.5742e-02],
        [ 6.5428e-02,  2.3117e-01,  4.2795e-02],
        [ 5.3624e-02,  1.6947e-01,  1.0421e-01],
        [ 6.9610e-02,  8.3991e-02,  5.5206e-02],
        [ 7.2441e-02,  1.7312e-01,  5.2436e-02],
        [ 7.6338e-02,  5.4336e-02,  3.2642e-02],
        [ 8.5465e-02,  1.0709e-01,  1.0540e-02],
        [ 8.8637e-02,  7.9554e-02,  6.6533e-03],
        [ 8.0681e-02,  1.4327e-01,  4.3107e-02],
        [ 9.5882e-02,  1.5177e-01,  1.2434e-03],
        [ 9.3258e-02,  8.9256e-02,  2.5360e-03],
        [ 9.5975e-02, -1.7663e-01,  1.2967e-03],
        [ 9.5395e-02, -2.5881e-02,  1.3322e-03],
        [ 9.8520e-02, -2.2985e-01,  1.9252e-04],
        [ 9.8683e-02, -2.5915e-01,  1.2082e-04],
        [ 9.9210e-02, -3.1574e-01,  6.1542e-05],
        [ 9.7902e-02, -1.5005e-01,  3.2723e-04],
        [ 9.4358e-02,  8.5303e-02,  1.6196e-03],
        [ 9.8237e-02,  7.5604e-02,  4.1029e-04],
        [ 9.4834e-02,  1.5305e-01,  2.2230e-03],
        [ 9.5386e-02,  2.0840e-01,  1.4893e-03],
        [ 9.5835e-02,  1.7100e-01,  1.0643e-03],
        [ 9.6709e-02, -9.6734e-04,  7.1883e-04],
        [ 9.5989e-02, -7.0571e-02,  2.1128e-03],
        [ 9.2621e-02, -1.6365e-01,  5.7904e-03],
        [ 8.1249e-02, -3.6159e-02,  2.3270e-02],
        [ 7.6484e-02,  2.9575e-02,  4.3697e-02],
        [ 8.2827e-02,  4.7404e-02,  2.4497e-02],
        [ 7.2670e-02,  2.6853e-02,  3.7890e-02],
        [ 6.4697e-02,  8.6734e-02,  9.9503e-02],
        [ 8.6797e-02,  5.2492e-02,  9.8019e-03],
        [ 6.5577e-02,  2.1543e-01,  5.4203e-02],
        [ 7.8773e-02,  2.1701e-01,  1.9380e-02],
        [ 7.7468e-02,  1.0766e-01,  1.5410e-02],
        [ 7.4220e-02,  1.4500e-01,  4.1393e-02],
        [ 6.2085e-02,  1.5487e-01,  7.8976e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 25
Episode Length = 101
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1117,  1.1059,  1.1093,  1.1150,  1.1190,  1.1124,  1.1098,  1.1133,
         1.1159,  1.1111,  1.1094,  1.1047, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1223,  1.1068,  1.1063,  1.1111,  1.1079,  1.1138,  1.1143,
         1.1164,  1.1158,  1.1163,  1.1158,  1.1172,  1.1147,  1.1080,  1.1073,
         1.1097,  1.1164,  1.1188,  1.1189,  1.1015,  1.1080,  1.1086,  1.1155,
         1.1217,  1.1180,  1.1005,  1.1065,  1.1049,  1.1068, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1133,  1.1115,  1.1126,  1.1063,  1.1135, -4.0000,
         0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 5.9506,  5.2112,  4.4328,  3.6135,  2.7511,  1.8432,  0.8876, -0.1183,
        -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000, 14.0543, 13.7414, 13.4120, 13.0653, 12.7003, 12.3161,
        11.9117, 11.4860, 11.0379, 10.5662, 10.0696,  9.5470,  8.9968,  8.4177,
         7.8081,  7.1664,  6.4910,  5.7800,  5.0316,  4.2438,  3.4145,  2.5416,
         1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.4518, -0.5770, -1.6600, -2.8000, -4.0000,
         0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1515,  1.1397,  1.1366,  1.1356,  1.1325,  1.1184,  1.1080,  1.1031,
         1.0970,  1.0831,  1.0718,  1.0569, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1213,  1.2133,  1.2103,  1.2123,  1.2063,  1.2091,  1.2065,
         1.2053,  1.2011,  1.1980,  1.1936,  1.1909,  1.1841,  1.1729,  1.1674,
         1.1648,  1.1662,  1.1630,  1.1572,  1.1338,  1.1338,  1.1276,  1.1273,
         1.1258,  1.1142,  1.0884,  1.0856,  1.0747,  1.0669, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1123,  1.1061,  1.0987,  1.0835,  1.0813, -4.0000,
         0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.7937e-02,  1.9213e-01,  3.8378e-03],
        [ 7.7312e-02,  1.7530e-01,  1.4533e-02],
        [ 8.7759e-02,  1.8857e-01,  4.0214e-03],
        [ 9.1151e-02,  9.7516e-02,  1.9511e-03],
        [ 8.9366e-02,  1.1618e-01,  2.3057e-03],
        [ 8.5921e-02,  1.0469e-01,  4.6070e-03],
        [ 8.5452e-02,  1.6848e-01,  5.0368e-03],
        [ 8.6561e-02,  1.9633e-02,  5.2672e-03],
        [ 8.4914e-02,  7.4001e-03,  7.1383e-03],
        [ 8.9821e-02,  2.4693e-02,  4.6253e-03],
        [ 9.1368e-02, -9.3728e-03,  4.1495e-03],
        [ 8.9795e-02,  1.1792e-01,  4.4917e-03],
        [ 8.5087e-02,  1.8838e-01,  6.0607e-03],
        [ 8.8003e-02,  1.4334e-01,  3.7293e-03],
        [ 9.2639e-02,  2.3701e-01,  1.2038e-03],
        [ 9.3441e-02,  1.8744e-01,  1.0329e-03],
        [ 9.4443e-02,  2.1779e-01,  6.8527e-04],
        [ 9.6066e-02,  2.1159e-01,  3.4422e-04],
        [ 9.5678e-02,  1.9868e-01,  5.7960e-04],
        [ 9.6593e-02,  2.4125e-01,  4.8703e-04],
        [ 9.3574e-02,  1.2667e-01,  1.9387e-03],
        [ 9.1632e-02,  2.1738e-01,  2.6300e-03],
        [ 9.4895e-02,  2.7683e-02,  9.0408e-04],
        [ 8.9794e-02,  1.5158e-01,  5.8037e-03],
        [ 9.1769e-02,  1.5136e-01,  3.0775e-03],
        [ 9.3972e-02,  1.1207e-01,  1.6236e-03],
        [ 9.4956e-02,  1.3859e-01,  1.1179e-03],
        [ 9.0716e-02,  1.9501e-01,  3.2677e-03],
        [ 9.4164e-02,  1.2605e-01,  2.2364e-03],
        [ 8.9892e-02,  2.1141e-01,  4.7272e-03],
        [ 8.7454e-02,  2.0525e-01,  8.2640e-03],
        [ 8.9530e-02,  1.8577e-01,  5.4818e-03],
        [ 8.8158e-02,  1.4843e-01,  6.2214e-03],
        [ 8.9825e-02,  1.7906e-01,  8.0616e-03],
        [ 8.7626e-02,  1.9771e-01,  1.0556e-02],
        [ 8.8181e-02,  1.9829e-01,  1.5008e-02],
        [ 8.1192e-02,  2.4133e-01,  3.4568e-02],
        [ 7.9088e-02,  1.3799e-01,  3.3114e-02],
        [ 7.9052e-02,  6.8457e-02,  4.3669e-02],
        [ 6.1522e-02,  1.2100e-01,  1.1961e-01],
        [ 5.0745e-02,  6.9235e-02,  2.2357e-01],
        [ 4.8869e-02,  1.4492e-01,  3.2344e-01],
        [ 5.4954e-02,  1.0385e-01,  8.5002e-02],
        [ 7.4465e-02,  9.9566e-02,  2.2217e-02],
        [ 5.3161e-02,  1.3384e-01,  1.1489e-01],
        [ 7.2990e-02,  1.4380e-02,  2.9458e-02],
        [ 8.3739e-02, -1.6414e-02,  1.5707e-02],
        [ 8.6353e-02,  7.0202e-02,  4.6871e-03],
        [ 6.2127e-02,  1.7360e-01,  5.9546e-02],
        [ 7.9466e-02,  1.3858e-01,  1.0955e-02],
        [ 8.2131e-02, -5.2770e-02,  1.1885e-02],
        [ 8.3025e-02,  1.1931e-01,  1.0907e-02],
        [ 8.4738e-02,  2.4603e-02,  8.5125e-03],
        [ 7.5855e-02,  5.7610e-02,  2.3079e-02],
        [ 9.7713e-02, -3.3460e-01,  3.5083e-04],
        [ 9.5569e-02, -2.5519e-01,  8.4740e-04],
        [ 9.7466e-02, -3.4648e-01,  8.3604e-04],
        [ 8.8917e-02,  2.2199e-01,  7.4052e-03],
        [ 9.1340e-02,  2.8047e-01,  4.0278e-03],
        [ 9.1475e-02,  2.3444e-01,  3.6771e-03],
        [ 9.2382e-02,  1.9310e-01,  1.5026e-03],
        [ 9.4137e-02,  2.3042e-01,  1.9713e-03],
        [ 8.8456e-02,  2.3297e-01,  4.4726e-03],
        [ 9.0121e-02,  2.9965e-01,  3.0582e-03],
        [ 8.9936e-02,  2.6312e-01,  3.3717e-03],
        [ 9.6145e-02,  3.2038e-01,  1.3961e-03],
        [ 9.2417e-02,  2.7985e-01,  2.5536e-03],
        [ 9.4462e-02,  2.7483e-01,  1.8181e-03],
        [ 8.8284e-02,  3.0904e-01,  8.3150e-03],
        [ 9.0403e-02,  2.6822e-01,  6.5799e-03],
        [ 9.2964e-02,  2.8467e-01,  3.3473e-03],
        [ 9.0423e-02,  1.5173e-01,  4.9596e-03],
        [ 8.9817e-02,  2.1972e-01,  3.7114e-03],
        [ 9.2386e-02,  2.0130e-01,  1.7213e-03],
        [ 8.9116e-02,  2.3165e-03,  6.4294e-03],
        [ 8.8041e-02,  1.7826e-01,  7.1164e-03],
        [ 9.2605e-02,  2.4065e-02,  3.1845e-03],
        [ 9.1517e-02, -7.6196e-02,  8.7981e-03],
        [ 8.7573e-02,  8.5975e-02,  8.0788e-03],
        [ 7.1935e-02,  2.0710e-01,  3.4917e-02],
        [ 9.1763e-02, -1.6057e-01,  3.5873e-03],
        [ 8.3604e-02, -3.6430e-02,  1.3353e-02],
        [ 7.5636e-02,  4.7570e-02,  3.7805e-02],
        [ 7.9186e-02,  3.8981e-02,  3.9590e-02],
        [ 7.7138e-02,  1.8350e-01,  2.6658e-02],
        [ 6.9161e-02,  1.2724e-01,  5.6795e-02],
        [ 7.6563e-02,  3.7337e-02,  5.0615e-02],
        [ 9.0733e-02,  4.1756e-03,  5.4116e-03],
        [ 9.7301e-02, -3.6566e-01,  1.4806e-03],
        [ 9.6251e-02, -2.9729e-01,  2.7577e-03],
        [ 9.5316e-02, -1.1003e-01,  1.4081e-03],
        [ 9.4924e-02, -2.2790e-01,  2.8424e-03],
        [ 8.4023e-02,  1.6882e-01,  3.5034e-02],
        [ 7.5577e-02,  1.0491e-01,  5.7188e-02],
        [ 6.7003e-02,  1.2105e-01,  1.1168e-01],
        [ 7.0932e-02,  8.2127e-02,  6.3597e-02],
        [ 6.1345e-02,  1.4490e-01,  7.9133e-02],
        [ 6.8051e-02,  1.1813e-01,  9.7201e-02],
        [ 7.2481e-02,  1.2793e-01,  5.3066e-02],
        [ 7.9112e-02,  1.6462e-01,  3.6284e-02],
        [ 6.4703e-02,  9.4674e-02,  9.4702e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 26
Episode Length = 81
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1129,  1.1086,  1.1108,  1.1071,  1.1124,  1.1177,  1.1154,  1.1125,
         1.1148,  1.1098,  1.1149,  1.1196,  1.1192,  1.1199, -4.0000,  0.0000,
         0.0000,  0.1174,  1.1123,  1.1156, -4.0000,  0.0000,  0.0000,  0.1197,
         1.1252,  1.1247,  1.1144,  1.1148, -4.0000,  0.0000,  0.0000,  0.1249,
         1.1231,  1.1242,  1.1243,  1.1216,  1.1223,  1.1184,  1.1195,  1.1172,
         1.1058,  1.1133,  1.0000], device='cuda:0')
target_q_episode tensor([ 8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,
         0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,
         8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,
         2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1613,  1.1529,  1.1507,  1.1424,  1.1429,  1.1430,  1.1354,  1.1268,
         1.1232,  1.1120,  1.1104,  1.1081,  1.1004,  1.0935, -4.0000,  0.0000,
         0.0000,  0.1166,  1.0936,  1.0892, -4.0000,  0.0000,  0.0000,  0.1189,
         1.1207,  1.1132,  1.0957,  1.0884, -4.0000,  0.0000,  0.0000,  0.1240,
         1.1736,  1.1707,  1.1665,  1.1594,  1.1554,  1.1465,  1.1424,  1.1347,
         1.1175,  1.1189,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.2666e-02, -2.9268e-02,  3.1001e-03],
        [ 8.9312e-02,  2.5385e-02,  4.8706e-03],
        [ 9.5778e-02,  2.6910e-02,  1.7233e-03],
        [ 9.8002e-02, -2.4745e-01,  2.2006e-04],
        [ 9.6295e-02, -5.0608e-02,  6.7416e-04],
        [ 9.7727e-02, -1.2407e-01,  3.0890e-04],
        [ 9.8087e-02, -1.2403e-01,  1.8188e-04],
        [ 9.8730e-02, -1.4708e-01,  1.4085e-04],
        [ 9.7751e-02, -8.0202e-02,  3.4982e-04],
        [ 9.9301e-02, -1.6621e-01,  4.7237e-05],
        [ 9.8253e-02, -1.3972e-01,  2.3314e-04],
        [ 9.9005e-02, -1.6467e-01,  1.0502e-04],
        [ 9.6544e-02, -9.1501e-02,  9.4792e-04],
        [ 9.7834e-02, -1.2885e-01,  3.0807e-04],
        [ 9.8776e-02, -1.9842e-01,  1.2818e-04],
        [ 9.8988e-02, -1.7075e-01,  7.5340e-05],
        [ 9.8582e-02, -2.2797e-01,  2.1610e-04],
        [ 9.8756e-02, -2.2482e-01,  2.1961e-04],
        [ 9.9192e-02, -2.8667e-01,  7.6771e-05],
        [ 9.9528e-02, -3.6906e-01,  3.4571e-05],
        [ 9.9214e-02, -3.4695e-01,  6.8009e-05],
        [ 9.9514e-02, -3.7559e-01,  2.9534e-05],
        [ 9.9686e-02, -3.9164e-01,  1.1891e-05],
        [ 9.9700e-02, -3.9398e-01,  9.1195e-06],
        [ 9.9791e-02, -3.9625e-01,  5.3942e-06],
        [ 9.8937e-02, -3.5831e-01,  1.0636e-04],
        [ 9.8539e-02, -2.3972e-01,  2.6861e-04],
        [ 9.9279e-02, -3.0314e-01,  8.8096e-05],
        [ 9.8894e-02, -2.5746e-01,  2.4956e-04],
        [ 9.8018e-02, -3.2742e-01,  6.2016e-04],
        [ 9.7361e-02, -3.2758e-01,  7.6941e-04],
        [ 9.4167e-02, -1.4943e-01,  2.9191e-03],
        [ 8.8272e-02,  4.4728e-02,  1.9850e-02],
        [ 7.7095e-02,  9.0789e-02,  7.3126e-02],
        [ 7.0945e-02,  5.9068e-02,  1.0747e-01],
        [ 5.7117e-02, -4.8595e-03,  2.4782e-01],
        [ 6.2135e-02, -2.1443e-02,  1.6063e-01],
        [ 4.6500e-02,  1.4852e-01,  3.0634e-01],
        [ 9.4262e-02, -4.9023e-03,  1.6820e-03],
        [ 9.5827e-02, -3.3618e-02,  1.0474e-03],
        [ 9.7622e-02, -1.1006e-01,  3.7846e-04],
        [ 8.5446e-02, -1.2119e-01,  8.6595e-03],
        [ 8.9392e-02, -1.6475e-01,  3.6978e-03],
        [ 8.8097e-02, -1.8322e-01,  5.5639e-03],
        [ 8.8766e-02, -1.0599e-01,  8.0826e-03],
        [ 8.5606e-02, -1.9035e-01,  6.8349e-03],
        [ 8.6050e-02, -1.7564e-01,  7.8400e-03],
        [ 7.7529e-02, -1.4519e-02,  3.2846e-02],
        [ 8.7729e-02, -1.4149e-01,  1.1113e-02],
        [ 7.6122e-02, -7.5486e-03,  3.1795e-02],
        [ 8.4445e-02, -4.7071e-02,  1.3486e-02],
        [ 8.5164e-02, -1.3445e-02,  1.1108e-02],
        [ 9.4754e-02, -9.7052e-02,  1.6935e-03],
        [ 9.3497e-02, -8.5619e-04,  2.5215e-03],
        [ 9.4237e-02, -2.7775e-02,  2.4551e-03],
        [ 9.3499e-02, -1.8450e-01,  2.8163e-03],
        [ 9.6962e-02, -1.7391e-01,  9.1490e-04],
        [ 9.2821e-02, -2.2471e-01,  3.6044e-03],
        [ 9.5138e-02, -2.8995e-01,  2.0382e-03],
        [ 9.1266e-02, -1.0324e-01,  1.1540e-02],
        [ 9.5647e-02, -2.1353e-01,  2.7666e-03],
        [ 9.9432e-02, -3.8337e-01,  3.6120e-05],
        [ 9.7520e-02, -1.2500e-01,  6.1953e-04],
        [ 9.5139e-02, -1.8261e-01,  1.7140e-03],
        [ 9.7307e-02, -8.2823e-02,  8.3581e-04],
        [ 9.6845e-02, -2.3734e-01,  1.4196e-03],
        [ 9.6377e-02, -1.9162e-01,  1.3197e-03],
        [ 9.8067e-02, -2.4724e-01,  2.2021e-04],
        [ 9.8622e-02, -2.9155e-01,  1.5670e-04],
        [ 9.9030e-02, -1.9100e-01,  1.2305e-04],
        [ 9.9239e-02, -3.7510e-01,  2.3419e-04],
        [ 9.9345e-02, -3.8786e-01,  7.8529e-05],
        [ 9.5397e-02, -3.3569e-01,  1.2425e-03],
        [ 9.7317e-02, -3.5002e-01,  1.0461e-03],
        [ 8.9216e-02, -1.1327e-01,  1.0513e-02],
        [ 8.8519e-02, -2.2529e-01,  8.8447e-03],
        [ 7.6146e-02,  2.5625e-02,  7.3587e-02],
        [ 6.0692e-02,  7.1843e-02,  1.7690e-01],
        [ 4.6571e-02,  7.8843e-02,  2.4625e-01],
        [ 4.3085e-02,  7.1902e-02,  2.9684e-01],
        [ 6.2817e-02, -4.9164e-02,  1.1034e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 27
Episode Length = 92
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1174,  1.1171,  1.1124,  1.1186,  1.1259,  1.1199,  1.1139,  1.1112,
         1.1106, -5.0000,  0.0000,  0.0000,  0.0000,  0.1179,  1.1075,  1.1185,
         1.1266,  1.1151,  1.1162,  1.1210,  1.1198, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1291,  1.1246,  1.1213,  1.1248,  1.1287, -6.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1103,  1.1086,  1.1090,  1.1246, -4.0000,
         0.0000,  0.0000,  0.1102,  1.1063,  1.1121,  1.1109, -4.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 4.2438,  3.4145,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625,
        -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.5416,  1.6227,
         0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000, -0.5770, -1.6600, -2.8000, -4.0000,
         0.0000,  0.0000,  0.0000, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1347,  1.1298,  1.1203,  1.1214,  1.1233,  1.1118,  1.0998,  1.0909,
         1.0838, -5.0000,  0.0000,  0.0000,  0.0000,  0.1173,  1.1154,  1.1212,
         1.1240,  1.1070,  1.1021,  1.1007,  1.0930, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1284,  1.1119,  1.1024,  1.0995,  1.0965, -6.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1097,  1.0993,  1.0937,  1.1029, -4.0000,
         0.0000,  0.0000,  0.1096,  1.0970,  1.0968,  1.0893, -4.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.9094e-02, -1.6882e-01,  1.7095e-02],
        [ 7.4923e-02, -8.2807e-02,  2.2808e-02],
        [ 7.8036e-02, -1.1817e-01,  1.4972e-02],
        [ 8.3543e-02, -1.5819e-01,  1.1236e-02],
        [ 8.5297e-02, -7.5480e-02,  1.0185e-02],
        [ 9.1290e-02, -2.1583e-01,  3.1406e-03],
        [ 8.8920e-02, -1.9432e-01,  5.3609e-03],
        [ 8.2893e-02, -6.7281e-02,  1.3384e-02],
        [ 9.0631e-02, -1.7072e-01,  5.5857e-03],
        [ 8.9318e-02, -3.7145e-03,  3.8451e-03],
        [ 8.7255e-02,  9.5985e-02,  4.9283e-03],
        [ 8.8698e-02,  7.6081e-02,  4.3389e-03],
        [ 9.0288e-02,  6.0409e-02,  2.8034e-03],
        [ 9.0709e-02,  3.1604e-02,  2.3181e-03],
        [ 9.1003e-02,  5.5721e-02,  2.7141e-03],
        [ 9.2994e-02,  1.4342e-01,  1.0491e-03],
        [ 9.3554e-02,  1.0572e-01,  1.5725e-03],
        [ 9.6340e-02,  1.1919e-01,  4.7296e-04],
        [ 9.6109e-02,  1.7318e-03,  3.8889e-04],
        [ 9.5208e-02,  4.0343e-02,  7.7814e-04],
        [ 9.7560e-02,  8.1618e-02,  1.8629e-04],
        [ 9.4543e-02,  2.8455e-02,  9.7674e-04],
        [ 9.0756e-02,  8.1559e-02,  4.9314e-03],
        [ 9.4122e-02,  7.4564e-02,  2.3409e-03],
        [ 9.3310e-02, -2.0708e-01,  3.1873e-03],
        [ 9.4270e-02, -2.3896e-01,  2.6820e-03],
        [ 9.5736e-02, -3.5896e-01,  8.1846e-04],
        [ 9.9609e-02, -3.9119e-01,  1.7494e-05],
        [ 9.8116e-02, -3.4994e-01,  3.5465e-04],
        [ 9.8722e-02, -3.8694e-01,  1.6069e-04],
        [ 9.3475e-02, -8.9053e-02,  3.7248e-03],
        [ 7.8654e-02,  2.2454e-02,  2.5773e-02],
        [ 8.6165e-02, -9.2396e-02,  1.9617e-02],
        [ 9.8579e-02, -3.6648e-01,  1.8248e-04],
        [ 9.8212e-02, -3.8201e-01,  2.4098e-04],
        [ 9.8555e-02, -3.8214e-01,  2.3565e-04],
        [ 9.8006e-02, -3.3664e-01,  4.2218e-04],
        [ 9.7296e-02, -2.5760e-01,  1.2048e-03],
        [ 9.1298e-02, -7.7153e-02,  7.5581e-03],
        [ 7.4107e-02,  4.1455e-02,  6.7850e-02],
        [ 6.4461e-02, -1.0718e-01,  1.0782e-01],
        [ 1.7646e-02, -1.7788e-02,  6.8931e-01],
        [ 5.7652e-02, -7.0839e-02,  8.5621e-02],
        [ 5.9157e-02, -2.9828e-02,  7.6117e-02],
        [ 7.9810e-02, -1.7454e-01,  1.4411e-02],
        [ 8.2435e-02, -1.1338e-01,  9.9128e-03],
        [ 9.7383e-02, -3.2693e-01,  5.6544e-04],
        [ 8.3471e-02, -1.4810e-01,  1.2337e-02],
        [ 8.6592e-02, -1.1520e-02,  7.5739e-03],
        [ 8.6219e-02,  8.7562e-02,  5.2909e-03],
        [ 8.3528e-02, -6.4419e-02,  8.9060e-03],
        [ 9.1227e-02, -1.6033e-01,  6.8605e-03],
        [ 9.5577e-02, -2.7902e-01,  1.7955e-03],
        [ 8.4259e-02, -6.2747e-02,  1.3196e-02],
        [ 8.7000e-02,  1.8994e-01,  6.2037e-03],
        [ 8.9020e-02,  2.2982e-01,  3.0619e-03],
        [ 9.0510e-02,  1.8002e-01,  2.7374e-03],
        [ 8.8185e-02, -1.0597e-02,  4.0709e-03],
        [ 8.8844e-02, -8.3835e-02,  5.6055e-03],
        [ 8.6645e-02,  1.3604e-03,  1.0553e-02],
        [ 9.0616e-02,  1.2857e-01,  3.5599e-03],
        [ 9.1306e-02, -1.1546e-01,  3.9384e-03],
        [ 8.6532e-02,  4.0915e-02,  8.1888e-03],
        [ 8.9148e-02,  8.0804e-02,  6.6684e-03],
        [ 8.7091e-02,  1.3498e-01,  9.3069e-03],
        [ 9.1147e-02,  1.7000e-01,  4.4434e-03],
        [ 8.7837e-02,  1.0469e-01,  1.4178e-02],
        [ 9.3421e-02, -2.2066e-01,  3.8904e-03],
        [ 9.4338e-02, -2.7879e-01,  2.9547e-03],
        [ 9.7538e-02, -3.4055e-01,  2.8786e-04],
        [ 9.2619e-02, -1.8626e-01,  2.1717e-03],
        [ 9.9140e-02, -3.7051e-01,  7.0155e-05],
        [ 9.9266e-02, -3.6724e-01,  1.6701e-04],
        [ 9.8030e-02, -3.7125e-01,  3.8925e-04],
        [ 9.6481e-02, -3.3267e-01,  1.5439e-03],
        [ 9.7794e-02, -3.3826e-01,  4.5487e-04],
        [ 9.2220e-02, -4.9063e-02,  1.0711e-02],
        [ 7.6188e-02, -2.5618e-02,  6.4931e-02],
        [ 9.8195e-02, -3.7729e-01,  4.1932e-04],
        [ 9.9326e-02, -3.9673e-01,  1.9759e-05],
        [ 9.5251e-02, -3.2882e-01,  1.5038e-03],
        [ 9.9458e-02, -3.9340e-01,  6.9737e-05],
        [ 9.6385e-02, -3.4143e-01,  1.1922e-03],
        [ 9.8066e-02, -3.7731e-01,  3.4171e-04],
        [ 6.6524e-02, -1.5873e-02,  1.7063e-01],
        [ 6.8388e-02, -1.3828e-01,  1.1274e-01],
        [ 5.7911e-02, -1.0391e-01,  1.2521e-01],
        [ 9.3965e-02, -3.1939e-01,  3.0488e-03],
        [ 8.3098e-02, -2.1639e-01,  2.5906e-02],
        [ 7.2314e-02, -5.8044e-02,  6.7276e-02],
        [ 7.5889e-02, -1.9950e-01,  6.4507e-02],
        [ 7.9343e-02, -1.5957e-01,  4.8378e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 28
Episode Length = 84
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1154,  1.1180,  1.1154,  1.1231,  1.1227,  1.1241,  1.1162,  1.1195,
         1.1199,  1.1210,  1.1238,  1.1282,  1.1269,  1.1164, -4.0000,  0.0000,
         0.0000,  0.1235,  1.1172,  1.1130,  1.1281,  1.1294, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1240,  1.1284,  1.1315,  1.1225,  1.1204, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1313,  1.1268,  1.1297,  1.1250,  1.1234,
         1.1267,  1.1251, -4.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  2.3578,  1.4293,  0.4519, -0.5770,
        -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1479,  1.1477,  1.1421,  1.1467,  1.1430,  1.1410,  1.1296,  1.1291,
         1.1255,  1.1224,  1.1208,  1.1205,  1.1144,  1.0987, -4.0000,  0.0000,
         0.0000,  0.1229,  1.1105,  1.1015,  1.1114,  1.1073, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1235,  1.1217,  1.1199,  1.1058,  1.0984, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1307,  1.1324,  1.1310,  1.1219,  1.1157,
         1.1141,  1.1074, -4.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.6981e-02, -2.1011e-01,  9.0685e-04],
        [ 9.6333e-02, -1.8882e-01,  1.2465e-03],
        [ 9.7881e-02, -1.6767e-01,  4.3952e-04],
        [ 9.5820e-02, -1.7043e-01,  1.1335e-03],
        [ 9.8353e-02, -2.6923e-01,  1.5873e-04],
        [ 9.8362e-02, -2.6930e-01,  1.8910e-04],
        [ 9.9462e-02, -3.3423e-01,  2.6971e-05],
        [ 9.8171e-02, -2.6376e-01,  2.5171e-04],
        [ 9.8403e-02, -2.2633e-01,  2.4533e-04],
        [ 9.9043e-02, -3.0039e-01,  9.7364e-05],
        [ 9.9345e-02, -3.3779e-01,  5.2333e-05],
        [ 9.9001e-02, -2.9123e-01,  9.7692e-05],
        [ 9.8967e-02, -2.8131e-01,  1.3214e-04],
        [ 9.8698e-02, -3.0376e-01,  1.7267e-04],
        [ 9.9260e-02, -3.2628e-01,  8.3715e-05],
        [ 9.9090e-02, -3.4184e-01,  7.6592e-05],
        [ 9.9045e-02, -2.3828e-01,  1.0741e-04],
        [ 9.9486e-02, -3.5026e-01,  3.3110e-05],
        [ 9.9567e-02, -3.7709e-01,  4.1962e-05],
        [ 9.8895e-02, -3.5739e-01,  1.8474e-04],
        [ 9.9787e-02, -3.9319e-01,  7.8380e-06],
        [ 9.9825e-02, -3.9588e-01,  4.4405e-06],
        [ 9.9840e-02, -3.9805e-01,  4.5896e-06],
        [ 9.9857e-02, -3.9739e-01,  4.5300e-06],
        [ 9.9927e-02, -3.9947e-01,  7.1526e-07],
        [ 9.8596e-02, -3.7720e-01,  2.6667e-04],
        [ 9.9618e-02, -3.8072e-01,  3.0935e-05],
        [ 9.9499e-02, -3.8080e-01,  6.4582e-05],
        [ 9.9520e-02, -3.7641e-01,  6.7323e-05],
        [ 9.8969e-02, -3.7678e-01,  1.9488e-04],
        [ 9.7978e-02, -3.5013e-01,  5.1713e-04],
        [ 9.6356e-02, -3.4389e-01,  1.1421e-03],
        [ 8.8325e-02, -5.5840e-02,  2.4786e-02],
        [ 7.4749e-02, -4.1762e-02,  9.5586e-02],
        [ 6.9842e-02, -6.8387e-02,  1.1796e-01],
        [ 6.3541e-02, -6.7908e-02,  1.9272e-01],
        [ 6.5088e-02, -8.5701e-02,  1.8852e-01],
        [ 3.9870e-02, -5.1189e-02,  5.1797e-01],
        [ 8.3515e-02, -1.4905e-01,  1.3067e-02],
        [ 8.8320e-02, -1.2228e-01,  5.8390e-03],
        [ 8.3511e-02, -2.1653e-01,  9.9317e-03],
        [ 8.4486e-02, -2.2128e-01,  7.7107e-03],
        [ 8.0072e-02, -2.1816e-01,  2.1700e-02],
        [ 9.8307e-02, -3.6682e-01,  2.1353e-04],
        [ 9.5388e-02, -1.2473e-01,  1.6131e-03],
        [ 9.7926e-02, -1.9735e-01,  3.6234e-04],
        [ 9.8971e-02, -3.5562e-01,  1.2740e-04],
        [ 9.8292e-02, -2.8892e-01,  1.8585e-04],
        [ 9.7074e-02, -2.9541e-01,  6.1181e-04],
        [ 9.9110e-02, -3.1433e-01,  5.5879e-05],
        [ 9.5979e-02,  1.6229e-01,  1.0956e-03],
        [ 9.7147e-02, -1.2776e-01,  1.0936e-03],
        [ 9.6216e-02,  4.2502e-02,  8.6245e-04],
        [ 9.7333e-02,  9.0945e-02,  6.1980e-04],
        [ 9.9236e-02, -3.5294e-01,  8.8096e-05],
        [ 9.7773e-02, -3.0040e-01,  4.3368e-04],
        [ 9.6555e-02, -2.8057e-01,  1.1507e-03],
        [ 9.2719e-02, -1.7797e-01,  4.9887e-03],
        [ 9.4311e-02, -2.9768e-01,  3.0370e-03],
        [ 9.5876e-02, -2.6145e-01,  2.0069e-03],
        [ 9.7601e-02, -2.4800e-01,  8.4648e-04],
        [ 9.8215e-02, -2.7321e-01,  3.7318e-04],
        [ 9.7956e-02, -2.8720e-01,  1.1189e-03],
        [ 9.7574e-02, -3.3935e-01,  1.4106e-03],
        [ 9.7830e-02, -3.5170e-01,  7.3695e-04],
        [ 9.8107e-02, -3.7545e-01,  5.1016e-04],
        [ 9.9257e-02, -3.9105e-01,  4.1127e-05],
        [ 9.8694e-02, -3.7022e-01,  2.2474e-04],
        [ 9.9361e-02, -3.8423e-01,  1.0890e-04],
        [ 9.9222e-02, -3.7809e-01,  1.3405e-04],
        [ 9.8893e-02, -3.8117e-01,  1.5587e-04],
        [ 9.8189e-02, -3.5435e-01,  9.4959e-04],
        [ 9.9450e-02, -3.9213e-01,  8.1807e-05],
        [ 9.9447e-02, -3.8742e-01,  6.3449e-05],
        [ 9.8161e-02, -3.9026e-01,  3.2800e-04],
        [ 9.8071e-02, -3.8915e-01,  6.0257e-04],
        [ 9.6198e-02, -3.7779e-01,  1.0374e-03],
        [ 8.5268e-02, -1.8285e-01,  3.6391e-02],
        [ 9.0338e-02, -1.8178e-01,  1.8619e-02],
        [ 7.9903e-02, -1.5890e-01,  6.1721e-02],
        [ 9.0701e-02, -2.1471e-01,  8.9486e-03],
        [ 8.3062e-02, -1.2264e-02,  2.1511e-02],
        [ 9.0651e-02, -2.4263e-01,  8.8232e-03],
        [ 8.9414e-02, -6.7841e-02,  6.5780e-03]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 29
Episode Length = 105
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1244,  1.1191,  1.1221,  1.1195,  1.1181,  1.1205,  1.1188,  1.1223,
         1.1214,  1.1303,  1.1302, -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1160,  1.1252,  1.1199,  1.1213,  1.1239,  1.1347,  1.1331,
         1.1319,  1.1344,  1.1185,  1.1252,  1.1297,  1.1346,  1.1345,  1.1322,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1292,  1.1306,
         1.1276,  1.1272,  1.1334, -3.0000,  0.0000,  0.1364,  1.1339,  1.1279,
         1.1252,  1.1242,  1.1188,  1.1243,  1.1272,  1.1237,  1.1231,  1.1266,
         1.1274,  1.1192,  1.1179,  1.1198,  1.1244,  1.1309,  1.0000],
       device='cuda:0')
target_q_episode tensor([ 4.6424,  3.8341,  2.9833,  2.0876,  1.1449,  0.1525, -0.8921, -1.9917,
        -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  6.8328,  6.1398,  5.4103,  4.6424,  3.8341,  2.9833,
         2.0876,  1.1449,  0.1525, -0.8921, -1.9917, -3.1491, -4.3675, -5.6500,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.2664,
         0.2804, -0.7575, -1.8500, -3.0000,  0.0000,  0.0000, 11.6376, 11.1975,
        10.7342, 10.2465,  9.7332,  9.1928,  8.6240,  8.0253,  7.3950,  6.7316,
         6.0333,  5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000],
       device='cuda:0')
target_q tensor([ 1.1374,  1.1291,  1.1290,  1.1231,  1.1182,  1.1169,  1.1113,  1.1107,
         1.1056,  1.1100,  1.1051, -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1156,  1.1463,  1.1384,  1.1371,  1.1369,  1.1446,  1.1400,
         1.1355,  1.1345,  1.1150,  1.1177,  1.1181,  1.1188,  1.1142,  1.1071,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1287,  1.1311,
         1.1245,  1.1203,  1.1224, -3.0000,  0.0000,  0.1359,  1.1727,  1.1651,
         1.1608,  1.1579,  1.1506,  1.1541,  1.1549,  1.1492,  1.1463,  1.1473,
         1.1455,  1.1346,  1.1305,  1.1294,  1.1308,  1.1339,  1.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.8001e-02, -1.2085e-01,  4.3871e-03],
        [ 8.7743e-02, -1.6019e-01,  5.5021e-03],
        [ 8.7771e-02, -1.1550e-01,  4.6247e-03],
        [ 9.1366e-02, -1.1766e-01,  2.1293e-03],
        [ 9.2926e-02, -1.3773e-01,  1.7690e-03],
        [ 9.3408e-02, -1.6081e-01,  1.4125e-03],
        [ 8.6457e-02, -1.5056e-01,  8.0179e-03],
        [ 8.9579e-02, -2.5014e-01,  6.7087e-03],
        [ 8.9537e-02, -2.5126e-01,  5.9440e-03],
        [ 9.2717e-02, -2.2326e-01,  3.5075e-03],
        [ 8.8940e-02, -1.3176e-01,  8.7373e-03],
        [ 8.9735e-02, -1.3409e-01,  6.6966e-03],
        [ 9.2072e-02, -1.7766e-01,  2.9839e-03],
        [ 9.1469e-02, -9.3040e-02,  3.0419e-03],
        [ 9.5187e-02, -8.6331e-02,  6.7300e-04],
        [ 9.4856e-02, -2.8886e-02,  7.7486e-04],
        [ 9.6680e-02,  2.5703e-02,  4.3598e-04],
        [ 9.7054e-02,  3.1363e-02,  3.6252e-04],
        [ 9.5364e-02, -7.6643e-02,  9.0781e-04],
        [ 9.6407e-02, -3.4078e-02,  6.2832e-04],
        [ 9.8105e-02, -5.5443e-02,  1.8227e-04],
        [ 9.8043e-02, -1.7481e-01,  2.2075e-04],
        [ 9.6467e-02, -2.8780e-02,  7.5045e-04],
        [ 9.3406e-02, -1.0737e-02,  2.3267e-03],
        [ 9.4643e-02, -1.1331e-01,  1.8447e-03],
        [ 9.4615e-02, -7.2138e-02,  1.9068e-03],
        [ 9.6488e-02, -1.5293e-01,  8.4054e-04],
        [ 9.4071e-02, -8.5687e-02,  2.1175e-03],
        [ 9.4342e-02, -6.9519e-02,  2.1885e-03],
        [ 9.5160e-02, -4.4106e-02,  1.5480e-03],
        [ 9.5584e-02, -7.0572e-02,  1.6998e-03],
        [ 9.6255e-02, -8.2716e-02,  8.4978e-04],
        [ 9.2273e-02, -9.5411e-03,  3.8110e-03],
        [ 9.4266e-02, -3.8574e-02,  2.7057e-03],
        [ 9.5694e-02, -1.7522e-01,  1.6327e-03],
        [ 9.1543e-02,  8.8683e-03,  7.7573e-03],
        [ 8.8651e-02, -6.5583e-02,  1.1829e-02],
        [ 8.4594e-02, -5.3493e-02,  2.3207e-02],
        [ 8.0343e-02, -9.2470e-02,  3.3457e-02],
        [ 7.4308e-02, -5.0588e-02,  5.1265e-02],
        [ 5.4606e-02, -4.6646e-02,  1.7984e-01],
        [ 4.8921e-02, -8.4544e-02,  2.7662e-01],
        [ 8.0731e-02, -9.2754e-02,  1.2138e-02],
        [ 8.6565e-02, -1.3365e-01,  5.3560e-03],
        [ 9.1164e-02,  9.0057e-02,  1.8308e-03],
        [ 8.9715e-02, -5.9620e-02,  2.3276e-03],
        [ 8.8112e-02, -7.2981e-03,  5.8356e-03],
        [ 9.2678e-02, -4.2354e-02,  2.1838e-03],
        [ 9.5639e-02, -2.2915e-01,  9.4202e-04],
        [ 9.4991e-02, -4.9219e-02,  1.3308e-03],
        [ 9.0400e-02,  3.3871e-02,  4.1082e-03],
        [ 8.6497e-02, -2.5707e-02,  8.1995e-03],
        [ 8.9169e-02, -2.6129e-02,  7.6961e-03],
        [ 8.8817e-02, -2.8839e-01,  5.3604e-03],
        [ 9.1920e-02, -2.7569e-01,  3.9168e-03],
        [ 9.5534e-02, -3.0317e-01,  1.5207e-03],
        [ 9.0020e-02, -2.1065e-01,  7.1175e-03],
        [ 8.8857e-02,  4.6305e-02,  7.5016e-03],
        [ 9.1208e-02,  5.8800e-02,  3.3352e-03],
        [ 8.9756e-02, -1.8479e-01,  3.1838e-03],
        [ 9.3913e-02, -3.2945e-01,  4.2896e-03],
        [ 9.9161e-02, -3.9765e-01,  4.3273e-05],
        [ 9.9389e-02, -3.9881e-01,  3.3736e-05],
        [ 9.8006e-02, -3.8884e-01,  3.7056e-04],
        [ 9.8619e-02, -3.9039e-01,  1.9526e-04],
        [ 9.9208e-02, -3.9420e-01,  3.5286e-05],
        [ 9.9751e-02, -3.9939e-01,  9.6262e-06],
        [ 9.9815e-02, -3.9944e-01,  1.0163e-05],
        [ 9.9786e-02, -3.9902e-01,  6.5565e-06],
        [ 9.9478e-02, -3.9666e-01,  3.0488e-05],
        [ 9.9649e-02, -3.9893e-01,  3.0965e-05],
        [ 9.9821e-02, -3.9979e-01,  6.0797e-06],
        [ 9.9730e-02, -3.9864e-01,  1.0043e-05],
        [ 9.9415e-02, -3.9537e-01,  5.8770e-05],
        [ 9.9011e-02, -3.9205e-01,  7.3761e-05],
        [ 9.1240e-02, -1.3791e-01,  7.3594e-03],
        [ 9.6041e-02, -2.1107e-01,  1.5557e-03],
        [ 9.7056e-02, -3.0040e-01,  1.7382e-03],
        [ 9.9568e-02, -3.9870e-01,  5.3912e-05],
        [ 9.9888e-02, -3.9959e-01,  5.7220e-06],
        [ 9.9863e-02, -3.9926e-01,  7.7784e-06],
        [ 9.9834e-02, -3.9945e-01,  8.2552e-06],
        [ 9.9930e-02, -3.9980e-01,  2.7120e-06],
        [ 9.9911e-02, -3.9979e-01,  4.2915e-06],
        [ 9.9917e-02, -3.9961e-01,  4.1425e-06],
        [ 9.9928e-02, -3.9979e-01,  4.1425e-06],
        [ 9.9943e-02, -3.9959e-01,  5.0664e-06],
        [ 9.9854e-02, -3.9838e-01,  1.5825e-05],
        [ 9.9113e-02, -3.7596e-01,  5.2583e-04],
        [ 9.5279e-02, -2.7034e-01,  2.0623e-03],
        [ 8.7108e-02, -7.4647e-02,  1.9674e-02],
        [ 9.4761e-02,  1.5047e-01,  2.6765e-03],
        [ 8.9010e-02,  2.1843e-02,  1.4725e-02],
        [ 8.7180e-02, -5.4507e-02,  2.5185e-02],
        [ 8.6921e-02, -1.4415e-01,  3.8105e-02],
        [ 8.9507e-02, -1.3101e-01,  2.7540e-02],
        [ 9.1893e-02, -3.3319e-01,  9.7549e-03],
        [ 7.7880e-02, -2.2393e-01,  7.0699e-02],
        [ 9.0113e-02, -2.0467e-01,  1.0175e-02],
        [ 8.6806e-02, -2.3628e-01,  3.6595e-02],
        [ 8.8827e-02, -3.1163e-01,  2.0465e-02],
        [ 8.6169e-02, -2.0089e-01,  2.9983e-02],
        [ 7.6075e-02, -1.2873e-01,  7.5910e-02],
        [ 7.9619e-02, -2.0072e-01,  6.8905e-02],
        [ 8.4671e-02, -1.7973e-01,  3.5000e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 30
Episode Length = 87
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1177,   1.1173,   1.1157,   1.1213,   1.1245, -11.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.1249,   1.1332,   1.1318,   1.1247,   1.1196,  -3.0000,
          0.0000,   0.1386,   1.1296,   1.1274,   1.1306,   1.1357,   1.1373,
          1.1373,   1.1253,   1.1216,   1.1246,  -5.0000,   0.0000,   0.0000,
          0.0000,   0.1389,   1.1351,   1.1313,   1.1301,   1.1251,   1.1208,
          1.1245,   1.1305,   1.1294,   1.1297,   1.1314,   1.1233,   1.0000],
       device='cuda:0')
target_q_episode tensor([ -3.9872,  -5.2497,  -6.5786,  -7.9775,  -9.4500, -11.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   1.2664,   0.2804,  -0.7575,  -1.8500,  -3.0000,
          0.0000,   0.0000,   4.2438,   3.4145,   2.5416,   1.6227,   0.6555,
         -0.3627,  -1.4344,  -2.5625,  -3.7500,  -5.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   9.1928,   8.6240,   8.0253,   7.3950,   6.7316,
          6.0333,   5.2982,   4.5244,   3.7099,   2.8525,   1.9500,   1.0000],
       device='cuda:0')
target_q tensor([  1.1023,   1.0981,   1.0924,   1.0937,   1.0925, -11.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.1246,   1.1336,   1.1292,   1.1190,   1.1106,  -3.0000,
          0.0000,   0.1382,   1.1391,   1.1343,   1.1349,   1.1372,   1.1359,
          1.1327,   1.1176,   1.1104,   1.1098,  -5.0000,   0.0000,   0.0000,
          0.0000,   0.1385,   1.1595,   1.1540,   1.1509,   1.1441,   1.1378,
          1.1394,   1.1432,   1.1397,   1.1375,   1.1366,   1.1258,   1.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.5509e-02, -2.4023e-01,  1.5660e-03],
        [ 9.4981e-02, -1.6812e-01,  1.7426e-03],
        [ 9.7109e-02, -2.2974e-01,  8.0228e-04],
        [ 9.6245e-02, -2.3800e-01,  9.6652e-04],
        [ 9.8427e-02, -2.9772e-01,  2.2024e-04],
        [ 9.8770e-02, -2.7148e-01,  1.1647e-04],
        [ 9.8826e-02, -3.0035e-01,  1.3122e-04],
        [ 9.9186e-02, -3.4259e-01,  7.5758e-05],
        [ 9.8777e-02, -2.9236e-01,  2.2408e-04],
        [ 9.9503e-02, -3.5089e-01,  3.1978e-05],
        [ 9.9122e-02, -3.0035e-01,  1.3256e-04],
        [ 9.9482e-02, -3.4625e-01,  5.2691e-05],
        [ 9.8511e-02, -3.1013e-01,  2.2602e-04],
        [ 9.8689e-02, -2.6991e-01,  2.0242e-04],
        [ 9.9173e-02, -3.1977e-01,  1.1456e-04],
        [ 9.9256e-02, -3.5948e-01,  8.4460e-05],
        [ 9.9355e-02, -3.6151e-01,  6.8933e-05],
        [ 9.9181e-02, -3.3253e-01,  1.0642e-04],
        [ 9.9636e-02, -3.8024e-01,  2.7001e-05],
        [ 9.9487e-02, -3.8806e-01,  4.3333e-05],
        [ 9.9643e-02, -3.9304e-01,  3.0637e-05],
        [ 9.9850e-02, -3.9869e-01,  4.4405e-06],
        [ 9.9958e-02, -3.9959e-01,  3.8743e-07],
        [ 9.9893e-02, -3.9804e-01,  3.4869e-06],
        [ 9.9953e-02, -3.9967e-01,  4.7684e-07],
        [ 9.9482e-02, -3.9380e-01,  3.7134e-05],
        [ 9.9788e-02, -3.9466e-01,  1.2219e-05],
        [ 9.9874e-02, -3.9815e-01,  7.7784e-06],
        [ 9.9886e-02, -3.9735e-01,  9.8646e-06],
        [ 9.9459e-02, -3.9790e-01,  4.5121e-05],
        [ 9.9462e-02, -3.8916e-01,  7.8976e-05],
        [ 9.7211e-02, -3.5075e-01,  9.7474e-04],
        [ 9.3751e-02, -2.3097e-01,  9.1291e-03],
        [ 7.9711e-02, -3.4554e-02,  6.2146e-02],
        [ 7.6145e-02, -6.0057e-02,  1.0333e-01],
        [ 7.4056e-02, -5.5860e-02,  8.8098e-02],
        [ 6.9526e-02, -8.2452e-02,  1.4678e-01],
        [ 4.7605e-02, -1.2830e-01,  4.8309e-01],
        [ 9.7601e-02, -3.1961e-01,  3.6213e-04],
        [ 9.5388e-02, -2.6119e-01,  1.0566e-03],
        [ 9.0364e-02, -2.0554e-01,  6.3496e-03],
        [ 9.1007e-02, -2.4681e-01,  5.2150e-03],
        [ 9.1392e-02, -1.8631e-01,  4.1742e-03],
        [ 8.9874e-02, -2.0501e-01,  5.2152e-03],
        [ 8.6854e-02, -2.3741e-01,  9.4903e-03],
        [ 9.5900e-02, -2.9588e-01,  8.3786e-04],
        [ 9.0172e-02, -3.1548e-01,  4.2819e-03],
        [ 8.7874e-02,  1.9598e-02,  1.0450e-02],
        [ 7.8037e-02, -1.2778e-01,  2.3193e-02],
        [ 8.8410e-02, -1.1490e-01,  8.9159e-03],
        [ 8.9549e-02, -1.1191e-01,  8.4242e-03],
        [ 8.8801e-02, -2.8719e-01,  7.9363e-03],
        [ 8.2649e-02, -1.0614e-01,  2.2275e-02],
        [ 7.9419e-02, -1.0411e-01,  3.5288e-02],
        [ 8.1715e-02, -9.0023e-02,  4.1543e-02],
        [ 8.9826e-02, -2.8579e-01,  9.8444e-03],
        [ 9.6090e-02, -3.5889e-01,  1.3722e-03],
        [ 9.4730e-02, -2.8414e-01,  2.8207e-03],
        [ 9.4584e-02, -3.3312e-01,  2.0324e-03],
        [ 8.9459e-02, -2.2605e-01,  1.3789e-02],
        [ 9.3510e-02, -2.5060e-01,  8.3615e-03],
        [ 9.7229e-02, -2.8110e-01,  1.2228e-03],
        [ 9.9244e-02, -3.6965e-01,  1.6260e-04],
        [ 9.8315e-02, -3.4815e-01,  4.8715e-04],
        [ 9.8494e-02, -3.6613e-01,  4.3535e-04],
        [ 9.8389e-02, -3.8070e-01,  3.1164e-04],
        [ 9.8992e-02, -3.7891e-01,  1.9905e-04],
        [ 9.8850e-02, -3.5856e-01,  2.7221e-04],
        [ 9.7470e-02, -2.9167e-01,  6.1113e-04],
        [ 9.8805e-02, -3.7531e-01,  1.8048e-04],
        [ 9.8689e-02, -3.7905e-01,  4.4817e-04],
        [ 9.9681e-02, -3.9637e-01,  3.0667e-05],
        [ 9.9629e-02, -3.9812e-01,  2.6286e-05],
        [ 9.9719e-02, -3.9805e-01,  2.9564e-05],
        [ 9.9877e-02, -3.9875e-01,  6.6161e-06],
        [ 9.9575e-02, -3.9839e-01,  3.7849e-05],
        [ 9.9624e-02, -3.9835e-01,  2.2888e-05],
        [ 9.6405e-02, -3.7082e-01,  1.4894e-03],
        [ 9.0616e-02, -2.0401e-01,  1.0110e-02],
        [ 7.6572e-02,  2.3083e-03,  8.1654e-02],
        [ 8.7869e-02, -2.3101e-01,  2.2458e-02],
        [ 9.2979e-02, -3.3102e-01,  6.1173e-03],
        [ 8.1046e-02, -1.8857e-01,  5.5218e-02],
        [ 7.9909e-02, -1.8081e-01,  4.7566e-02],
        [ 8.1584e-02, -1.2547e-01,  2.9442e-02],
        [ 7.8527e-02, -1.0470e-01,  6.1180e-02],
        [ 8.9264e-02, -1.7712e-01,  1.2734e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Saving checkpoint
Run No. 31
Episode Length = 103
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1231,  1.1193,  1.1212,  1.1199,  1.1199,  1.1251,  1.1293, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1264,  1.1309,  1.1380,  1.1315,  1.1206,
         1.1240,  1.1257,  1.1264,  1.1402,  1.1396,  1.1386,  1.1230,  1.1245,
         1.1261,  1.1260,  1.1351,  1.1388,  1.1291,  1.1355,  1.1344,  1.1322,
         1.1327,  1.1364,  1.1327,  1.1330,  1.1336,  1.1349,  1.1400,  1.1315,
         1.1372,  1.1287,  1.1226,  1.1225,  1.1232, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1398,  1.1247,  1.1210,  1.1229,  1.1166, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000, 15.3994, 15.1572, 14.9023, 14.6340,
        14.3516, 14.0543, 13.7414, 13.4120, 13.0653, 12.7003, 12.3161, 11.9117,
        11.4860, 11.0379, 10.5662, 10.0696,  9.5470,  8.9968,  8.4177,  7.8081,
         7.1664,  6.4910,  5.7800,  5.0316,  4.2438,  3.4145,  2.5416,  1.6227,
         0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -1.9917, -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1266,  1.1206,  1.1200,  1.1162,  1.1136,  1.1159,  1.1172, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1261,  1.1663,  1.1728,  1.1656,  1.1541,
         1.1568,  1.1577,  1.1577,  1.1706,  1.1692,  1.1672,  1.1508,  1.1513,
         1.1518,  1.1506,  1.1585,  1.1609,  1.1499,  1.1550,  1.1524,  1.1488,
         1.1477,  1.1497,  1.1442,  1.1426,  1.1413,  1.1406,  1.1435,  1.1327,
         1.1360,  1.1250,  1.1163,  1.1134,  1.1111, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1394,  1.1170,  1.1104,  1.1093,  1.0998, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.3194e-02, -1.2422e-01,  4.1705e-02],
        [ 7.4913e-02, -2.0707e-01,  2.7797e-02],
        [ 8.3477e-02, -2.4087e-01,  1.1482e-02],
        [ 8.2546e-02, -2.6253e-01,  1.7254e-02],
        [ 8.2373e-02, -2.1956e-01,  1.5330e-02],
        [ 8.9100e-02, -2.1296e-01,  7.1809e-03],
        [ 8.6935e-02, -2.2992e-01,  8.9837e-03],
        [ 8.8976e-02, -2.2484e-01,  8.7464e-03],
        [ 8.3710e-02, -1.3110e-01,  1.3808e-02],
        [ 8.9139e-02, -7.6421e-02,  4.6010e-03],
        [ 9.0133e-02, -1.5337e-01,  3.8981e-03],
        [ 9.0683e-02,  7.7269e-03,  3.1825e-03],
        [ 9.1011e-02, -4.7041e-02,  2.9457e-03],
        [ 9.3010e-02, -5.2480e-03,  2.3474e-03],
        [ 9.3180e-02,  1.3476e-02,  1.9015e-03],
        [ 9.4714e-02,  6.3361e-02,  1.1334e-03],
        [ 9.6039e-02,  3.9009e-02,  8.0034e-04],
        [ 9.6479e-02, -2.0024e-02,  6.7663e-04],
        [ 9.2222e-02,  2.4680e-02,  3.3258e-03],
        [ 9.7237e-02, -3.2362e-02,  5.6705e-04],
        [ 9.5621e-02,  1.3727e-02,  1.1876e-03],
        [ 9.6745e-02, -4.3694e-02,  8.5893e-04],
        [ 9.1258e-02,  2.6576e-02,  4.6616e-03],
        [ 9.5535e-02, -3.2171e-02,  1.9765e-03],
        [ 9.1437e-02, -2.5362e-01,  5.0058e-03],
        [ 9.5787e-02, -3.0751e-01,  3.0164e-03],
        [ 9.7699e-02, -3.8715e-01,  2.8554e-04],
        [ 9.9458e-02, -3.9380e-01,  4.7952e-05],
        [ 9.9107e-02, -3.8985e-01,  1.4833e-04],
        [ 9.9388e-02, -3.9564e-01,  8.3923e-05],
        [ 9.1456e-02, -1.1219e-01,  8.7419e-03],
        [ 7.7743e-02,  4.4349e-03,  3.4099e-02],
        [ 8.7924e-02, -9.7485e-02,  1.7395e-02],
        [ 9.9735e-02, -3.9799e-01,  5.9307e-06],
        [ 9.8170e-02, -3.7818e-01,  3.6693e-04],
        [ 9.9415e-02, -3.9358e-01,  5.3257e-05],
        [ 9.8191e-02, -3.7332e-01,  5.2068e-04],
        [ 9.6420e-02, -2.8813e-01,  1.9495e-03],
        [ 9.3068e-02, -1.7603e-01,  4.8971e-03],
        [ 8.6843e-02, -1.5185e-01,  2.3248e-02],
        [ 7.1178e-02, -1.5121e-01,  1.0239e-01],
        [ 9.0709e-03, -4.1066e-02,  7.8105e-01],
        [ 6.2167e-02, -1.4496e-01,  7.1622e-02],
        [ 6.4884e-02, -1.3080e-01,  4.8748e-02],
        [ 9.6404e-02, -3.1878e-01,  1.0317e-03],
        [ 9.1379e-02, -2.8214e-01,  3.1893e-03],
        [ 9.7547e-02, -3.7970e-01,  3.5274e-04],
        [ 9.9310e-02, -3.9687e-01,  3.0577e-05],
        [ 9.8985e-02, -3.9674e-01,  5.9187e-05],
        [ 9.7980e-02, -3.8995e-01,  1.9196e-04],
        [ 9.9361e-02, -3.9654e-01,  3.8594e-05],
        [ 9.7779e-02, -3.7362e-01,  3.3471e-04],
        [ 9.7695e-02, -3.4421e-01,  9.9313e-04],
        [ 9.8527e-02, -3.7833e-01,  5.0652e-04],
        [ 9.5945e-02, -3.5096e-01,  2.7824e-03],
        [ 9.6256e-02, -3.7541e-01,  1.0968e-03],
        [ 9.4334e-02, -3.4753e-01,  4.1007e-03],
        [ 8.8741e-02, -6.1978e-02,  5.7566e-03],
        [ 9.3294e-02, -1.5684e-01,  1.6901e-03],
        [ 8.6596e-02, -2.3111e-01,  1.3438e-02],
        [ 9.7556e-02, -3.7363e-01,  7.8577e-04],
        [ 9.6183e-02, -3.3591e-01,  2.7319e-03],
        [ 9.9368e-02, -3.9679e-01,  4.6104e-05],
        [ 9.8862e-02, -3.8391e-01,  3.9494e-04],
        [ 9.6129e-02, -5.2340e-02,  1.3710e-03],
        [ 9.6649e-02,  1.5457e-01,  8.2645e-04],
        [ 9.2376e-02,  8.3906e-02,  5.6594e-03],
        [ 9.5817e-02, -4.6096e-02,  1.6986e-03],
        [ 9.5615e-02, -2.5638e-01,  2.4180e-03],
        [ 9.8868e-02, -3.4596e-01,  2.5812e-04],
        [ 9.4800e-02, -2.0948e-02,  2.9860e-03],
        [ 9.4936e-02,  6.0382e-02,  3.6152e-03],
        [ 9.3018e-02, -1.6627e-02,  5.7995e-03],
        [ 9.5074e-02, -2.5619e-01,  1.8300e-03],
        [ 9.5814e-02, -3.2360e-01,  1.9967e-03],
        [ 9.3858e-02, -3.3639e-01,  4.6845e-03],
        [ 8.9944e-02, -3.4690e-01,  9.9729e-03],
        [ 9.3793e-02, -2.9367e-01,  6.5965e-03],
        [ 9.6513e-02, -3.6871e-01,  3.0191e-03],
        [ 9.7725e-02, -3.7917e-01,  1.4961e-03],
        [ 9.3583e-02, -3.3412e-01,  4.3673e-03],
        [ 9.8769e-02, -3.8876e-01,  6.0135e-04],
        [ 9.8573e-02, -3.9559e-01,  4.1449e-04],
        [ 9.1777e-02, -3.2543e-01,  9.9171e-03],
        [ 8.6305e-02, -1.8678e-01,  3.0595e-02],
        [ 8.2834e-02, -1.3872e-01,  4.0172e-02],
        [ 9.8492e-02, -3.8795e-01,  3.8752e-04],
        [ 9.9867e-02, -3.9968e-01,  2.8014e-06],
        [ 9.9437e-02, -3.9629e-01,  1.0306e-04],
        [ 9.9193e-02, -3.9552e-01,  1.3760e-04],
        [ 9.9115e-02, -3.8804e-01,  2.2933e-04],
        [ 9.7577e-02, -3.5450e-01,  9.2602e-04],
        [ 8.2755e-02, -1.9172e-01,  5.4810e-02],
        [ 8.3647e-02, -2.4288e-01,  2.2336e-02],
        [ 6.8020e-02, -1.4393e-01,  1.5333e-01],
        [ 7.7002e-02, -1.9643e-01,  9.8289e-02],
        [ 7.4203e-02, -2.0130e-01,  1.0964e-01],
        [ 9.8188e-02, -3.9266e-01,  4.7296e-04],
        [ 9.1968e-02, -3.2223e-01,  9.3805e-03],
        [ 6.8275e-02, -9.9972e-02,  1.3795e-01],
        [ 7.1841e-02, -1.7424e-01,  1.2998e-01],
        [ 7.4502e-02, -2.2693e-01,  7.3854e-02],
        [ 8.5525e-02, -2.7358e-01,  2.6538e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 32
Episode Length = 81
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1275,  1.1207,  1.1201,  1.1230,  1.1320,  1.1322,  1.1365,  1.1304,
         1.1292,  1.1295,  1.1305, -5.0000,  0.0000,  0.0000,  0.0000,  0.1316,
         1.1306,  1.1269,  1.1360,  1.1418,  1.1427,  1.1420,  1.1317,  1.1303,
         1.1294,  1.1363,  1.1436,  1.1399,  1.1436,  1.1463,  1.1457,  1.1446,
         1.1385,  1.1373,  1.1390,  1.1366,  1.1394,  1.1324,  1.1330,  1.1303,
         1.1305,  1.1333,  1.0000], device='cuda:0')
target_q_episode tensor([ 5.7800,  5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555, -0.3627,
        -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        14.9931, 14.7296, 14.4522, 14.1602, 13.8529, 13.5293, 13.1888, 12.8303,
        12.4529, 12.0557, 11.6376, 11.1975, 10.7342, 10.2465,  9.7332,  9.1928,
         8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,
         2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1369,  1.1286,  1.1264,  1.1276,  1.1349,  1.1332,  1.1355,  1.1274,
         1.1240,  1.1220,  1.1206, -5.0000,  0.0000,  0.0000,  0.0000,  0.1313,
         1.1587,  1.1545,  1.1630,  1.1682,  1.1685,  1.1671,  1.1561,  1.1541,
         1.1524,  1.1585,  1.1649,  1.1603,  1.1630,  1.1648,  1.1632,  1.1609,
         1.1537,  1.1513,  1.1517,  1.1479,  1.1493,  1.1408,  1.1398,  1.1355,
         1.1340,  1.1349,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.6922e-02, -2.8017e-01,  9.3499e-04],
        [ 9.4887e-02, -1.9685e-01,  1.9323e-03],
        [ 9.6447e-02, -2.0851e-01,  1.2557e-03],
        [ 9.6647e-02, -2.2907e-01,  1.0476e-03],
        [ 9.8543e-02, -1.9821e-01,  1.4797e-04],
        [ 9.8112e-02, -2.8047e-01,  3.0103e-04],
        [ 9.8651e-02, -3.0962e-01,  2.4131e-04],
        [ 9.8932e-02, -2.9886e-01,  1.3930e-04],
        [ 9.9199e-02, -3.3183e-01,  1.2255e-04],
        [ 9.8006e-02, -2.7782e-01,  4.6983e-04],
        [ 9.9012e-02, -3.0593e-01,  1.6344e-04],
        [ 9.8679e-02, -2.3401e-01,  2.8959e-04],
        [ 9.8642e-02, -2.5624e-01,  2.5952e-04],
        [ 9.8513e-02, -2.7845e-01,  2.7430e-04],
        [ 9.8993e-02, -3.2246e-01,  1.3602e-04],
        [ 9.8886e-02, -2.9352e-01,  2.1276e-04],
        [ 9.9408e-02, -3.5096e-01,  9.8318e-05],
        [ 9.9425e-02, -3.6588e-01,  5.9873e-05],
        [ 9.9467e-02, -3.7198e-01,  6.0588e-05],
        [ 9.9645e-02, -3.8984e-01,  2.1487e-05],
        [ 9.9623e-02, -3.8855e-01,  4.0233e-05],
        [ 9.9899e-02, -3.9882e-01,  2.5630e-06],
        [ 9.9981e-02, -3.9977e-01,  1.4901e-07],
        [ 9.9945e-02, -3.9894e-01,  1.7881e-06],
        [ 9.9923e-02, -3.9886e-01,  2.0862e-06],
        [ 9.9596e-02, -3.9513e-01,  3.0756e-05],
        [ 9.9814e-02, -3.9493e-01,  1.3798e-05],
        [ 9.9847e-02, -3.9760e-01,  1.0014e-05],
        [ 9.9820e-02, -3.9801e-01,  1.4007e-05],
        [ 9.9760e-02, -3.9873e-01,  1.9222e-05],
        [ 9.8935e-02, -3.8478e-01,  2.7758e-04],
        [ 9.7878e-02, -3.4375e-01,  7.8592e-04],
        [ 9.5857e-02, -2.8967e-01,  4.8565e-03],
        [ 8.0730e-02, -2.1806e-02,  7.8885e-02],
        [ 8.1968e-02, -4.5343e-02,  5.2642e-02],
        [ 7.0538e-02, -9.6574e-02,  1.3639e-01],
        [ 6.3487e-02, -1.5339e-01,  2.2573e-01],
        [ 5.2104e-02, -7.7893e-02,  3.8717e-01],
        [ 9.2213e-02, -1.2908e-01,  4.2287e-03],
        [ 9.6377e-02, -2.7436e-01,  8.9437e-04],
        [ 9.5386e-02, -1.9642e-01,  2.0257e-03],
        [ 9.4392e-02, -2.5575e-01,  2.3873e-03],
        [ 8.9324e-02, -2.7103e-01,  5.1107e-03],
        [ 9.1551e-02, -2.7590e-01,  4.7246e-03],
        [ 9.2275e-02, -2.3760e-01,  3.4407e-03],
        [ 9.7748e-02, -3.1836e-01,  4.3952e-04],
        [ 9.7723e-02, -1.3066e-01,  7.3835e-04],
        [ 9.8505e-02, -2.7405e-01,  3.9586e-04],
        [ 9.8818e-02, -3.3726e-01,  1.6814e-04],
        [ 9.7504e-02, -2.3281e-01,  7.3496e-04],
        [ 9.9131e-02, -3.2773e-01,  1.1322e-04],
        [ 9.5361e-02, -1.6615e-01,  3.8340e-03],
        [ 9.5339e-02, -3.9252e-02,  2.8787e-03],
        [ 9.3883e-02, -1.4091e-01,  5.6353e-03],
        [ 9.6204e-02, -1.4876e-01,  2.9776e-03],
        [ 9.6023e-02, -2.5730e-01,  2.5357e-03],
        [ 9.7263e-02, -3.6011e-01,  1.4808e-03],
        [ 9.4426e-02, -3.3197e-01,  4.9321e-03],
        [ 9.1929e-02, -2.2328e-01,  8.7394e-03],
        [ 9.7313e-02, -2.5900e-01,  1.3721e-03],
        [ 9.9269e-02, -3.8751e-01,  1.2076e-04],
        [ 9.7467e-02, -3.3545e-01,  9.7486e-04],
        [ 9.9415e-02, -3.7559e-01,  7.3820e-05],
        [ 9.5646e-02, -2.6790e-01,  3.9111e-03],
        [ 9.4771e-02, -2.5127e-01,  6.9130e-03],
        [ 9.9644e-02, -3.9448e-01,  2.7329e-05],
        [ 9.9666e-02, -3.9820e-01,  1.6540e-05],
        [ 9.9813e-02, -3.9926e-01,  6.2585e-06],
        [ 9.9876e-02, -3.9803e-01,  1.4991e-05],
        [ 9.9879e-02, -3.9883e-01,  7.3910e-06],
        [ 9.8858e-02, -3.8790e-01,  3.2833e-04],
        [ 9.9649e-02, -3.9740e-01,  4.7028e-05],
        [ 9.9452e-02, -3.9771e-01,  4.9651e-05],
        [ 9.7931e-02, -3.8341e-01,  7.1567e-04],
        [ 9.6008e-02, -3.6274e-01,  1.7845e-03],
        [ 9.3990e-02, -3.6296e-01,  3.1995e-03],
        [ 7.3273e-02, -1.0442e-01,  1.1234e-01],
        [ 7.7457e-02, -5.5124e-02,  8.0178e-02],
        [ 4.7068e-02, -1.1017e-02,  4.1532e-01],
        [ 5.2818e-02, -7.1484e-02,  3.1253e-01],
        [ 3.3661e-02, -5.2278e-02,  4.8357e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 33
Episode Length = 105
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1248,  1.1251,  1.1313,  1.1344,  1.1312,  1.1330,  1.1307,  1.1350,
         1.1318,  1.1294,  1.1286,  1.1249,  1.1247,  1.1236,  1.1224,  1.1243,
         1.1269,  1.1227,  1.1331,  1.1302,  1.1342,  1.1328,  1.1346,  1.1396,
         1.1342,  1.1244,  1.1298,  1.1288,  1.1315,  1.1328,  1.1361,  1.1351,
         1.1362,  1.1330,  1.1279,  1.1316,  1.1355,  1.1391,  1.1409,  1.1401,
         1.1411,  1.1413,  1.1400,  1.1341,  1.1314,  1.1313, -4.0000,  0.0000,
         0.0000,  0.1403,  1.1314,  1.1246,  1.1254,  1.1267,  1.1258, -8.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q_episode tensor([17.7328, 17.6134, 17.4878, 17.3556, 17.2164, 17.0699, 16.9157, 16.7534,
        16.5825, 16.4026, 16.2133, 16.0140, 15.8042, 15.5834, 15.3509, 15.1062,
        14.8487, 14.5775, 14.2922, 13.9917, 13.6755, 13.3426, 12.9923, 12.6234,
        12.2352, 11.8265, 11.3963, 10.9435, 10.4669,  9.9651,  9.4370,  8.8810,
         8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000, -1.6659, -2.8062, -4.0065, -5.2700, -6.6000, -8.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q tensor([ 1.1523,  1.1525,  1.1585,  1.1613,  1.1579,  1.1595,  1.1569,  1.1609,
         1.1574,  1.1547,  1.1537,  1.1496,  1.1491,  1.1476,  1.1461,  1.1475,
         1.1497,  1.1451,  1.1550,  1.1515,  1.1550,  1.1531,  1.1543,  1.1587,
         1.1527,  1.1422,  1.1469,  1.1451,  1.1470,  1.1474,  1.1499,  1.1480,
         1.1481,  1.1439,  1.1377,  1.1402,  1.1429,  1.1453,  1.1458,  1.1436,
         1.1431,  1.1418,  1.1389,  1.1313,  1.1268,  1.1248, -4.0000,  0.0000,
         0.0000,  0.1401,  1.1267,  1.1181,  1.1169,  1.1161,  1.1129, -8.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.0724e-02, -1.1247e-01,  1.9429e-02],
        [ 7.6992e-02, -1.1015e-01,  2.5336e-02],
        [ 8.1781e-02, -1.0677e-01,  1.8296e-02],
        [ 8.7068e-02, -1.1063e-01,  7.4059e-03],
        [ 8.7530e-02, -7.1960e-03,  7.5623e-03],
        [ 8.3047e-02, -1.5740e-01,  1.3786e-02],
        [ 8.7803e-02, -1.1736e-01,  7.9060e-03],
        [ 8.9621e-02, -2.4994e-01,  6.9425e-03],
        [ 9.3437e-02, -3.2168e-01,  3.5143e-03],
        [ 8.8781e-02, -1.7484e-01,  8.2787e-03],
        [ 9.0854e-02, -1.5985e-01,  6.0933e-03],
        [ 8.2544e-02, -9.9629e-02,  1.6619e-02],
        [ 9.2083e-02, -8.1450e-02,  3.5311e-03],
        [ 9.5102e-02, -1.5793e-02,  9.5189e-04],
        [ 9.4940e-02, -3.2801e-02,  1.0003e-03],
        [ 9.7110e-02,  2.0985e-02,  3.7253e-04],
        [ 9.5371e-02,  5.1290e-02,  1.5983e-03],
        [ 9.7647e-02, -2.4198e-02,  3.9870e-04],
        [ 9.6972e-02, -8.3035e-02,  5.5692e-04],
        [ 9.6070e-02,  5.7069e-02,  1.0782e-03],
        [ 9.5947e-02, -2.3750e-02,  1.0405e-03],
        [ 9.6999e-02, -1.4849e-01,  7.9224e-04],
        [ 9.7585e-02, -8.5360e-02,  4.6936e-04],
        [ 9.6596e-02, -5.6333e-02,  1.2408e-03],
        [ 9.6031e-02, -2.7878e-02,  1.9418e-03],
        [ 9.7784e-02, -1.4737e-01,  4.8712e-04],
        [ 9.7710e-02, -1.3946e-01,  5.0130e-04],
        [ 9.7652e-02, -1.1776e-01,  5.8433e-04],
        [ 9.5125e-02, -1.5447e-02,  1.9442e-03],
        [ 9.5586e-02, -4.3483e-02,  1.5269e-03],
        [ 9.6083e-02, -1.1731e-01,  1.2519e-03],
        [ 9.4901e-02, -3.6096e-02,  2.4816e-03],
        [ 9.3051e-02, -1.0221e-01,  4.1725e-03],
        [ 9.3802e-02, -5.5407e-02,  3.3888e-03],
        [ 9.2774e-02, -4.9520e-02,  5.2543e-03],
        [ 8.9570e-02, -8.5204e-02,  1.4333e-02],
        [ 8.3447e-02, -8.8742e-02,  3.0125e-02],
        [ 8.3172e-02, -1.1138e-02,  2.6642e-02],
        [ 8.4483e-02,  4.0385e-03,  2.3226e-02],
        [ 6.6813e-02, -9.1178e-02,  1.1300e-01],
        [ 5.7118e-02, -9.7269e-02,  1.9233e-01],
        [ 4.3204e-02, -2.5349e-03,  3.4816e-01],
        [ 6.9165e-02, -1.8050e-02,  4.8795e-02],
        [ 6.9371e-02,  6.8132e-03,  3.8423e-02],
        [ 5.3714e-02,  1.2488e-02,  1.1168e-01],
        [ 4.9254e-02, -5.1437e-03,  1.5047e-01],
        [ 8.3367e-02,  5.5566e-02,  7.4793e-03],
        [ 9.0439e-02, -2.7097e-01,  6.0242e-03],
        [ 7.3151e-02, -5.9076e-02,  3.8329e-02],
        [ 8.4967e-02, -1.6880e-01,  1.2497e-02],
        [ 9.0171e-02, -2.5390e-01,  6.1679e-03],
        [ 9.1775e-02, -1.9263e-01,  3.8449e-03],
        [ 9.9023e-02, -3.7564e-01,  1.0487e-04],
        [ 9.5493e-02, -2.1762e-01,  2.1235e-03],
        [ 9.3208e-02, -2.6279e-01,  3.2720e-03],
        [ 7.8914e-02, -1.0177e-01,  2.6802e-02],
        [ 8.0449e-02, -1.0958e-01,  3.0438e-02],
        [ 8.1204e-02,  6.2929e-02,  1.9714e-02],
        [ 9.1878e-02,  6.2673e-02,  3.4822e-03],
        [ 9.5570e-02,  7.6860e-02,  1.0535e-03],
        [ 8.8306e-02,  4.2017e-02,  1.0115e-02],
        [ 8.7512e-02, -7.5645e-02,  8.3897e-03],
        [ 9.0634e-02, -4.5680e-02,  7.8205e-03],
        [ 9.3210e-02, -1.9976e-01,  5.5957e-03],
        [ 9.4070e-02, -2.0757e-01,  3.6755e-03],
        [ 8.9768e-02, -1.9256e-01,  1.1838e-02],
        [ 8.9645e-02, -8.1235e-02,  1.3110e-02],
        [ 8.8979e-02,  8.3823e-02,  9.9235e-03],
        [ 9.5030e-02,  6.7244e-03,  1.4732e-03],
        [ 9.5706e-02, -1.3096e-01,  1.3918e-03],
        [ 9.7898e-02, -3.6887e-01,  1.1547e-03],
        [ 9.7024e-02, -3.6686e-01,  1.3884e-03],
        [ 9.8514e-02, -3.9321e-01,  3.4380e-04],
        [ 9.8188e-02, -3.8671e-01,  4.3738e-04],
        [ 9.4203e-02, -3.2524e-01,  4.1800e-03],
        [ 9.8373e-02, -3.7005e-01,  6.6772e-04],
        [ 9.9060e-02, -3.9400e-01,  2.0576e-04],
        [ 9.7488e-02, -3.5466e-01,  1.2158e-03],
        [ 9.9301e-02, -3.9792e-01,  8.4549e-05],
        [ 9.9682e-02, -3.9970e-01,  1.3530e-05],
        [ 9.9890e-02, -3.9983e-01,  2.7120e-06],
        [ 9.9872e-02, -3.9983e-01,  2.8312e-06],
        [ 9.9824e-02, -3.9978e-01,  4.7386e-06],
        [ 9.9901e-02, -3.9990e-01,  2.1160e-06],
        [ 9.9667e-02, -3.9927e-01,  3.7581e-05],
        [ 9.9530e-02, -3.9448e-01,  2.0298e-04],
        [ 9.7986e-02, -3.6805e-01,  1.5967e-03],
        [ 9.7395e-02, -3.5303e-01,  1.7627e-03],
        [ 9.9517e-02, -3.9828e-01,  9.8616e-05],
        [ 9.9866e-02, -3.9951e-01,  9.7454e-06],
        [ 9.9990e-02, -3.9999e-01,  5.9605e-08],
        [ 9.9623e-02, -3.9790e-01,  1.7777e-04],
        [ 9.6707e-02, -1.3482e-01,  3.2662e-03],
        [ 8.7758e-02,  6.7138e-02,  1.8641e-02],
        [ 8.2454e-02,  1.5292e-02,  4.3774e-02],
        [ 7.9685e-02,  5.6149e-02,  8.7085e-02],
        [ 9.3990e-02, -2.9807e-01,  1.4095e-02],
        [ 9.0166e-02, -2.4225e-01,  3.1620e-02],
        [ 9.1946e-02, -2.3830e-01,  1.3511e-02],
        [ 9.3967e-02, -3.4652e-01,  1.3940e-02],
        [ 8.8249e-02, -1.5366e-01,  3.3520e-02],
        [ 9.2483e-02, -1.3669e-01,  1.3811e-02],
        [ 7.2092e-02,  9.5531e-05,  1.1192e-01],
        [ 9.3023e-02,  1.1104e-01,  8.0377e-03],
        [ 9.1925e-02,  1.7665e-02,  1.7958e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 34
Episode Length = 88
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1275,  1.1224,  1.1323,  1.1307,  1.1321,  1.1247,  1.1233, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1480,  1.1413,  1.1311,  1.1307,  1.1324,
         1.1359,  1.1369, -5.0000,  0.0000,  0.0000,  0.0000,  0.1451,  1.1446,
         1.1508,  1.1493,  1.1434,  1.1370,  1.1390, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1553,  1.1467,  1.1399,  1.1392,  1.1411, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1452,  1.1309,  1.1280,  1.1294,
         1.1390,  1.0000], device='cuda:0')
target_q_episode tensor([ 2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  1.6227,  0.6555, -0.3627, -1.4344,
        -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.6227,
         0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -1.9917, -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.5244,  3.7099,  2.8525,
         1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1294,  1.1231,  1.1317,  1.1286,  1.1286,  1.1197,  1.1166, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1478,  1.1419,  1.1304,  1.1287,  1.1289,
         1.1308,  1.1302, -5.0000,  0.0000,  0.0000,  0.0000,  0.1449,  1.1453,
         1.1502,  1.1472,  1.1399,  1.1319,  1.1324, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1551,  1.1425,  1.1341,  1.1317,  1.1319, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1450,  1.1355,  1.1315,  1.1318,
         1.1401,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.4441e-02, -1.6397e-01,  3.0409e-03],
        [ 8.9493e-02, -8.3243e-02,  7.9099e-03],
        [ 9.6273e-02, -1.1717e-01,  1.4192e-03],
        [ 9.4382e-02, -1.4570e-01,  2.3468e-03],
        [ 9.7522e-02, -1.8760e-01,  5.0023e-04],
        [ 9.8204e-02, -1.8468e-01,  3.2693e-04],
        [ 9.8860e-02, -2.6100e-01,  1.9079e-04],
        [ 9.6586e-02, -1.2491e-01,  1.1099e-03],
        [ 9.7239e-02, -9.5911e-02,  9.7251e-04],
        [ 9.6029e-02, -1.3461e-01,  1.6218e-03],
        [ 9.6543e-02, -1.0637e-01,  1.4115e-03],
        [ 9.8506e-02, -1.7021e-01,  3.2505e-04],
        [ 9.8034e-02, -1.3544e-01,  4.2579e-04],
        [ 9.6790e-02, -1.3303e-01,  1.5210e-03],
        [ 9.9055e-02, -2.4727e-01,  1.4427e-04],
        [ 9.7205e-02, -1.1635e-01,  1.0163e-03],
        [ 9.9304e-02, -2.8152e-01,  1.1206e-04],
        [ 9.9197e-02, -2.4081e-01,  2.0045e-04],
        [ 9.9379e-02, -3.4200e-01,  8.9020e-05],
        [ 9.9699e-02, -3.7799e-01,  2.1935e-05],
        [ 9.9638e-02, -3.7503e-01,  3.6836e-05],
        [ 9.9862e-02, -3.9109e-01,  7.2718e-06],
        [ 9.9905e-02, -3.9493e-01,  3.5465e-06],
        [ 9.9966e-02, -3.9913e-01,  3.2783e-07],
        [ 9.9980e-02, -3.9938e-01,  2.0862e-07],
        [ 9.8996e-02, -3.6465e-01,  1.3947e-04],
        [ 9.9625e-02, -3.8065e-01,  4.7654e-05],
        [ 9.9720e-02, -3.9309e-01,  3.9399e-05],
        [ 9.9541e-02, -3.8699e-01,  9.4861e-05],
        [ 9.9795e-02, -3.9636e-01,  1.4812e-05],
        [ 9.8943e-02, -3.7429e-01,  1.5697e-04],
        [ 9.8178e-02, -3.4772e-01,  4.1568e-04],
        [ 9.4027e-02, -9.9493e-02,  1.1221e-02],
        [ 8.1936e-02,  3.4311e-02,  6.5452e-02],
        [ 7.6625e-02, -1.3207e-02,  1.1787e-01],
        [ 6.8319e-02, -1.8533e-02,  1.5906e-01],
        [ 6.0402e-02, -4.3656e-02,  2.4645e-01],
        [ 4.5979e-02,  1.2811e-02,  5.3135e-01],
        [ 8.8585e-02, -1.3347e-01,  7.7868e-03],
        [ 8.5527e-02, -1.8400e-01,  1.3913e-02],
        [ 8.8107e-02, -1.0621e-01,  8.0358e-03],
        [ 8.1678e-02, -7.0863e-02,  2.4602e-02],
        [ 9.3788e-02, -2.0570e-01,  2.8136e-03],
        [ 8.8178e-02, -7.3905e-02,  8.6859e-03],
        [ 8.9453e-02, -1.0258e-01,  6.7573e-03],
        [ 8.4654e-02, -1.6149e-01,  1.2350e-02],
        [ 8.4503e-02, -1.7951e-01,  1.1268e-02],
        [ 7.4039e-02, -6.2724e-02,  5.3146e-02],
        [ 7.9359e-02,  5.2322e-03,  2.9090e-02],
        [ 9.3848e-02, -2.8059e-01,  4.0687e-03],
        [ 9.7716e-02, -2.2709e-01,  7.2214e-04],
        [ 8.9618e-02,  1.7896e-01,  9.6642e-03],
        [ 9.5863e-02, -1.4662e-01,  1.6387e-03],
        [ 9.1497e-02, -2.1571e-01,  7.1081e-03],
        [ 9.3279e-02, -1.6443e-01,  5.4029e-03],
        [ 8.8566e-02, -1.3439e-01,  1.7354e-02],
        [ 8.4798e-02, -5.9679e-02,  2.2281e-02],
        [ 7.9746e-02, -7.3819e-02,  4.8886e-02],
        [ 9.4852e-02, -3.0606e-01,  5.6502e-03],
        [ 9.7575e-02, -2.4242e-01,  1.2848e-03],
        [ 9.6499e-02, -2.4839e-01,  2.4131e-03],
        [ 9.4446e-02, -2.4817e-01,  3.5756e-03],
        [ 9.3283e-02, -2.3129e-01,  4.1685e-03],
        [ 9.7824e-02, -3.5239e-01,  5.5006e-04],
        [ 9.9286e-02, -3.7424e-01,  1.5751e-04],
        [ 9.9423e-02, -3.6765e-01,  1.5414e-04],
        [ 9.9184e-02, -3.6242e-01,  2.5818e-04],
        [ 9.8707e-02, -3.6544e-01,  2.9251e-04],
        [ 9.8861e-02, -3.7359e-01,  1.5068e-04],
        [ 9.8859e-02, -3.7372e-01,  1.8305e-04],
        [ 9.9737e-02, -3.9125e-01,  5.2691e-05],
        [ 9.9136e-02, -3.8724e-01,  2.0283e-04],
        [ 9.9569e-02, -3.9644e-01,  7.3224e-05],
        [ 9.9600e-02, -3.9253e-01,  5.0128e-05],
        [ 9.9303e-02, -3.9451e-01,  2.2048e-04],
        [ 9.9610e-02, -3.9421e-01,  3.4332e-05],
        [ 9.9865e-02, -3.9840e-01,  1.3232e-05],
        [ 9.9584e-02, -3.9351e-01,  1.1456e-04],
        [ 9.9895e-02, -3.9911e-01,  8.9705e-06],
        [ 9.9742e-02, -3.9563e-01,  2.2918e-05],
        [ 9.9596e-02, -3.9793e-01,  3.6627e-05],
        [ 9.9475e-02, -3.9238e-01,  7.8470e-05],
        [ 9.2092e-02, -2.2409e-01,  2.0963e-02],
        [ 6.8466e-02,  1.4474e-01,  1.8638e-01],
        [ 6.5996e-02,  9.9289e-02,  1.5651e-01],
        [ 6.0755e-02,  1.0775e-01,  1.9009e-01],
        [ 5.3687e-02,  1.8026e-02,  3.3322e-01],
        [ 5.7310e-02,  3.3356e-02,  2.9251e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 35
Episode Length = 89
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1256,  1.1276,  1.1311,  1.1286,  1.1316,  1.1286,  1.1356,  1.1320,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1228,  1.1329,
         1.1313,  1.1325,  1.1375,  1.1428,  1.1366,  1.1436,  1.1415,  1.1341,
         1.1332,  1.1286, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1490,
         1.1479,  1.1492,  1.1441,  1.1408,  1.1416,  1.1388,  1.1350,  1.1321,
         1.1308,  1.1329,  1.1455,  1.1436,  1.1426,  1.1473,  1.0000],
       device='cuda:0')
target_q_episode tensor([ 2.0876,  1.1449,  0.1525, -0.8921, -1.9917, -3.1491, -4.3675, -5.6500,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  5.2112,
         4.4328,  3.6135,  2.7511,  1.8432,  0.8876, -0.1183, -1.1772, -2.2917,
        -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        10.7342, 10.2465,  9.7332,  9.1928,  8.6240,  8.0253,  7.3950,  6.7316,
         6.0333,  5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000],
       device='cuda:0')
target_q tensor([ 1.1266,  1.1276,  1.1300,  1.1264,  1.1282,  1.1238,  1.1294,  1.1244,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1226,  1.1374,
         1.1350,  1.1352,  1.1393,  1.1436,  1.1364,  1.1422,  1.1390,  1.1302,
         1.1281,  1.1221, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1488,
         1.1586,  1.1593,  1.1537,  1.1498,  1.1499,  1.1465,  1.1420,  1.1384,
         1.1362,  1.1375,  1.1493,  1.1465,  1.1445,  1.1482,  1.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 6.3533e-02, -1.2686e-01,  7.4966e-02],
        [ 7.9878e-02, -1.9405e-01,  1.8278e-02],
        [ 8.5034e-02, -2.0276e-01,  1.3788e-02],
        [ 7.6157e-02, -1.5299e-01,  2.9877e-02],
        [ 9.2019e-02, -2.7101e-01,  3.5609e-03],
        [ 9.0261e-02, -2.2301e-01,  6.5277e-03],
        [ 9.1636e-02, -2.4210e-01,  4.0968e-03],
        [ 9.0610e-02, -2.1918e-01,  5.6363e-03],
        [ 8.6080e-02,  2.1779e-02,  1.1149e-02],
        [ 8.2587e-02, -2.1202e-03,  1.4317e-02],
        [ 8.6462e-02, -5.2156e-02,  9.6408e-03],
        [ 8.8599e-02,  1.0834e-02,  6.6673e-03],
        [ 9.0222e-02,  3.1543e-02,  5.0890e-03],
        [ 9.2997e-02, -3.9262e-03,  2.5619e-03],
        [ 9.4552e-02,  3.6903e-02,  1.7167e-03],
        [ 9.6740e-02,  2.7062e-04,  6.2326e-04],
        [ 9.6027e-02, -2.6153e-02,  9.3755e-04],
        [ 9.7731e-02,  3.2134e-02,  4.4295e-04],
        [ 9.8229e-02, -7.0666e-02,  2.0614e-04],
        [ 9.8728e-02, -5.0937e-02,  1.4091e-04],
        [ 9.6934e-02,  1.2726e-02,  6.7687e-04],
        [ 9.8226e-02, -2.9489e-02,  2.3711e-04],
        [ 9.4363e-02,  6.0922e-02,  2.7545e-03],
        [ 9.5320e-02,  6.8544e-03,  2.9595e-03],
        [ 9.2343e-02, -1.7551e-01,  6.0851e-03],
        [ 9.5316e-02, -2.7418e-01,  3.2657e-03],
        [ 9.8657e-02, -3.8680e-01,  1.3319e-04],
        [ 9.9775e-02, -3.9644e-01,  1.4126e-05],
        [ 9.9717e-02, -3.9488e-01,  4.5776e-05],
        [ 9.9915e-02, -3.9937e-01,  1.8477e-06],
        [ 9.7566e-02, -1.9453e-01,  1.2086e-03],
        [ 9.0782e-02, -8.5137e-02,  7.0116e-03],
        [ 9.2987e-02, -1.8725e-01,  5.8986e-03],
        [ 9.9974e-02, -3.9973e-01,  1.7881e-07],
        [ 9.9886e-02, -3.9720e-01,  3.2187e-06],
        [ 9.9908e-02, -3.9788e-01,  2.2948e-06],
        [ 9.9552e-02, -3.8539e-01,  4.4465e-05],
        [ 9.9070e-02, -3.5580e-01,  2.7493e-04],
        [ 9.7506e-02, -2.6452e-01,  9.7343e-04],
        [ 9.0954e-02, -1.8821e-01,  1.4142e-02],
        [ 8.6772e-02, -2.5678e-01,  2.3950e-02],
        [ 1.8337e-02,  5.9312e-02,  7.4769e-01],
        [ 5.3869e-02,  3.2000e-02,  9.3043e-02],
        [ 4.9017e-02,  5.2083e-02,  1.3288e-01],
        [ 4.6835e-02,  2.4346e-02,  1.3973e-01],
        [ 6.4734e-02,  3.1862e-02,  6.1817e-02],
        [ 6.4723e-02,  1.9661e-02,  7.1796e-02],
        [ 7.2597e-02,  1.6001e-02,  3.9756e-02],
        [ 8.1026e-02,  6.1661e-02,  1.4614e-02],
        [ 8.5266e-02,  4.3274e-02,  1.0260e-02],
        [ 9.0468e-02, -9.3594e-02,  3.5705e-03],
        [ 9.1252e-02, -4.5489e-02,  4.8465e-03],
        [ 9.4991e-02, -3.0036e-01,  1.6878e-03],
        [ 8.5338e-02, -9.0059e-02,  1.8786e-02],
        [ 9.2128e-02, -1.6243e-01,  4.0579e-03],
        [ 9.6276e-02, -3.1290e-01,  7.0965e-04],
        [ 9.8138e-02, -3.3451e-01,  2.2203e-04],
        [ 8.7597e-02, -1.0454e-01,  8.2628e-03],
        [ 8.6990e-02, -8.8182e-02,  1.0317e-02],
        [ 8.9802e-02, -2.5800e-02,  7.1621e-03],
        [ 9.1464e-02,  9.3331e-02,  5.2537e-03],
        [ 8.9752e-02,  9.7422e-02,  6.2707e-03],
        [ 8.1493e-02,  1.2262e-02,  3.1645e-02],
        [ 9.7061e-02, -2.8815e-01,  9.4700e-04],
        [ 8.4755e-02, -1.3614e-01,  2.0349e-02],
        [ 9.4855e-02, -3.4124e-01,  2.5388e-03],
        [ 8.9973e-02, -2.1596e-01,  8.6204e-03],
        [ 9.3031e-02, -2.6755e-01,  5.4337e-03],
        [ 9.1123e-02, -1.6158e-01,  1.1189e-02],
        [ 9.3070e-02,  9.5733e-02,  4.7630e-03],
        [ 9.4093e-02,  4.7237e-02,  5.2489e-03],
        [ 9.2260e-02, -1.3797e-02,  1.2898e-02],
        [ 9.3087e-02, -1.8295e-01,  8.4538e-03],
        [ 9.6925e-02, -2.9736e-01,  1.7656e-03],
        [ 9.9544e-02, -3.9485e-01,  1.8477e-05],
        [ 9.9757e-02, -3.9672e-01,  2.4617e-05],
        [ 9.8143e-02, -3.5202e-01,  7.7036e-04],
        [ 9.9632e-02, -3.9701e-01,  1.7524e-05],
        [ 9.9357e-02, -3.7737e-01,  7.2330e-05],
        [ 9.7104e-02, -2.6206e-01,  2.2856e-03],
        [ 9.0563e-02, -1.9049e-01,  1.3116e-02],
        [ 8.9577e-02, -1.8018e-01,  2.2383e-02],
        [ 9.6095e-02, -3.3231e-01,  3.9030e-03],
        [ 9.9878e-02, -3.9913e-01,  1.9372e-06],
        [ 9.9806e-02, -3.9555e-01,  1.3441e-05],
        [ 9.8370e-02, -3.7669e-01,  2.8175e-04],
        [ 8.9546e-02, -2.9589e-01,  1.1583e-02],
        [ 9.0390e-02, -2.6174e-01,  1.6338e-02],
        [ 7.6770e-02, -2.6522e-01,  8.6123e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 36
Episode Length = 82
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1409,  1.1363,  1.1338,  1.1357, -9.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1386,  1.1336,  1.1366,  1.1456,
         1.1420,  1.1426, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1440,
         1.1460,  1.1511,  1.1549,  1.1555,  1.1469,  1.1524,  1.1509, -3.0000,
         0.0000,  0.1624,  1.1614,  1.1627,  1.1615,  1.1594,  1.1542,  1.1499,
         1.1572,  1.1538,  1.1469,  1.0000], device='cuda:0')
target_q_episode tensor([-3.6207, -4.8639, -6.1725, -7.5500, -9.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1183, -1.1772, -2.2917,
        -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         3.9382,  3.0929,  2.2030,  1.2664,  0.2804, -0.7575, -1.8500, -3.0000,
         0.0000,  0.0000,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,
         3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1366,  1.1308,  1.1271,  1.1278, -9.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1385,  1.1324,  1.1345,  1.1424,
         1.1378,  1.1373, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1438,
         1.1486,  1.1529,  1.1559,  1.1556,  1.1461,  1.1507,  1.1482, -3.0000,
         0.0000,  0.1622,  1.1677,  1.1683,  1.1665,  1.1639,  1.1580,  1.1530,
         1.1595,  1.1553,  1.1476,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.6003e-02, -8.5162e-02,  1.9279e-03],
        [ 9.4355e-02, -5.2832e-02,  3.4039e-03],
        [ 9.7003e-02, -1.2782e-01,  1.1292e-03],
        [ 9.6674e-02, -2.0298e-01,  1.0662e-03],
        [ 9.7403e-02, -2.1311e-01,  4.8664e-04],
        [ 9.8119e-02, -1.3163e-01,  5.4348e-04],
        [ 9.7950e-02, -1.6640e-01,  5.1606e-04],
        [ 9.7596e-02, -1.5098e-01,  6.2919e-04],
        [ 9.8858e-02, -1.3291e-01,  2.3258e-04],
        [ 9.7680e-02, -1.3599e-01,  6.5124e-04],
        [ 9.7243e-02, -2.6226e-02,  1.0272e-03],
        [ 9.7347e-02, -4.2549e-02,  1.1345e-03],
        [ 9.6644e-02, -9.6261e-02,  1.3500e-03],
        [ 9.7038e-02, -9.0229e-02,  1.1985e-03],
        [ 9.7461e-02, -1.0953e-01,  1.0792e-03],
        [ 9.6530e-02, -1.4273e-01,  1.4489e-03],
        [ 9.8159e-02, -2.1234e-01,  6.5735e-04],
        [ 9.9181e-02, -2.8552e-01,  1.3593e-04],
        [ 9.8710e-02, -2.7424e-01,  3.1728e-04],
        [ 9.9568e-02, -3.5861e-01,  4.0203e-05],
        [ 9.9495e-02, -3.6692e-01,  7.7963e-05],
        [ 9.9838e-02, -3.8898e-01,  6.7651e-06],
        [ 9.9971e-02, -3.9793e-01,  3.5763e-07],
        [ 9.9872e-02, -3.8936e-01,  5.6326e-06],
        [ 9.9986e-02, -3.9961e-01,  8.9407e-08],
        [ 9.9143e-02, -3.5354e-01,  1.2618e-04],
        [ 9.9744e-02, -3.8569e-01,  1.9461e-05],
        [ 9.9561e-02, -3.7533e-01,  8.1182e-05],
        [ 9.9479e-02, -3.8572e-01,  1.0154e-04],
        [ 9.9867e-02, -3.9820e-01,  6.0201e-06],
        [ 9.9396e-02, -3.8545e-01,  6.9320e-05],
        [ 9.8211e-02, -3.2901e-01,  6.5079e-04],
        [ 9.3234e-02, -1.4022e-01,  1.6280e-02],
        [ 7.6527e-02,  2.2806e-02,  1.0806e-01],
        [ 8.1601e-02, -4.9346e-02,  5.4095e-02],
        [ 7.0967e-02, -6.5407e-03,  1.4865e-01],
        [ 5.6131e-02, -8.2095e-02,  3.2576e-01],
        [ 3.0246e-02, -5.7314e-02,  6.7705e-01],
        [ 9.0668e-02, -1.9495e-01,  4.9934e-03],
        [ 9.4480e-02, -1.9653e-01,  2.0431e-03],
        [ 9.5941e-02, -1.5059e-01,  1.3710e-03],
        [ 9.2148e-02, -9.9182e-02,  3.5014e-03],
        [ 9.4772e-02, -1.1436e-01,  2.0277e-03],
        [ 8.9690e-02, -1.5023e-01,  8.3363e-03],
        [ 9.6248e-02, -2.6244e-01,  1.1930e-03],
        [ 9.2391e-02,  9.1957e-02,  6.5366e-03],
        [ 9.4898e-02, -6.8851e-02,  1.7005e-03],
        [ 9.3242e-02, -7.2814e-02,  5.1701e-03],
        [ 9.8347e-02, -3.3699e-01,  3.3176e-04],
        [ 9.5539e-02, -2.8757e-01,  1.7033e-03],
        [ 9.4954e-02, -4.9977e-02,  1.7832e-03],
        [ 8.8698e-02, -9.1813e-03,  9.4710e-03],
        [ 8.7358e-02,  4.6073e-02,  1.2081e-02],
        [ 8.7485e-02,  2.1910e-02,  1.1274e-02],
        [ 8.7754e-02,  1.3846e-01,  1.8395e-02],
        [ 9.6165e-02, -4.6677e-02,  2.5281e-03],
        [ 8.8629e-02, -2.1321e-01,  1.9201e-02],
        [ 9.6311e-02, -3.3419e-01,  1.6561e-03],
        [ 9.6511e-02, -2.0130e-01,  3.2465e-03],
        [ 9.5985e-02,  1.0311e-01,  3.7274e-03],
        [ 9.7241e-02, -1.1892e-01,  1.3305e-03],
        [ 9.8419e-02, -3.5803e-01,  3.4910e-04],
        [ 9.6593e-02, -1.9267e-01,  1.7671e-03],
        [ 9.5351e-02, -2.1511e-01,  3.4082e-03],
        [ 9.7308e-02, -3.3283e-01,  1.0158e-03],
        [ 9.5055e-02, -1.0938e-01,  3.8672e-03],
        [ 9.8602e-02, -3.1785e-01,  4.2868e-04],
        [ 9.7727e-02, -2.7693e-01,  6.8945e-04],
        [ 9.8456e-02, -3.2004e-01,  2.5734e-04],
        [ 9.9176e-02, -3.5250e-01,  1.4403e-04],
        [ 9.9875e-02, -3.9813e-01,  3.8147e-06],
        [ 9.7985e-02, -3.6878e-01,  8.1757e-04],
        [ 9.9745e-02, -3.9544e-01,  2.8193e-05],
        [ 9.9425e-02, -3.9224e-01,  1.5706e-04],
        [ 9.9850e-02, -3.9759e-01,  1.2815e-05],
        [ 9.9698e-02, -3.9491e-01,  1.8060e-05],
        [ 9.9073e-02, -3.9266e-01,  1.9929e-04],
        [ 9.8948e-02, -3.9357e-01,  2.0361e-04],
        [ 9.9152e-02, -3.9451e-01,  1.0440e-04],
        [ 9.9404e-02, -3.9392e-01,  7.3224e-05],
        [ 9.6419e-02, -3.6479e-01,  2.0983e-03],
        [ 9.0649e-02, -2.3585e-01,  1.2016e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 37
Episode Length = 98
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1362,  1.1361,  1.1296,  1.1352,  1.1333,  1.1386,  1.1423,  1.1451,
         1.1424,  1.1361, -4.0000,  0.0000,  0.0000,  0.1352,  1.1303,  1.1388,
         1.1402,  1.1437,  1.1427,  1.1342,  1.1356,  1.1384,  1.1435,  1.1423,
         1.1403,  1.1408,  1.1412,  1.1399,  1.1374, -4.0000,  0.0000,  0.0000,
         0.1408,  1.1425,  1.1403,  1.1348,  1.1342,  1.1388,  1.1451,  1.1469,
         1.1404,  1.1344,  1.1370,  1.1353,  1.1382,  1.1446,  1.1457,  1.1489,
        -8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q_episode tensor([ 5.6303,  4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770,
        -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  8.8810,  8.2958,
         7.6798,  7.0314,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,  2.3578,
         1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,
         0.0000,  7.0278,  6.3451,  5.6264,  4.8699,  4.0736,  3.2354,  2.3530,
         1.4242,  0.4466, -0.5826, -1.6659, -2.8062, -4.0065, -5.2700, -6.6000,
        -8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q tensor([ 1.1395,  1.1389,  1.1318,  1.1368,  1.1342,  1.1388,  1.1417,  1.1438,
         1.1403,  1.1332, -4.0000,  0.0000,  0.0000,  0.1351,  1.1360,  1.1441,
         1.1451,  1.1481,  1.1466,  1.1376,  1.1383,  1.1406,  1.1450,  1.1432,
         1.1405,  1.1403,  1.1400,  1.1378,  1.1345, -4.0000,  0.0000,  0.0000,
         0.1407,  1.1469,  1.1442,  1.1382,  1.1370,  1.1410,  1.1467,  1.1478,
         1.1406,  1.1338,  1.1357,  1.1332,  1.1353,  1.1407,  1.1409,  1.1431,
        -8.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.6235e-02, -1.7101e-01,  3.3801e-02],
        [ 8.3310e-02, -9.9558e-02,  1.3630e-02],
        [ 8.7023e-02, -1.5459e-01,  8.9358e-03],
        [ 8.0073e-02, -3.8179e-02,  1.9888e-02],
        [ 8.2480e-02, -4.9664e-02,  1.7879e-02],
        [ 8.2303e-02, -6.9935e-02,  1.4656e-02],
        [ 9.1384e-02, -2.0917e-01,  3.5598e-03],
        [ 9.5232e-02, -2.9192e-01,  2.0143e-03],
        [ 9.6259e-02, -3.1106e-01,  1.1579e-03],
        [ 9.4412e-02, -2.7685e-01,  2.7219e-03],
        [ 9.4721e-02, -2.2664e-01,  3.3886e-03],
        [ 9.5172e-02, -1.5794e-01,  1.9476e-03],
        [ 9.4739e-02, -5.1867e-02,  1.3183e-03],
        [ 9.7311e-02, -1.3354e-01,  2.8247e-04],
        [ 9.8541e-02, -3.4076e-02,  9.9361e-05],
        [ 9.8113e-02,  4.7087e-02,  2.4402e-04],
        [ 9.9142e-02, -6.5778e-02,  5.1886e-05],
        [ 9.9561e-02, -2.5534e-01,  1.6153e-05],
        [ 9.8289e-02,  2.2628e-02,  2.4739e-04],
        [ 9.9116e-02, -6.1748e-02,  8.3029e-05],
        [ 9.8668e-02, -7.0587e-02,  2.0549e-04],
        [ 9.9376e-02, -1.1304e-01,  4.4525e-05],
        [ 9.9152e-02, -1.6685e-01,  8.6248e-05],
        [ 9.9106e-02, -1.1523e-01,  1.0163e-04],
        [ 9.7899e-02, -4.0787e-02,  6.8057e-04],
        [ 9.8833e-02, -1.5117e-01,  2.1091e-04],
        [ 9.8598e-02, -1.7441e-01,  1.9398e-04],
        [ 9.9170e-02, -2.1811e-01,  1.2758e-04],
        [ 9.8366e-02, -1.2643e-01,  2.4199e-04],
        [ 9.8557e-02, -8.5217e-02,  1.8996e-04],
        [ 9.7147e-02, -3.3159e-02,  8.6951e-04],
        [ 9.8728e-02, -9.1142e-02,  1.5989e-04],
        [ 9.6630e-02, -6.2575e-02,  1.4464e-03],
        [ 9.7495e-02, -1.2705e-01,  1.1834e-03],
        [ 9.6952e-02, -1.8793e-01,  1.6759e-03],
        [ 9.7199e-02, -1.0245e-01,  1.5278e-03],
        [ 9.2770e-02, -9.3120e-02,  8.5584e-03],
        [ 8.8744e-02, -6.0900e-02,  2.0853e-02],
        [ 8.9997e-02, -1.7556e-01,  1.5769e-02],
        [ 7.6566e-02, -1.3322e-01,  8.4452e-02],
        [ 7.1079e-02, -1.2946e-01,  1.2249e-01],
        [ 3.7662e-02, -9.8624e-02,  5.0314e-01],
        [ 8.3097e-02, -1.6671e-01,  1.5102e-02],
        [ 7.9553e-02, -1.3247e-01,  1.9304e-02],
        [ 8.0216e-02, -1.4141e-01,  2.2043e-02],
        [ 8.6097e-02, -1.4643e-01,  1.0542e-02],
        [ 7.4744e-02, -1.3897e-01,  3.7113e-02],
        [ 9.5729e-02, -3.2414e-01,  1.4854e-03],
        [ 9.5933e-02, -3.2638e-01,  1.1518e-03],
        [ 9.6565e-02, -3.5263e-01,  8.8137e-04],
        [ 9.4392e-02, -2.8881e-01,  2.3324e-03],
        [ 8.9238e-02, -1.2672e-01,  7.4234e-03],
        [ 9.5824e-02, -3.3583e-01,  1.7869e-03],
        [ 9.8953e-02, -3.7835e-01,  1.6159e-04],
        [ 9.9908e-02, -3.9553e-01,  6.0201e-06],
        [ 9.3429e-02, -1.9979e-01,  3.4714e-03],
        [ 9.7496e-02,  5.0591e-02,  4.4677e-04],
        [ 9.2012e-02,  1.0726e-01,  3.5602e-03],
        [ 9.3765e-02,  1.4742e-02,  3.1019e-03],
        [ 9.5817e-02, -7.5765e-02,  9.9200e-04],
        [ 9.6896e-02, -4.2153e-02,  5.5560e-04],
        [ 9.4745e-02, -2.3374e-02,  2.3121e-03],
        [ 9.8537e-02,  9.2846e-03,  2.0206e-04],
        [ 9.5475e-02,  7.8622e-02,  2.6077e-03],
        [ 9.8932e-02, -1.5881e-01,  1.1542e-04],
        [ 9.8638e-02, -5.6429e-02,  2.0152e-04],
        [ 9.9321e-02, -1.2216e-01,  4.4972e-05],
        [ 9.7033e-02, -3.8149e-02,  8.6415e-04],
        [ 9.8869e-02, -1.2119e-01,  1.5199e-04],
        [ 9.7911e-02,  8.3054e-03,  4.3899e-04],
        [ 9.5913e-02,  1.9581e-02,  4.1573e-03],
        [ 9.7257e-02, -6.3804e-02,  1.1844e-03],
        [ 9.7219e-02,  1.1238e-02,  1.1424e-03],
        [ 9.7717e-02, -3.2930e-02,  7.6663e-04],
        [ 9.1750e-02, -6.8067e-02,  8.7148e-03],
        [ 9.8531e-02, -2.8194e-01,  2.6676e-04],
        [ 9.8070e-02, -1.7161e-01,  4.1959e-04],
        [ 9.0644e-02, -9.3249e-02,  8.4499e-03],
        [ 8.5998e-02, -9.0823e-02,  1.7806e-02],
        [ 9.4434e-02, -2.4847e-01,  3.4744e-03],
        [ 9.2216e-02, -1.7165e-01,  9.5268e-03],
        [ 9.4779e-02, -2.3226e-01,  5.3172e-03],
        [ 7.8587e-02, -1.2509e-01,  5.6660e-02],
        [ 9.5586e-02,  7.3156e-02,  1.8120e-03],
        [ 9.2216e-02,  1.0450e-04,  7.5129e-03],
        [ 8.1059e-02, -1.1280e-01,  4.7464e-02],
        [ 8.8375e-02, -2.5153e-01,  3.2319e-02],
        [ 9.1408e-02, -3.1341e-01,  6.7562e-03],
        [ 8.3896e-02, -2.1650e-01,  3.0853e-02],
        [ 9.1629e-02, -9.3324e-02,  9.5351e-03],
        [ 8.8967e-02, -1.6919e-02,  1.2498e-02],
        [ 9.3713e-02, -1.3716e-01,  6.9957e-03],
        [ 9.1187e-02, -1.9365e-01,  1.3285e-02],
        [ 7.8536e-02, -1.3849e-01,  5.6309e-02],
        [ 8.9622e-02, -3.3504e-01,  1.2003e-02],
        [ 8.2873e-02, -2.0327e-01,  3.9315e-02],
        [ 9.2008e-02, -3.1159e-01,  1.0655e-02],
        [ 8.9905e-02, -2.6538e-01,  1.9588e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 38
Episode Length = 85
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1346,   1.1367,   1.1319,   1.1319,   1.1274,   1.1410,   1.1475,
          1.1481,   1.1403,   1.1433,   1.1483, -10.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1541,
          1.1524,   1.1564,   1.1592,   1.1648,   1.1567,   1.1584,   1.1616,
          1.1545,   1.1570,   1.1577,   1.1564,   1.1574,   1.1627,   1.1556,
          1.1495,   1.1476,   1.1525,   1.1617,   1.1568,   1.1541,   1.1563,
          1.1522,   1.1437,   1.1516,   1.1483,   1.0000], device='cuda:0')
target_q_episode tensor([  2.9360,   2.0379,   1.0925,   0.0974,  -0.9501,  -2.0528,  -3.2134,
         -4.4352,  -5.7213,  -7.0750,  -8.5000, -10.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
         14.7296,  14.4522,  14.1602,  13.8529,  13.5293,  13.1888,  12.8303,
         12.4529,  12.0557,  11.6376,  11.1975,  10.7342,  10.2465,   9.7332,
          9.1928,   8.6240,   8.0253,   7.3950,   6.7316,   6.0333,   5.2982,
          4.5244,   3.7099,   2.8525,   1.9500,   1.0000], device='cuda:0')
target_q tensor([  1.1357,   1.1373,   1.1319,   1.1313,   1.1261,   1.1391,   1.1448,
          1.1447,   1.1361,   1.1383,   1.1424, -10.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1540,
          1.1607,   1.1645,   1.1672,   1.1726,   1.1643,   1.1657,   1.1688,
          1.1614,   1.1637,   1.1641,   1.1625,   1.1632,   1.1683,   1.1608,
          1.1544,   1.1522,   1.1567,   1.1655,   1.1602,   1.1571,   1.1588,
          1.1543,   1.1453,   1.1526,   1.1488,   1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.3236e-02, -9.6548e-02,  4.9522e-03],
        [ 9.1940e-02, -8.0804e-02,  5.3578e-03],
        [ 9.6237e-02, -1.4379e-01,  1.6565e-03],
        [ 9.7885e-02, -1.6907e-01,  5.2908e-04],
        [ 9.8707e-02, -2.0195e-01,  2.5180e-04],
        [ 9.7873e-02, -1.7127e-01,  4.8012e-04],
        [ 9.7725e-02, -1.1661e-01,  5.5337e-04],
        [ 9.8273e-02, -1.6858e-01,  4.2018e-04],
        [ 9.8207e-02, -4.3008e-02,  4.2549e-04],
        [ 9.7686e-02, -8.8722e-02,  7.2205e-04],
        [ 9.8817e-02, -4.2016e-02,  2.7338e-04],
        [ 9.8196e-02, -2.2183e-02,  6.2656e-04],
        [ 9.7195e-02, -9.6258e-03,  1.2785e-03],
        [ 9.7843e-02, -8.2377e-02,  6.6811e-04],
        [ 9.8347e-02, -1.3124e-01,  4.4498e-04],
        [ 9.8452e-02, -7.8007e-02,  4.0734e-04],
        [ 9.8757e-02, -1.8870e-01,  2.6521e-04],
        [ 9.8761e-02, -1.7994e-01,  3.8737e-04],
        [ 9.9420e-02, -3.0208e-01,  7.6711e-05],
        [ 9.9434e-02, -3.2623e-01,  7.9274e-05],
        [ 9.9664e-02, -3.5259e-01,  3.8773e-05],
        [ 9.9844e-02, -3.8898e-01,  8.1956e-06],
        [ 9.9970e-02, -3.9703e-01,  3.8743e-07],
        [ 9.9983e-02, -3.9917e-01,  1.1921e-07],
        [ 9.9989e-02, -3.9935e-01,  5.9605e-08],
        [ 9.9709e-02, -3.6868e-01,  2.5183e-05],
        [ 9.9720e-02, -3.6865e-01,  2.6822e-05],
        [ 9.9825e-02, -3.9083e-01,  1.1265e-05],
        [ 9.9778e-02, -3.8848e-01,  2.0593e-05],
        [ 9.9893e-02, -3.9845e-01,  2.7716e-06],
        [ 9.9845e-02, -3.9254e-01,  6.0797e-06],
        [ 9.9219e-02, -3.7324e-01,  1.2940e-04],
        [ 9.6267e-02, -1.7671e-01,  4.4017e-03],
        [ 8.4464e-02,  5.6599e-02,  4.4985e-02],
        [ 8.0513e-02, -2.7038e-02,  7.2544e-02],
        [ 8.1966e-02, -6.6514e-02,  5.3929e-02],
        [ 6.6560e-02, -6.6495e-02,  2.2517e-01],
        [ 3.5642e-02, -5.2188e-02,  6.5962e-01],
        [ 8.7194e-02,  1.9445e-02,  1.4024e-02],
        [ 8.6573e-02,  6.9706e-02,  1.3757e-02],
        [ 8.8402e-02,  2.1998e-04,  1.3988e-02],
        [ 9.6840e-02, -2.0311e-01,  7.6431e-04],
        [ 9.4277e-02, -2.3961e-01,  2.5412e-03],
        [ 9.5149e-02, -2.3351e-01,  1.8121e-03],
        [ 9.1253e-02, -1.0766e-01,  7.0445e-03],
        [ 9.7275e-02, -2.2432e-01,  7.1952e-04],
        [ 8.9734e-02, -1.3704e-01,  8.0257e-03],
        [ 9.5221e-02, -2.7251e-01,  2.0294e-03],
        [ 9.6692e-02, -3.2980e-01,  7.6935e-04],
        [ 9.0591e-02, -1.4308e-01,  6.5935e-03],
        [ 9.4593e-02, -1.0394e-01,  3.2529e-03],
        [ 9.3711e-02,  3.7128e-02,  4.2599e-03],
        [ 9.9260e-02, -3.8402e-01,  5.7727e-05],
        [ 9.3912e-02, -1.2237e-01,  3.9782e-03],
        [ 9.5899e-02, -3.0083e-01,  1.3949e-03],
        [ 9.3376e-02, -2.4798e-01,  3.5272e-03],
        [ 9.3852e-02, -2.4773e-01,  2.8251e-03],
        [ 8.0930e-02, -1.0464e-01,  3.4746e-02],
        [ 9.3742e-02, -2.1241e-01,  4.4077e-03],
        [ 9.5524e-02, -2.2252e-01,  5.4368e-03],
        [ 9.3966e-02, -1.7573e-01,  6.3975e-03],
        [ 9.6809e-02, -2.6536e-01,  2.0633e-03],
        [ 9.7556e-02, -2.1536e-01,  1.3396e-03],
        [ 9.7488e-02, -2.5588e-01,  1.1280e-03],
        [ 9.8816e-02, -3.7836e-01,  2.1246e-04],
        [ 9.9041e-02, -3.5027e-01,  3.6424e-04],
        [ 9.7715e-02, -2.8564e-01,  1.6583e-03],
        [ 9.8792e-02, -3.5136e-01,  4.0701e-04],
        [ 9.8242e-02, -3.3247e-01,  8.8349e-04],
        [ 9.9246e-02, -3.7641e-01,  1.6272e-04],
        [ 9.9768e-02, -3.9715e-01,  1.2755e-05],
        [ 9.7226e-02, -3.4906e-01,  1.2457e-03],
        [ 9.9216e-02, -3.8493e-01,  1.4976e-04],
        [ 9.9015e-02, -3.8762e-01,  1.6576e-04],
        [ 9.7454e-02, -3.3772e-01,  7.9718e-04],
        [ 9.4303e-02, -3.4526e-01,  4.1251e-03],
        [ 9.8898e-02, -3.7409e-01,  1.8042e-04],
        [ 9.7481e-02, -3.6091e-01,  1.1435e-03],
        [ 9.7278e-02, -3.7222e-01,  1.0724e-03],
        [ 9.3941e-02, -3.0388e-01,  5.6316e-03],
        [ 7.2807e-02, -1.8422e-02,  1.4229e-01],
        [ 7.1606e-02, -9.4806e-03,  1.3090e-01],
        [ 5.2371e-02,  2.3271e-02,  2.6745e-01],
        [ 6.7994e-02, -1.4871e-01,  1.7649e-01],
        [ 7.2959e-02, -2.0808e-01,  1.4687e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 39
Episode Length = 95
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1340,  1.1373,  1.1373,  1.1409,  1.1374,  1.1443,  1.1407,  1.1364,
         1.1386,  1.1389,  1.1413,  1.1396,  1.1405,  1.1345,  1.1298,  1.1430,
         1.1423,  1.1359,  1.1374,  1.1400,  1.1366,  1.1384,  1.1291,  1.1423,
         1.1429,  1.1400,  1.1463, -5.0000,  0.0000,  0.0000,  0.0000,  0.1600,
         1.1523,  1.1514,  1.1560,  1.1562,  1.1555,  1.1547,  1.1513,  1.1430,
         1.1387,  1.1385,  1.1483,  1.1480,  1.1466,  1.1481,  1.1500,  1.1440,
         1.1408,  1.1411,  1.1479,  1.1494,  1.0000], device='cuda:0')
target_q_episode tensor([13.7414, 13.4120, 13.0653, 12.7003, 12.3161, 11.9117, 11.4860, 11.0379,
        10.5662, 10.0696,  9.5470,  8.9968,  8.4177,  7.8081,  7.1664,  6.4910,
         5.7800,  5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555, -0.3627,
        -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        13.1888, 12.8303, 12.4529, 12.0557, 11.6376, 11.1975, 10.7342, 10.2465,
         9.7332,  9.1928,  8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,
         4.5244,  3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1403,  1.1434,  1.1433,  1.1466,  1.1430,  1.1497,  1.1459,  1.1413,
         1.1433,  1.1434,  1.1455,  1.1435,  1.1442,  1.1379,  1.1328,  1.1457,
         1.1446,  1.1379,  1.1390,  1.1411,  1.1373,  1.1386,  1.1289,  1.1415,
         1.1416,  1.1382,  1.1439, -5.0000,  0.0000,  0.0000,  0.0000,  0.1600,
         1.1583,  1.1573,  1.1616,  1.1617,  1.1607,  1.1598,  1.1561,  1.1476,
         1.1430,  1.1425,  1.1521,  1.1515,  1.1497,  1.1509,  1.1524,  1.1460,
         1.1425,  1.1424,  1.1488,  1.1498,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.3991e-02, -1.5891e-01,  3.3681e-02],
        [ 8.0907e-02, -1.2111e-01,  2.2224e-02],
        [ 8.6500e-02, -1.4169e-01,  1.2802e-02],
        [ 9.0726e-02, -2.1734e-01,  6.8449e-03],
        [ 9.2211e-02, -2.0663e-01,  4.4912e-03],
        [ 9.0013e-02, -1.4697e-01,  6.1013e-03],
        [ 9.5116e-02, -1.4761e-01,  1.6834e-03],
        [ 9.3723e-02, -2.1680e-01,  2.9828e-03],
        [ 9.0403e-02,  4.2520e-03,  5.8811e-03],
        [ 9.2243e-02,  3.8469e-02,  3.5194e-03],
        [ 9.3724e-02, -3.3466e-02,  1.8893e-03],
        [ 9.4639e-02, -1.0631e-02,  1.6337e-03],
        [ 9.2834e-02,  2.6381e-02,  2.6683e-03],
        [ 9.5632e-02,  4.1992e-02,  1.2046e-03],
        [ 9.6307e-02,  7.3169e-02,  8.5211e-04],
        [ 9.7006e-02,  3.9190e-02,  5.7521e-04],
        [ 9.7274e-02,  5.7964e-02,  5.5486e-04],
        [ 9.8757e-02,  3.9391e-02,  1.2329e-04],
        [ 9.8565e-02, -2.8081e-02,  2.3523e-04],
        [ 9.8362e-02, -5.3511e-02,  2.6274e-04],
        [ 9.8731e-02, -1.1507e-02,  1.9091e-04],
        [ 9.8876e-02, -6.5568e-02,  1.0043e-04],
        [ 9.5317e-02,  6.0395e-02,  1.9413e-03],
        [ 9.7813e-02, -1.3782e-01,  9.2745e-04],
        [ 9.6336e-02, -2.2029e-01,  1.2040e-03],
        [ 9.3634e-02, -1.4591e-01,  4.6725e-03],
        [ 9.9624e-02, -3.9477e-01,  9.3281e-06],
        [ 9.9681e-02, -3.9272e-01,  1.6958e-05],
        [ 9.9355e-02, -3.7812e-01,  1.1891e-04],
        [ 9.9898e-02, -3.9819e-01,  2.5332e-06],
        [ 9.8056e-02, -2.3241e-01,  5.5352e-04],
        [ 8.7362e-02,  1.9468e-02,  1.3043e-02],
        [ 9.5099e-02, -1.6747e-01,  2.5293e-03],
        [ 9.9855e-02, -3.9466e-01,  4.9174e-06],
        [ 9.9927e-02, -3.9769e-01,  1.4305e-06],
        [ 9.9963e-02, -3.9779e-01,  6.5565e-07],
        [ 9.9638e-02, -3.6048e-01,  5.3495e-05],
        [ 9.6611e-02, -1.7202e-01,  2.5918e-03],
        [ 9.5204e-02, -2.4713e-01,  4.9545e-03],
        [ 7.8956e-02, -1.7322e-01,  5.3844e-02],
        [ 1.1286e-02, -3.7147e-02,  7.9926e-01],
        [ 7.6975e-02, -7.1799e-02,  2.7263e-02],
        [ 6.3888e-02, -6.7697e-02,  6.4023e-02],
        [ 7.0997e-02, -3.0102e-02,  3.9765e-02],
        [ 7.9815e-02, -2.3596e-02,  1.9252e-02],
        [ 7.5821e-02,  4.6118e-03,  3.7113e-02],
        [ 7.9213e-02, -3.1296e-02,  2.7845e-02],
        [ 7.6280e-02, -5.7149e-02,  2.9247e-02],
        [ 7.5070e-02, -6.8621e-02,  3.4512e-02],
        [ 8.8682e-02,  1.4510e-02,  5.7059e-03],
        [ 7.6398e-02,  4.0990e-02,  3.0885e-02],
        [ 8.6198e-02, -8.3959e-02,  1.1063e-02],
        [ 8.0059e-02,  2.3086e-02,  2.2566e-02],
        [ 8.7570e-02,  8.4473e-04,  8.1063e-03],
        [ 9.5450e-02,  8.1440e-02,  9.0811e-04],
        [ 9.4636e-02,  6.7558e-03,  1.4631e-03],
        [ 9.1469e-02,  4.6270e-02,  4.0233e-03],
        [ 9.2233e-02,  3.4643e-03,  3.9996e-03],
        [ 9.4569e-02,  4.3944e-02,  1.4016e-03],
        [ 9.3058e-02, -1.2423e-02,  2.8481e-03],
        [ 9.5822e-02,  4.1030e-02,  1.0544e-03],
        [ 9.3062e-02,  2.4993e-02,  3.1711e-03],
        [ 9.1917e-02,  8.8834e-04,  5.8940e-03],
        [ 9.5540e-02,  6.2890e-03,  1.2037e-03],
        [ 9.3699e-02,  2.1866e-02,  2.4374e-03],
        [ 9.7148e-02,  5.0783e-02,  6.5607e-04],
        [ 9.3611e-02,  6.0672e-02,  2.9285e-03],
        [ 9.0144e-02,  4.7478e-02,  1.2575e-02],
        [ 9.2035e-02,  5.7080e-03,  6.3922e-03],
        [ 9.8842e-02, -6.6545e-02,  1.5536e-04],
        [ 9.7256e-02, -2.1102e-02,  1.2738e-03],
        [ 9.1833e-02, -1.1975e-01,  1.0484e-02],
        [ 9.6468e-02, -2.5869e-01,  1.9930e-03],
        [ 9.6889e-02, -3.5753e-01,  1.1282e-03],
        [ 9.9070e-02, -3.7362e-01,  1.5986e-04],
        [ 9.8654e-02, -3.3343e-01,  6.5610e-04],
        [ 9.9833e-02, -3.9701e-01,  1.2696e-05],
        [ 9.9872e-02, -3.9730e-01,  6.7651e-06],
        [ 9.9689e-02, -3.8126e-01,  2.7388e-05],
        [ 9.8022e-02, -2.6631e-01,  9.5871e-04],
        [ 9.2744e-02, -1.4352e-01,  6.9865e-03],
        [ 7.9295e-02, -3.0192e-02,  5.3946e-02],
        [ 8.5645e-02, -1.6673e-01,  1.8468e-02],
        [ 9.8094e-02, -3.6075e-01,  5.0390e-04],
        [ 9.9427e-02, -3.8587e-01,  8.2642e-05],
        [ 9.2686e-02, -2.4334e-01,  1.4974e-02],
        [ 8.1752e-02, -1.5153e-01,  7.7220e-02],
        [ 9.0291e-02, -2.1447e-01,  1.7703e-02],
        [ 8.6945e-02, -2.6898e-01,  2.2237e-02],
        [ 8.0128e-02, -1.7855e-01,  5.7803e-02],
        [ 9.2118e-02, -3.3971e-01,  1.2383e-02],
        [ 8.9560e-02, -2.8721e-01,  3.2699e-02],
        [ 8.3423e-02, -2.2890e-01,  8.1328e-02],
        [ 7.0518e-02, -2.4292e-01,  1.9388e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 40
Episode Length = 89
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1386,  1.1417,  1.1367,  1.1298,  1.1282,  1.1348,  1.1364,  1.1477,
         1.1472, -4.0000,  0.0000,  0.0000,  0.1388,  1.1477,  1.1459,  1.1524,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1353,  1.1495,  1.1530,  1.1516,
         1.1451,  1.1540,  1.1502, -4.0000,  0.0000,  0.0000,  0.1633,  1.1631,
         1.1611,  1.1540,  1.1564,  1.1618,  1.1593,  1.1618,  1.1614,  1.1653,
         1.1635,  1.1547,  1.1535,  1.1595,  1.1464,  1.1487,  1.1572,  1.1568,
         1.1450,  1.1494,  1.0000], device='cuda:0')
target_q_episode tensor([ 4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600,
        -2.8000, -4.0000,  0.0000,  0.0000,  0.0000, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.3578,  1.4293,  0.4518,
        -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000, 12.8303,
        12.4529, 12.0557, 11.6376, 11.1975, 10.7342, 10.2465,  9.7332,  9.1928,
         8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,
         2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1402,  1.1429,  1.1375,  1.1303,  1.1283,  1.1345,  1.1357,  1.1466,
         1.1455, -4.0000,  0.0000,  0.0000,  0.1388,  1.1466,  1.1443,  1.1504,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1353,  1.1500,  1.1531,  1.1513,
         1.1444,  1.1528,  1.1485, -4.0000,  0.0000,  0.0000,  0.1632,  1.1679,
         1.1657,  1.1585,  1.1607,  1.1659,  1.1632,  1.1655,  1.1649,  1.1686,
         1.1665,  1.1575,  1.1561,  1.1618,  1.1484,  1.1504,  1.1586,  1.1578,
         1.1457,  1.1497,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.4129e-02, -5.7870e-02,  3.2584e-03],
        [ 9.5060e-02, -2.4503e-02,  2.3917e-03],
        [ 9.7516e-02, -1.2338e-01,  7.5990e-04],
        [ 9.5050e-02, -6.2704e-02,  2.0426e-03],
        [ 9.6906e-02, -1.6901e-01,  8.1930e-04],
        [ 9.7359e-02, -7.7457e-02,  7.7710e-04],
        [ 9.9179e-02, -1.6873e-01,  1.0148e-04],
        [ 9.8338e-02, -1.2244e-01,  3.5405e-04],
        [ 9.7048e-02,  4.0080e-02,  1.2356e-03],
        [ 9.8295e-02, -4.8547e-02,  4.8727e-04],
        [ 9.8049e-02,  2.7177e-02,  6.1318e-04],
        [ 9.8840e-02, -1.0595e-01,  2.6974e-04],
        [ 9.8556e-02, -4.6505e-02,  3.9747e-04],
        [ 9.8178e-02, -4.8993e-02,  6.2138e-04],
        [ 9.6833e-02,  3.7807e-02,  1.5772e-03],
        [ 9.8180e-02, -4.0163e-02,  6.7437e-04],
        [ 9.9377e-02, -1.9557e-01,  8.2046e-05],
        [ 9.7306e-02, -3.2681e-02,  1.6073e-03],
        [ 9.8665e-02, -1.8598e-01,  5.2246e-04],
        [ 9.9686e-02, -3.5227e-01,  2.9266e-05],
        [ 9.9599e-02, -3.3923e-01,  5.3734e-05],
        [ 9.9890e-02, -3.8641e-01,  4.0233e-06],
        [ 9.9966e-02, -3.9459e-01,  6.5565e-07],
        [ 9.9987e-02, -3.9831e-01,  8.9407e-08],
        [ 9.9982e-02, -3.9752e-01,  1.7881e-07],
        [ 9.9685e-02, -3.5111e-01,  2.4408e-05],
        [ 9.9786e-02, -3.7221e-01,  1.7315e-05],
        [ 9.9758e-02, -3.7152e-01,  2.6047e-05],
        [ 9.9583e-02, -3.7470e-01,  5.9605e-05],
        [ 9.9963e-02, -3.9907e-01,  8.9407e-07],
        [ 9.9125e-02, -3.1601e-01,  1.6585e-04],
        [ 9.8905e-02, -3.5610e-01,  1.9956e-04],
        [ 9.4724e-02, -1.6104e-01,  1.2556e-02],
        [ 8.6141e-02,  1.6305e-02,  3.1705e-02],
        [ 8.7477e-02, -9.9394e-02,  2.7543e-02],
        [ 8.2091e-02, -4.3134e-02,  4.5125e-02],
        [ 7.7670e-02, -4.7100e-02,  1.1146e-01],
        [ 3.2746e-02, -2.4336e-02,  6.9980e-01],
        [ 9.6919e-02, -2.5836e-01,  7.9966e-04],
        [ 9.3403e-02, -1.4983e-01,  3.3343e-03],
        [ 9.4969e-02, -1.3199e-01,  2.3194e-03],
        [ 9.5925e-02, -9.2702e-02,  1.3244e-03],
        [ 9.5648e-02, -9.6980e-02,  1.5906e-03],
        [ 9.4899e-02, -2.5098e-01,  1.7950e-03],
        [ 9.6757e-02, -2.1787e-01,  1.0489e-03],
        [ 9.5114e-02, -2.2655e-01,  2.3829e-03],
        [ 9.6637e-02, -2.3840e-01,  9.9659e-04],
        [ 9.1456e-02,  6.5734e-03,  6.2369e-03],
        [ 9.2812e-02, -1.5948e-02,  4.1758e-03],
        [ 9.4840e-02, -1.6291e-01,  2.2773e-03],
        [ 8.7192e-02, -1.1813e-02,  1.5242e-02],
        [ 8.7051e-02, -3.4247e-02,  2.1748e-02],
        [ 8.9998e-02, -1.2950e-01,  1.1549e-02],
        [ 8.8184e-02, -1.9966e-02,  1.3246e-02],
        [ 9.7228e-02, -3.2787e-01,  1.0388e-03],
        [ 9.3051e-02, -4.2575e-02,  6.6952e-03],
        [ 9.2878e-02,  2.0111e-01,  8.9292e-03],
        [ 9.2804e-02, -1.6111e-02,  8.7227e-03],
        [ 9.6925e-02, -2.1373e-01,  1.4329e-03],
        [ 8.5552e-02, -5.8728e-02,  3.3895e-02],
        [ 9.4630e-02, -2.5984e-01,  3.6751e-03],
        [ 9.3065e-02, -2.5818e-01,  6.3606e-03],
        [ 8.2896e-02, -8.6576e-02,  4.7491e-02],
        [ 9.1620e-02, -2.3759e-01,  7.9956e-03],
        [ 9.0916e-02, -2.0474e-01,  1.0700e-02],
        [ 9.4920e-02, -2.2142e-01,  3.5830e-03],
        [ 8.9999e-02, -1.7280e-01,  1.3108e-02],
        [ 9.7960e-02, -3.3581e-01,  8.0004e-04],
        [ 9.7948e-02, -2.6177e-01,  9.5001e-04],
        [ 9.9196e-02, -3.6983e-01,  1.1957e-04],
        [ 9.9374e-02, -3.8577e-01,  3.1525e-04],
        [ 9.8587e-02, -3.7028e-01,  5.0217e-04],
        [ 9.6528e-02, -3.5316e-01,  2.2787e-03],
        [ 9.6707e-02, -3.4232e-01,  2.5164e-03],
        [ 9.8978e-02, -3.5144e-01,  3.0321e-04],
        [ 9.8917e-02, -3.7850e-01,  4.2474e-04],
        [ 9.9250e-02, -3.8287e-01,  1.3697e-04],
        [ 9.9278e-02, -3.9144e-01,  1.0055e-04],
        [ 9.8442e-02, -3.7793e-01,  4.8938e-04],
        [ 9.6348e-02, -2.8672e-01,  2.1277e-03],
        [ 9.1368e-02, -2.1198e-01,  1.2158e-02],
        [ 8.8111e-02, -1.2499e-01,  2.4933e-02],
        [ 6.5455e-02,  2.1099e-02,  1.4747e-01],
        [ 7.6689e-02,  3.3188e-02,  8.8128e-02],
        [ 5.6921e-02, -8.3740e-02,  2.7131e-01],
        [ 5.1638e-02, -3.9379e-02,  3.9198e-01],
        [ 5.3577e-02, -5.1795e-02,  3.9495e-01],
        [ 8.4732e-02, -1.7369e-01,  2.9792e-02],
        [ 7.6641e-02, -8.3441e-02,  6.3533e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Saving checkpoint
Run No. 41
Episode Length = 107
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1327,  1.1344,  1.1312,  1.1362,  1.1315,  1.1380,  1.1397, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1474,  1.1544,  1.1525,  1.1539,  1.1624,
         1.1500,  1.1486,  1.1484,  1.1460, -7.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1510,  1.1546,  1.1513,  1.1483,  1.1397,  1.1443,
         1.1554, -5.0000,  0.0000,  0.0000,  0.0000,  0.1326,  1.1396,  1.1466,
         1.1492,  1.1469,  1.1448,  1.1414,  1.1350,  1.1358,  1.1407,  1.1495,
         1.1451,  1.1421,  1.1442,  1.1439,  1.1437,  1.1505,  1.1411,  1.1365,
         1.1409,  1.1444,  1.1477,  1.1538,  1.1476,  1.1345,  1.1340,  1.1452,
         1.0000], device='cuda:0')
target_q_episode tensor([ 2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  2.0876,  1.1449,  0.1525, -0.8921,
        -1.9917, -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625,
        -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, 14.9931, 14.7296,
        14.4522, 14.1602, 13.8529, 13.5293, 13.1888, 12.8303, 12.4529, 12.0557,
        11.6376, 11.1975, 10.7342, 10.2465,  9.7332,  9.1928,  8.6240,  8.0253,
         7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,  2.8525,  1.9500,
         1.0000], device='cuda:0')
target_q tensor([ 1.1332,  1.1346,  1.1311,  1.1357,  1.1307,  1.1368,  1.1381, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1473,  1.1548,  1.1525,  1.1535,  1.1617,
         1.1490,  1.1472,  1.1465,  1.1437, -7.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1510,  1.1548,  1.1511,  1.1478,  1.1388,  1.1431,
         1.1537, -5.0000,  0.0000,  0.0000,  0.0000,  0.1326,  1.1442,  1.1511,
         1.1536,  1.1512,  1.1491,  1.1455,  1.1391,  1.1397,  1.1445,  1.1532,
         1.1486,  1.1455,  1.1474,  1.1469,  1.1466,  1.1532,  1.1436,  1.1388,
         1.1430,  1.1463,  1.1494,  1.1552,  1.1487,  1.1354,  1.1346,  1.1454,
         1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.5623e-02, -1.1193e-01,  3.2445e-02],
        [ 7.2079e-02, -3.1537e-02,  3.5283e-02],
        [ 8.0893e-02, -5.6567e-02,  2.2139e-02],
        [ 6.9748e-02, -3.4788e-02,  4.8472e-02],
        [ 8.7997e-02, -6.7056e-02,  7.7088e-03],
        [ 8.2672e-02, -4.1966e-02,  1.5622e-02],
        [ 8.8322e-02, -6.8002e-02,  8.0861e-03],
        [ 9.3159e-02, -1.5881e-01,  3.6188e-03],
        [ 9.5246e-02, -2.4525e-01,  1.7281e-03],
        [ 9.1393e-02, -8.9127e-02,  5.5965e-03],
        [ 9.2062e-02, -1.0193e-01,  4.6661e-03],
        [ 9.2595e-02, -2.0099e-03,  4.7823e-03],
        [ 9.5523e-02, -3.6784e-02,  1.2461e-03],
        [ 9.6741e-02,  3.1807e-02,  5.8019e-04],
        [ 9.8624e-02, -3.9360e-02,  8.6665e-05],
        [ 9.8568e-02, -2.6572e-02,  1.1879e-04],
        [ 9.8847e-02,  8.8197e-03,  1.0729e-04],
        [ 9.9099e-02, -7.1635e-02,  4.7445e-05],
        [ 9.9070e-02, -4.0572e-02,  8.0884e-05],
        [ 9.9222e-02, -9.0187e-02,  4.2826e-05],
        [ 9.9664e-02, -1.8377e-01,  1.2815e-05],
        [ 9.9478e-02, -1.4417e-01,  3.6389e-05],
        [ 9.9409e-02, -2.0524e-01,  2.6971e-05],
        [ 9.8589e-02, -5.7286e-02,  2.1273e-04],
        [ 9.9208e-02, -1.6160e-01,  8.6784e-05],
        [ 9.8788e-02, -1.2758e-01,  1.6069e-04],
        [ 9.8961e-02, -1.5644e-01,  9.8467e-05],
        [ 9.8247e-02, -1.1342e-01,  3.1301e-04],
        [ 9.7574e-02, -6.4213e-02,  6.3515e-04],
        [ 9.8517e-02, -1.2907e-01,  2.5588e-04],
        [ 9.8527e-02, -1.1060e-01,  2.3761e-04],
        [ 9.8135e-02, -5.6887e-02,  5.1525e-04],
        [ 9.7956e-02, -7.1945e-02,  7.1138e-04],
        [ 9.7181e-02, -1.4703e-02,  1.0695e-03],
        [ 9.8113e-02, -2.1837e-01,  4.2832e-04],
        [ 9.6165e-02, -1.0393e-01,  1.9475e-03],
        [ 9.4519e-02, -1.3101e-01,  6.2546e-03],
        [ 9.3522e-02, -1.2609e-01,  8.0091e-03],
        [ 9.3135e-02, -1.4907e-01,  7.7399e-03],
        [ 7.9101e-02, -1.1629e-01,  6.1212e-02],
        [ 5.9074e-02, -7.0852e-02,  3.1428e-01],
        [ 4.3103e-02, -4.1149e-02,  4.1090e-01],
        [ 6.6474e-02, -6.7406e-02,  5.8276e-02],
        [ 8.0212e-02, -6.0668e-02,  2.1624e-02],
        [ 7.0183e-02,  1.4063e-03,  5.2718e-02],
        [ 6.7634e-02, -6.0853e-03,  5.2582e-02],
        [ 8.1645e-02,  3.0866e-02,  1.6520e-02],
        [ 9.4635e-02, -3.0458e-01,  1.8436e-03],
        [ 9.9331e-02, -3.4856e-01,  9.0331e-05],
        [ 9.6613e-02, -2.8720e-01,  1.1594e-03],
        [ 9.6645e-02, -2.9647e-01,  1.1847e-03],
        [ 9.5919e-02, -2.5442e-01,  1.3388e-03],
        [ 9.9794e-02, -3.9702e-01,  4.9174e-06],
        [ 9.9812e-02, -3.9641e-01,  3.9339e-06],
        [ 9.9885e-02, -3.9801e-01,  1.0729e-06],
        [ 9.9896e-02, -3.9797e-01,  1.7583e-06],
        [ 9.9585e-02, -3.8990e-01,  2.3335e-05],
        [ 9.9898e-02, -3.9830e-01,  1.2517e-06],
        [ 9.9723e-02, -3.9298e-01,  1.0669e-05],
        [ 9.9295e-02, -3.7856e-01,  7.6950e-05],
        [ 9.8748e-02, -3.5498e-01,  1.8832e-04],
        [ 9.8105e-02, -3.5081e-01,  3.1489e-04],
        [ 9.9740e-02, -3.9018e-01,  1.7405e-05],
        [ 9.9565e-02, -3.9500e-01,  2.0146e-05],
        [ 9.9287e-02, -3.5852e-01,  2.0745e-04],
        [ 9.9661e-02, -3.7525e-01,  6.2019e-05],
        [ 9.9698e-02, -3.8361e-01,  4.6104e-05],
        [ 9.7454e-02,  8.8475e-02,  7.0509e-04],
        [ 9.6430e-02,  6.6633e-02,  3.3686e-03],
        [ 9.6664e-02, -8.2797e-02,  3.1702e-03],
        [ 9.8326e-02, -3.2568e-01,  7.5439e-04],
        [ 9.6210e-02, -2.5349e-01,  4.7726e-03],
        [ 9.1801e-02, -1.9912e-01,  1.5916e-02],
        [ 9.7316e-02, -2.8621e-01,  1.8620e-03],
        [ 9.4040e-02, -2.3542e-01,  8.7236e-03],
        [ 9.8304e-02, -3.4290e-01,  7.3987e-04],
        [ 9.9466e-02, -3.4262e-01,  1.0905e-04],
        [ 9.2854e-02, -2.0249e-01,  7.9704e-03],
        [ 9.3871e-02, -2.5859e-01,  8.8285e-03],
        [ 9.4419e-02, -2.4388e-01,  1.3033e-02],
        [ 8.9544e-02,  2.0157e-03,  3.1562e-02],
        [ 9.5778e-02, -2.4741e-01,  2.7730e-03],
        [ 9.1072e-02, -1.1185e-01,  1.6726e-02],
        [ 7.7885e-02, -5.4367e-02,  5.6042e-02],
        [ 9.4010e-02, -2.4704e-01,  9.0186e-03],
        [ 9.3949e-02, -2.1269e-01,  6.2493e-03],
        [ 8.3156e-02, -1.5065e-01,  6.3400e-02],
        [ 8.5070e-02, -1.5712e-01,  6.5449e-02],
        [ 9.3717e-02, -2.3970e-01,  9.4601e-03],
        [ 9.7720e-02, -3.5598e-01,  4.1413e-03],
        [ 9.4294e-02, -3.3577e-01,  1.7134e-02],
        [ 9.6034e-02, -2.8199e-01,  3.2552e-03],
        [ 9.4798e-02, -2.8009e-01,  6.7051e-03],
        [ 9.4622e-02, -2.6468e-01,  4.7123e-03],
        [ 7.7743e-02, -9.4421e-02,  9.8841e-02],
        [ 8.5390e-02, -9.5363e-02,  4.5155e-02],
        [ 7.6483e-02, -6.2905e-02,  7.2948e-02],
        [ 8.0697e-02, -4.0106e-02,  7.0125e-02],
        [ 6.5666e-02, -1.7993e-01,  1.7295e-01],
        [ 7.1623e-02, -7.7436e-02,  9.2761e-02],
        [ 7.9566e-02, -1.7450e-01,  6.4922e-02],
        [ 6.7421e-02, -7.3086e-02,  1.7255e-01],
        [ 5.8987e-02, -1.9591e-01,  2.2529e-01],
        [ 8.7853e-02, -3.7117e-02,  1.5572e-02],
        [ 6.2278e-02, -3.8876e-02,  1.3906e-01],
        [ 6.7690e-02, -1.7409e-01,  1.4448e-01],
        [ 6.5512e-02, -8.9073e-02,  1.3751e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 42
Episode Length = 91
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1317,  1.1315, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1580,
         1.1384,  1.1404,  1.1432,  1.1426,  1.1466,  1.1473,  1.1429,  1.1452,
         1.1458,  1.1393,  1.1515,  1.1449,  1.1461, -7.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1384,  1.1444,  1.1481,  1.1512,  1.1519,
         1.1621,  1.1649,  1.1626,  1.1631,  1.1571,  1.1621, -3.0000,  0.0000,
         0.1712,  1.1642,  1.1608,  1.1609,  1.1635, -8.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([-3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         6.1398,  5.4103,  4.6424,  3.8341,  2.9833,  2.0876,  1.1449,  0.1525,
        -0.8921, -1.9917, -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  6.2291,  5.5043,  4.7413,  3.9382,
         3.0929,  2.2030,  1.2664,  0.2804, -0.7575, -1.8500, -3.0000,  0.0000,
         0.0000, -2.8062, -4.0065, -5.2700, -6.6000, -8.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1304,  1.1299, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1580,
         1.1397,  1.1415,  1.1442,  1.1434,  1.1471,  1.1476,  1.1429,  1.1449,
         1.1452,  1.1384,  1.1503,  1.1434,  1.1443, -7.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1384,  1.1458,  1.1493,  1.1522,  1.1527,
         1.1627,  1.1652,  1.1626,  1.1628,  1.1565,  1.1613, -3.0000,  0.0000,
         0.1711,  1.1632,  1.1594,  1.1591,  1.1614, -8.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.5094e-02, -4.1602e-02,  2.2522e-03],
        [ 9.1836e-02, -5.6076e-02,  5.9166e-03],
        [ 9.3317e-02,  1.2875e-03,  3.6921e-03],
        [ 9.5545e-02, -1.4195e-01,  1.9293e-03],
        [ 9.8155e-02, -1.4185e-01,  3.8564e-04],
        [ 9.6737e-02, -5.0844e-02,  9.3549e-04],
        [ 9.7474e-02, -3.4345e-02,  7.3534e-04],
        [ 9.7290e-02, -4.4625e-02,  7.6509e-04],
        [ 9.8028e-02, -5.6116e-02,  4.8023e-04],
        [ 9.8064e-02,  7.2998e-03,  6.2665e-04],
        [ 9.7212e-02,  9.2458e-02,  9.0316e-04],
        [ 9.7165e-02,  1.6930e-02,  1.0633e-03],
        [ 9.7675e-02,  2.2750e-02,  7.8115e-04],
        [ 9.8124e-02, -1.0270e-03,  5.2801e-04],
        [ 9.8922e-02, -7.5707e-02,  1.9288e-04],
        [ 9.8380e-02, -4.5216e-02,  4.3282e-04],
        [ 9.7573e-02, -3.0124e-02,  1.0084e-03],
        [ 9.8520e-02, -9.3660e-02,  5.0679e-04],
        [ 9.9338e-02, -1.9920e-01,  9.6053e-05],
        [ 9.9335e-02, -2.7184e-01,  1.0842e-04],
        [ 9.9523e-02, -3.0193e-01,  7.6890e-05],
        [ 9.9817e-02, -3.6990e-01,  7.8678e-06],
        [ 9.9903e-02, -3.6749e-01,  3.9339e-06],
        [ 9.9975e-02, -3.9619e-01,  3.2783e-07],
        [ 9.9991e-02, -3.9846e-01,  5.9605e-08],
        [ 9.9229e-02, -2.9791e-01,  1.1793e-04],
        [ 9.9639e-02, -3.5285e-01,  4.3511e-05],
        [ 9.9527e-02, -3.5110e-01,  7.4893e-05],
        [ 9.9855e-02, -3.9264e-01,  9.3281e-06],
        [ 9.9445e-02, -3.7635e-01,  7.2420e-05],
        [ 9.9202e-02, -3.4832e-01,  1.2642e-04],
        [ 9.7824e-02, -2.7398e-01,  7.0462e-04],
        [ 9.7623e-02, -2.1200e-01,  2.0297e-03],
        [ 9.2280e-02,  3.7790e-02,  7.9002e-03],
        [ 9.4226e-02, -6.3472e-02,  5.8748e-03],
        [ 8.3361e-02, -5.8578e-02,  4.2016e-02],
        [ 7.8073e-02, -9.9821e-02,  1.0086e-01],
        [ 6.3449e-02, -3.8193e-02,  3.0189e-01],
        [ 9.2972e-02, -2.0999e-02,  3.9544e-03],
        [ 9.1422e-02, -6.9018e-02,  5.6671e-03],
        [ 9.4176e-02, -2.1642e-01,  2.8667e-03],
        [ 9.2510e-02, -1.9405e-01,  4.9829e-03],
        [ 9.2484e-02, -1.5481e-01,  5.2027e-03],
        [ 8.7240e-02, -3.4667e-02,  1.3139e-02],
        [ 9.2039e-02, -1.8715e-02,  5.6619e-03],
        [ 9.3784e-02, -6.0612e-02,  2.3667e-03],
        [ 9.4386e-02, -1.4464e-01,  3.5503e-03],
        [ 9.4981e-02, -2.6707e-01,  1.5968e-03],
        [ 9.3818e-02, -9.0607e-02,  4.5489e-03],
        [ 9.5861e-02, -1.4992e-01,  1.9495e-03],
        [ 9.3176e-02, -7.5596e-02,  4.8964e-03],
        [ 9.3165e-02, -4.3302e-02,  3.0073e-03],
        [ 8.8636e-02, -2.0721e-02,  9.1622e-03],
        [ 8.9571e-02,  2.3558e-02,  7.7337e-03],
        [ 9.2835e-02, -7.5521e-02,  4.6661e-03],
        [ 9.1582e-02, -4.5640e-02,  6.5332e-03],
        [ 9.5730e-02, -1.1304e-01,  2.6107e-03],
        [ 9.4991e-02, -6.8112e-04,  3.4706e-03],
        [ 9.0814e-02,  1.1220e-01,  1.1283e-02],
        [ 9.4324e-02,  4.6510e-02,  4.3125e-03],
        [ 9.8171e-02, -3.0448e-01,  4.3833e-04],
        [ 9.8265e-02, -2.3769e-01,  6.4901e-04],
        [ 9.3266e-02, -8.8372e-02,  1.0096e-02],
        [ 9.5901e-02,  1.6303e-01,  3.5979e-03],
        [ 9.6088e-02, -1.6302e-01,  1.8652e-03],
        [ 9.4777e-02,  1.5423e-01,  4.2437e-03],
        [ 9.6559e-02, -1.2575e-01,  2.5865e-03],
        [ 9.9321e-02, -3.7408e-01,  7.5400e-05],
        [ 9.5020e-02, -1.1376e-01,  3.4859e-03],
        [ 9.7742e-02, -3.4294e-01,  6.8352e-04],
        [ 9.4176e-02, -2.8291e-01,  5.1942e-03],
        [ 9.6481e-02, -1.6330e-01,  2.8803e-03],
        [ 9.2283e-02, -1.3600e-01,  9.8116e-03],
        [ 9.2342e-02, -1.4391e-01,  6.5063e-03],
        [ 9.3439e-02, -2.1222e-01,  5.7445e-03],
        [ 9.8864e-02, -3.3870e-01,  2.8777e-04],
        [ 9.7865e-02, -3.4528e-01,  8.3634e-04],
        [ 9.5844e-02, -3.2225e-01,  2.3645e-03],
        [ 9.9564e-02, -3.7411e-01,  8.1778e-05],
        [ 9.8384e-02, -3.4456e-01,  9.7555e-04],
        [ 9.9281e-02, -3.6591e-01,  1.9261e-04],
        [ 9.9218e-02, -3.7793e-01,  1.9181e-04],
        [ 9.8810e-02, -3.5623e-01,  4.3833e-04],
        [ 9.8793e-02, -3.5388e-01,  4.3857e-04],
        [ 9.9613e-02, -3.8596e-01,  4.3988e-05],
        [ 9.6722e-02, -3.1812e-01,  2.5482e-03],
        [ 9.9109e-02, -3.7744e-01,  1.6433e-04],
        [ 9.4252e-02, -2.0105e-01,  4.4558e-03],
        [ 8.5567e-02, -1.0705e-01,  3.1158e-02],
        [ 6.2842e-02,  1.6266e-02,  1.8892e-01],
        [ 5.5635e-02,  5.3319e-02,  2.2891e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 43
Episode Length = 94
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1320,  1.1341,  1.1285,  1.1327,  1.1374,  1.1372,  1.1388,  1.1380,
         1.1412,  1.1517,  1.1443,  1.1386,  1.1371, -7.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1371,  1.1416,  1.1394,  1.1413,  1.1456,
         1.1457,  1.1514,  1.1581,  1.1479,  1.1504,  1.1448,  1.1519,  1.1479,
         1.1497,  1.1509,  1.1462,  1.1468,  1.1605,  1.1560,  1.1418,  1.1401,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1467,  1.1455,  1.1384, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 6.1398,  5.4103,  4.6424,  3.8341,  2.9833,  2.0876,  1.1449,  0.1525,
        -0.8921, -1.9917, -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000, 11.0379, 10.5662, 10.0696,  9.5470,
         8.9968,  8.4177,  7.8081,  7.1664,  6.4910,  5.7800,  5.0316,  4.2438,
         3.4145,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -2.5625, -3.7500, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1332,  1.1350,  1.1293,  1.1333,  1.1378,  1.1375,  1.1389,  1.1378,
         1.1407,  1.1510,  1.1433,  1.1374,  1.1356, -7.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1371,  1.1438,  1.1415,  1.1433,  1.1474,
         1.1475,  1.1530,  1.1596,  1.1493,  1.1517,  1.1459,  1.1528,  1.1486,
         1.1502,  1.1512,  1.1463,  1.1467,  1.1602,  1.1554,  1.1410,  1.1390,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1467,  1.1447,  1.1373, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 6.5082e-02, -8.5394e-02,  5.9007e-02],
        [ 8.3493e-02, -1.3398e-01,  1.4824e-02],
        [ 9.2730e-02, -1.7159e-01,  3.3931e-03],
        [ 8.4179e-02, -1.2488e-01,  1.6223e-02],
        [ 9.1722e-02, -1.4847e-01,  4.3134e-03],
        [ 9.2648e-02, -1.7505e-01,  3.7451e-03],
        [ 9.3401e-02, -1.6816e-01,  2.6309e-03],
        [ 9.1693e-02, -1.4363e-01,  3.8049e-03],
        [ 8.8638e-02, -1.0703e-02,  6.8883e-03],
        [ 9.5595e-02, -6.8382e-02,  8.1748e-04],
        [ 9.7338e-02, -8.3463e-02,  5.0184e-04],
        [ 9.5756e-02, -7.4722e-03,  8.7100e-04],
        [ 9.5637e-02,  1.3165e-02,  8.5235e-04],
        [ 9.7690e-02, -1.3074e-02,  2.9600e-04],
        [ 9.7482e-02, -2.9847e-02,  2.9802e-04],
        [ 9.8915e-02, -7.2687e-02,  7.2420e-05],
        [ 9.8577e-02, -8.8317e-03,  1.1230e-04],
        [ 9.7959e-02, -8.4050e-02,  3.0497e-04],
        [ 9.9128e-02, -6.5600e-02,  5.1528e-05],
        [ 9.8855e-02, -1.2829e-01,  9.0897e-05],
        [ 9.9447e-02, -9.9243e-02,  2.4170e-05],
        [ 9.9508e-02, -1.6542e-01,  2.1279e-05],
        [ 9.8413e-02, -1.4896e-01,  2.8005e-04],
        [ 9.8429e-02, -2.2556e-01,  4.1428e-04],
        [ 9.6652e-02, -2.1676e-01,  1.3481e-03],
        [ 9.5897e-02, -2.1193e-01,  2.1839e-03],
        [ 9.9007e-02, -3.7865e-01,  7.0184e-05],
        [ 9.9522e-02, -3.8418e-01,  5.6356e-05],
        [ 9.9353e-02, -3.6808e-01,  9.9540e-05],
        [ 9.9872e-02, -3.9775e-01,  4.2319e-06],
        [ 9.7518e-02, -1.1208e-01,  1.0818e-03],
        [ 9.0083e-02, -3.1672e-02,  8.1875e-03],
        [ 9.3785e-02, -1.5915e-01,  5.1773e-03],
        [ 9.9988e-02, -3.9974e-01,  2.9802e-08],
        [ 9.9959e-02, -3.9864e-01,  5.3644e-07],
        [ 9.9950e-02, -3.9734e-01,  8.6427e-07],
        [ 9.9918e-02, -3.9459e-01,  2.3842e-06],
        [ 9.9912e-02, -3.8441e-01,  3.5763e-06],
        [ 9.9309e-02, -2.6905e-01,  1.3167e-04],
        [ 9.3990e-02, -1.3303e-01,  8.9271e-03],
        [ 8.4933e-02, -1.6054e-01,  3.1381e-02],
        [-2.2312e-03,  1.9175e-02,  8.9188e-01],
        [ 9.3488e-02, -9.2521e-02,  1.6395e-03],
        [ 8.8290e-02, -4.5585e-02,  5.5367e-03],
        [ 9.2982e-02,  2.3186e-03,  2.4150e-03],
        [ 8.7387e-02,  3.4375e-02,  6.5547e-03],
        [ 9.1420e-02, -5.9758e-02,  2.6671e-03],
        [ 8.4795e-02, -1.1754e-01,  1.5352e-02],
        [ 8.9834e-02, -2.3777e-01,  6.4752e-03],
        [ 8.6724e-02, -1.3762e-01,  1.0116e-02],
        [ 8.7616e-02, -1.1513e-01,  1.1997e-02],
        [ 9.5510e-02, -2.2138e-01,  2.0572e-03],
        [ 9.1666e-02, -7.7441e-02,  4.6363e-03],
        [ 9.6195e-02, -4.7041e-02,  7.9745e-04],
        [ 9.2423e-02, -3.2872e-02,  2.3592e-03],
        [ 8.3355e-02,  2.3548e-02,  1.6667e-02],
        [ 9.1900e-02, -9.8593e-04,  5.0660e-03],
        [ 9.0790e-02, -4.1489e-02,  7.6907e-03],
        [ 9.5354e-02, -8.0432e-02,  1.7390e-03],
        [ 9.2411e-02, -2.0452e-01,  8.2528e-03],
        [ 9.0750e-02, -1.6668e-01,  1.1445e-02],
        [ 9.6298e-02, -1.4700e-01,  1.5832e-03],
        [ 9.4826e-02, -1.9599e-01,  2.5587e-03],
        [ 9.8235e-02, -2.8745e-01,  3.4177e-04],
        [ 9.6067e-02, -2.3894e-01,  1.7456e-03],
        [ 9.6618e-02, -2.3975e-01,  1.3236e-03],
        [ 9.3553e-02, -8.8924e-02,  4.8927e-03],
        [ 9.6301e-02, -2.7342e-01,  1.4128e-03],
        [ 9.5821e-02, -2.3767e-01,  2.0236e-03],
        [ 9.6054e-02, -1.4619e-01,  2.6634e-03],
        [ 9.6298e-02, -2.4361e-01,  1.3280e-03],
        [ 9.8010e-02, -2.9868e-01,  3.1495e-04],
        [ 9.9431e-02, -3.5966e-01,  5.5045e-05],
        [ 9.9761e-02, -3.8447e-01,  1.9461e-05],
        [ 9.9751e-02, -3.9147e-01,  3.9607e-05],
        [ 9.8956e-02, -3.6566e-01,  3.0762e-04],
        [ 9.9675e-02, -3.9295e-01,  2.3723e-05],
        [ 9.9804e-02, -3.9309e-01,  1.3590e-05],
        [ 9.9709e-02, -3.9624e-01,  3.5673e-05],
        [ 9.9681e-02, -3.9288e-01,  3.6478e-05],
        [ 9.9597e-02, -3.7897e-01,  4.4405e-05],
        [ 9.9666e-02, -3.9485e-01,  1.3620e-05],
        [ 9.9860e-02, -3.9753e-01,  6.6757e-06],
        [ 9.9525e-02, -3.8731e-01,  5.6773e-05],
        [ 9.9725e-02, -3.8945e-01,  4.1187e-05],
        [ 9.9509e-02, -3.8367e-01,  4.1991e-05],
        [ 9.9888e-02, -3.9798e-01,  2.1756e-06],
        [ 9.9772e-02, -3.8334e-01,  2.2888e-05],
        [ 9.9503e-02, -3.7865e-01,  1.2025e-04],
        [ 9.4546e-02, -2.9651e-01,  6.1295e-03],
        [ 9.7321e-02, -3.4097e-01,  1.5166e-03],
        [ 9.8860e-02, -3.6517e-01,  3.9330e-04],
        [ 9.7306e-02, -3.6029e-01,  1.1352e-03],
        [ 9.4760e-02, -3.1215e-01,  7.5854e-03]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 44
Episode Length = 97
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1337,   1.1364,   1.1374,   1.1448,   1.1509,   1.1433,   1.1374,
          1.1475,   1.1348,   1.1386,   1.1411,   1.1505, -16.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1623,
          1.1588,   1.1572,   1.1565,   1.1575,   1.1545,   1.1631,  -3.0000,
          0.0000,   0.1517,   1.1634,   1.1642,   1.1714,   1.1636,   1.1637,
          1.1640,   1.1650,   1.1703,   1.1629,   1.1580,   1.1467,   1.1559,
         -4.0000,   0.0000,   0.0000,   0.1615,   1.1588,   1.1551,   1.1555,
          1.1482,   1.1457,   1.0000], device='cuda:0')
target_q_episode tensor([  0.5470,  -0.4768,  -1.5545,  -2.6890,  -3.8831,  -5.1401,  -6.4633,
         -7.8561,  -9.3222, -10.8655, -12.4900, -14.2000, -16.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          3.0929,   2.2030,   1.2664,   0.2804,  -0.7575,  -1.8500,  -3.0000,
          0.0000,   0.0000,   7.0314,   6.3488,   5.6303,   4.8740,   4.0779,
          3.2399,   2.3578,   1.4293,   0.4519,  -0.5770,  -1.6600,  -2.8000,
         -4.0000,   0.0000,   0.0000,   0.0000,   5.2982,   4.5244,   3.7099,
          2.8525,   1.9500,   1.0000], device='cuda:0')
target_q tensor([  1.1336,   1.1361,   1.1369,   1.1441,   1.1500,   1.1421,   1.1360,
          1.1458,   1.1329,   1.1364,   1.1386,   1.1477, -16.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1623,
          1.1591,   1.1574,   1.1565,   1.1573,   1.1542,   1.1626,  -3.0000,
          0.0000,   0.1516,   1.1644,   1.1651,   1.1722,   1.1643,   1.1642,
          1.1644,   1.1653,   1.1703,   1.1628,   1.1576,   1.1462,   1.1552,
         -4.0000,   0.0000,   0.0000,   0.1614,   1.1596,   1.1557,   1.1560,
          1.1485,   1.1459,   1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.5489e-02, -1.9740e-02,  1.8932e-03],
        [ 9.4923e-02, -2.9240e-02,  2.2704e-03],
        [ 9.5151e-02, -4.2310e-02,  2.3726e-03],
        [ 9.6971e-02, -1.1266e-01,  8.9911e-04],
        [ 9.8017e-02, -1.9585e-01,  3.6716e-04],
        [ 9.8826e-02, -1.3256e-01,  1.7709e-04],
        [ 9.9110e-02, -1.5459e-01,  1.0756e-04],
        [ 9.9228e-02, -1.3383e-01,  1.2234e-04],
        [ 9.8392e-02,  6.1441e-02,  2.9987e-04],
        [ 9.8172e-02,  8.4322e-03,  4.1479e-04],
        [ 9.8137e-02,  1.2264e-02,  5.6827e-04],
        [ 9.8405e-02,  1.5158e-02,  3.9315e-04],
        [ 9.4929e-02,  7.7454e-02,  2.5720e-03],
        [ 9.8191e-02,  4.8738e-03,  4.8593e-04],
        [ 9.8099e-02, -2.6822e-02,  5.7337e-04],
        [ 9.8610e-02, -3.2837e-02,  3.8093e-04],
        [ 9.8996e-02, -6.5096e-02,  2.1598e-04],
        [ 9.8907e-02, -1.2735e-01,  3.1406e-04],
        [ 9.9508e-02, -2.1178e-01,  6.5893e-05],
        [ 9.9752e-02, -3.1972e-01,  2.4498e-05],
        [ 9.9480e-02, -2.9766e-01,  7.4029e-05],
        [ 9.9886e-02, -3.6616e-01,  6.6459e-06],
        [ 9.9854e-02, -3.7868e-01,  5.8413e-06],
        [ 9.9956e-02, -3.9406e-01,  6.5565e-07],
        [ 9.9996e-02, -3.9948e-01,  0.0000e+00],
        [ 9.9875e-02, -3.8426e-01,  3.6955e-06],
        [ 9.9669e-02, -3.6191e-01,  2.5392e-05],
        [ 9.9765e-02, -3.6844e-01,  1.5706e-05],
        [ 9.9189e-02, -3.0989e-01,  1.4350e-04],
        [ 9.9752e-02, -3.9230e-01,  1.5080e-05],
        [ 9.9227e-02, -3.4425e-01,  9.0539e-05],
        [ 9.9004e-02, -3.3593e-01,  1.4788e-04],
        [ 9.6277e-02, -1.6677e-01,  4.9648e-03],
        [ 8.9097e-02,  1.4142e-02,  1.7739e-02],
        [ 9.4211e-02, -1.1884e-01,  4.1215e-03],
        [ 8.4559e-02, -8.6006e-02,  3.1282e-02],
        [ 7.9672e-02, -7.8123e-02,  7.4713e-02],
        [ 4.4237e-02, -3.4675e-02,  5.9462e-01],
        [ 8.5383e-02,  3.7064e-02,  1.2902e-02],
        [ 8.9402e-02, -1.3891e-02,  6.8181e-03],
        [ 9.4477e-02, -4.7995e-02,  2.4079e-03],
        [ 9.5971e-02, -1.2388e-01,  1.4023e-03],
        [ 9.2556e-02, -3.1896e-02,  4.1788e-03],
        [ 9.2840e-02,  6.0205e-02,  4.6151e-03],
        [ 9.1599e-02,  4.1356e-02,  5.1743e-03],
        [ 9.2959e-02,  8.2949e-02,  4.3729e-03],
        [ 9.5482e-02, -1.8504e-02,  2.0370e-03],
        [ 9.4912e-02, -6.0309e-02,  2.1353e-03],
        [ 8.9034e-02, -1.3314e-01,  8.3461e-03],
        [ 8.8459e-02, -1.2655e-01,  9.1540e-03],
        [ 8.9036e-02, -5.7211e-02,  9.5267e-03],
        [ 9.6539e-02,  1.4679e-02,  1.7262e-03],
        [ 9.5284e-02,  4.1683e-02,  1.9782e-03],
        [ 8.8526e-02, -4.3605e-02,  8.5932e-03],
        [ 8.8533e-02, -6.7381e-02,  1.4807e-02],
        [ 9.3905e-02, -2.6898e-01,  2.3532e-03],
        [ 9.3636e-02, -1.8825e-01,  4.2808e-03],
        [ 9.7989e-02, -2.8921e-01,  5.1904e-04],
        [ 9.6719e-02, -2.2057e-01,  1.1965e-03],
        [ 9.6972e-02, -1.7548e-01,  7.9933e-04],
        [ 9.5799e-02, -2.0536e-01,  2.0026e-03],
        [ 9.6846e-02, -2.2985e-01,  1.1943e-03],
        [ 9.3268e-02, -1.1495e-01,  6.0848e-03],
        [ 9.3366e-02, -9.7016e-02,  5.8618e-03],
        [ 9.1748e-02, -1.4994e-01,  6.7593e-03],
        [ 9.3548e-02, -9.5597e-02,  6.8611e-03],
        [ 9.4214e-02, -4.9436e-03,  6.3545e-03],
        [ 9.6375e-02, -2.0041e-01,  1.5220e-03],
        [ 9.6561e-02, -1.6128e-01,  1.4241e-03],
        [ 9.2980e-02, -8.3157e-02,  3.8874e-03],
        [ 9.4968e-02, -2.1830e-01,  2.6056e-03],
        [ 9.7764e-02, -3.4570e-01,  1.1947e-03],
        [ 9.8850e-02, -3.7018e-01,  3.9884e-04],
        [ 9.8061e-02, -3.4872e-01,  1.3193e-03],
        [ 9.8545e-02, -3.4846e-01,  6.0958e-04],
        [ 9.9305e-02, -3.7426e-01,  1.6204e-04],
        [ 9.8896e-02, -3.5912e-01,  6.3184e-04],
        [ 9.9305e-02, -3.8053e-01,  2.2483e-04],
        [ 9.9050e-02, -3.5580e-01,  2.4047e-04],
        [ 9.8825e-02, -3.6960e-01,  2.4354e-04],
        [ 9.9867e-02, -3.9567e-01,  9.0599e-06],
        [ 9.9954e-02, -3.9908e-01,  1.1623e-06],
        [ 9.9976e-02, -3.9936e-01,  2.6822e-07],
        [ 9.9123e-02, -3.8467e-01,  1.1837e-04],
        [ 9.8848e-02, -3.5909e-01,  3.1009e-04],
        [ 9.8820e-02, -3.5314e-01,  2.5621e-04],
        [ 9.7682e-02, -3.0781e-01,  5.2625e-04],
        [ 9.8895e-02, -3.6067e-01,  2.8399e-04],
        [ 9.8675e-02, -3.8258e-01,  3.8669e-04],
        [ 9.8694e-02, -3.8270e-01,  5.3737e-04],
        [ 9.7626e-02, -3.6210e-01,  1.9141e-03],
        [ 9.2819e-02, -2.2629e-01,  2.0855e-02],
        [ 8.5848e-02,  5.8385e-03,  2.9239e-02],
        [ 8.0026e-02, -3.4090e-02,  6.3027e-02],
        [ 8.9572e-02, -7.9673e-02,  1.3131e-02],
        [ 8.9524e-02, -1.6495e-01,  1.1079e-02],
        [ 8.3410e-02, -2.9851e-02,  4.8171e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 45
Episode Length = 112
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1337,   1.1269,   1.1288,   1.1297, -10.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1610,
          1.1426,   1.1410,   1.1479,   1.1515,  -4.0000,   0.0000,   0.0000,
          0.1578,   1.1513,   1.1616,   1.1476,   1.1453,   1.1380,   1.1459,
          1.1491,   1.1455,   1.1465,   1.1536,   1.1647,   1.1499,   1.1472,
          1.1408,   1.1440,   1.1445,   1.1479,  -5.0000,   0.0000,   0.0000,
          0.0000,   0.1411,   1.1379,   1.1395,   1.1476,   1.1494,   1.1495,
          1.1557,   1.1515,   1.1460,   1.1456,   1.1323,   1.1422,   1.1380,
         -5.0000,   0.0000,   0.0000,   0.0000,   0.1457,   1.1424,   1.1452,
          1.1527,   1.1539,  -5.0000,   0.0000,   0.0000,   0.0000,   0.0000],
       device='cuda:0')
target_q_episode tensor([ -4.4352,  -5.7213,  -7.0750,  -8.5000, -10.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.4519,  -0.5770,  -1.6600,  -2.8000,  -4.0000,   0.0000,   0.0000,
          0.0000,   9.5470,   8.9968,   8.4177,   7.8081,   7.1664,   6.4910,
          5.7800,   5.0316,   4.2438,   3.4145,   2.5416,   1.6227,   0.6555,
         -0.3627,  -1.4344,  -2.5625,  -3.7500,  -5.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   6.4910,   5.7800,   5.0316,   4.2438,   3.4145,
          2.5416,   1.6227,   0.6555,  -0.3627,  -1.4344,  -2.5625,  -3.7500,
         -5.0000,   0.0000,   0.0000,   0.0000,   0.0000,  -0.3627,  -1.4344,
         -2.5625,  -3.7500,  -5.0000,   0.0000,   0.0000,   0.0000,   0.0000],
       device='cuda:0')
target_q tensor([  1.1329,   1.1258,   1.1276,   1.1283, -10.0000,   0.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1609,
          1.1425,   1.1408,   1.1475,   1.1509,  -4.0000,   0.0000,   0.0000,
          0.1578,   1.1526,   1.1628,   1.1487,   1.1463,   1.1389,   1.1467,
          1.1498,   1.1461,   1.1469,   1.1539,   1.1649,   1.1499,   1.1471,
          1.1406,   1.1436,   1.1440,   1.1472,  -5.0000,   0.0000,   0.0000,
          0.0000,   0.1411,   1.1387,   1.1402,   1.1482,   1.1499,   1.1498,
          1.1559,   1.1516,   1.1459,   1.1454,   1.1319,   1.1417,   1.1372,
         -5.0000,   0.0000,   0.0000,   0.0000,   0.1457,   1.1422,   1.1448,
          1.1522,   1.1531,  -5.0000,   0.0000,   0.0000,   0.0000,   0.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.7538e-02, -8.5604e-02,  2.5102e-02],
        [ 8.1524e-02, -5.8540e-02,  1.2602e-02],
        [ 7.5568e-02, -4.0873e-02,  3.3487e-02],
        [ 6.8198e-02, -3.4629e-02,  5.5094e-02],
        [ 7.6477e-02, -2.9385e-03,  2.7608e-02],
        [ 8.3924e-02, -6.4412e-02,  1.1834e-02],
        [ 8.8801e-02, -3.1240e-02,  5.4773e-03],
        [ 8.9861e-02, -1.6469e-01,  7.6287e-03],
        [ 9.6051e-02, -2.2047e-01,  1.3416e-03],
        [ 9.4753e-02, -1.3289e-01,  1.9107e-03],
        [ 9.5928e-02, -9.2993e-02,  1.1781e-03],
        [ 9.1395e-02,  1.3501e-03,  4.5342e-03],
        [ 9.6716e-02, -1.3783e-01,  6.6221e-04],
        [ 9.7708e-02, -6.5551e-02,  2.3517e-04],
        [ 9.8194e-02, -1.0381e-01,  1.6040e-04],
        [ 9.8828e-02, -1.1997e-01,  6.1572e-05],
        [ 9.8820e-02, -8.6197e-02,  8.5235e-05],
        [ 9.9168e-02, -2.1357e-01,  3.4660e-05],
        [ 9.9575e-02, -2.2215e-01,  1.3888e-05],
        [ 9.9489e-02, -1.7870e-01,  1.8239e-05],
        [ 9.9759e-02, -2.4873e-01,  5.5134e-06],
        [ 9.9701e-02, -2.6430e-01,  7.9870e-06],
        [ 9.9577e-02, -2.6063e-01,  1.1623e-05],
        [ 9.9346e-02, -2.4098e-01,  4.6790e-05],
        [ 9.9636e-02, -2.8685e-01,  1.4156e-05],
        [ 9.9386e-02, -2.5261e-01,  3.4600e-05],
        [ 9.9735e-02, -3.1211e-01,  7.2122e-06],
        [ 9.9525e-02, -3.1410e-01,  2.1368e-05],
        [ 9.9548e-02, -2.9098e-01,  2.6166e-05],
        [ 9.9197e-02, -1.9194e-01,  7.4387e-05],
        [ 9.9254e-02, -1.7333e-01,  5.2243e-05],
        [ 9.9027e-02, -1.4138e-01,  9.4801e-05],
        [ 9.8728e-02, -2.2017e-01,  1.7691e-04],
        [ 9.8351e-02, -2.0005e-01,  4.2316e-04],
        [ 9.7932e-02, -1.0923e-01,  7.5534e-04],
        [ 9.6186e-02, -8.6679e-02,  2.2437e-03],
        [ 9.6284e-02, -2.2410e-01,  2.1347e-03],
        [ 9.2486e-02, -1.3635e-01,  1.0664e-02],
        [ 9.1955e-02, -1.7060e-01,  1.6102e-02],
        [ 8.0280e-02, -1.6018e-01,  8.2102e-02],
        [ 5.8672e-02, -8.9312e-02,  3.5516e-01],
        [ 3.4688e-02, -9.2783e-02,  6.2047e-01],
        [ 9.3155e-02, -2.6678e-01,  4.7330e-03],
        [ 8.7756e-02, -1.1288e-01,  1.4588e-02],
        [ 9.0798e-02, -1.7864e-01,  5.7154e-03],
        [ 9.5009e-02, -2.4354e-01,  2.2660e-03],
        [ 9.7466e-02, -3.0563e-01,  3.8826e-04],
        [ 9.8749e-02, -3.5701e-01,  2.1008e-04],
        [ 9.6683e-02, -2.0914e-01,  8.5595e-04],
        [ 9.8606e-02, -3.7003e-01,  1.1656e-04],
        [ 9.9888e-02, -3.9665e-01,  1.3709e-06],
        [ 9.9029e-02, -3.5034e-01,  6.4105e-05],
        [ 9.8763e-02, -2.7451e-01,  2.4518e-04],
        [ 9.8923e-02, -3.3693e-01,  1.4651e-04],
        [ 9.8128e-02, -2.9364e-01,  3.6383e-04],
        [ 9.8871e-02, -3.5204e-01,  1.5464e-04],
        [ 9.9801e-02, -3.9415e-01,  7.5698e-06],
        [ 9.9398e-02, -3.7064e-01,  4.5627e-05],
        [ 9.8350e-02, -3.5701e-01,  2.6953e-04],
        [ 9.9652e-02, -3.9006e-01,  1.0490e-05],
        [ 9.9711e-02, -3.9273e-01,  6.1989e-06],
        [ 9.7936e-02, -3.4335e-01,  5.7507e-04],
        [ 9.3371e-02, -2.1185e-01,  7.9464e-03],
        [ 9.9456e-02, -3.7990e-01,  6.0529e-05],
        [ 9.7843e-02, -3.0452e-01,  6.9246e-04],
        [ 9.6100e-02, -1.9497e-01,  4.4233e-03],
        [ 9.2636e-02,  2.8481e-02,  1.4799e-02],
        [ 9.1620e-02,  6.9162e-02,  9.6032e-03],
        [ 9.6384e-02,  2.3844e-03,  2.0584e-03],
        [ 9.5424e-02, -1.0235e-01,  3.1035e-03],
        [ 9.4710e-02, -4.7130e-02,  3.2488e-03],
        [ 9.4691e-02, -8.7259e-02,  6.4738e-03],
        [ 9.3879e-02, -2.5640e-01,  1.1763e-02],
        [ 9.9619e-02, -3.8507e-01,  8.1807e-05],
        [ 9.7657e-02, -3.4485e-01,  2.8783e-03],
        [ 9.3793e-02, -9.8335e-02,  9.5599e-03],
        [ 9.5745e-02, -1.2825e-01,  4.5651e-03],
        [ 9.5692e-02, -1.9579e-01,  2.8265e-03],
        [ 9.5383e-02, -1.6324e-01,  2.6900e-03],
        [ 8.6729e-02, -1.0856e-01,  3.4190e-02],
        [ 8.9504e-02, -1.8743e-01,  1.3672e-02],
        [ 9.4345e-02, -2.6208e-01,  8.0017e-03],
        [ 9.1684e-02, -2.6547e-01,  1.5422e-02],
        [ 9.9146e-02, -3.4214e-01,  5.9456e-05],
        [ 9.5560e-02, -1.7541e-01,  2.4984e-03],
        [ 9.3305e-02, -1.5308e-01,  6.8049e-03],
        [ 9.2838e-02, -1.0393e-01,  7.1633e-03],
        [ 9.2337e-02, -1.9456e-01,  6.4191e-03],
        [ 9.6874e-02, -2.6600e-01,  1.6773e-03],
        [ 9.5786e-02, -3.2632e-01,  7.0829e-03],
        [ 9.3327e-02, -3.0336e-01,  7.8436e-03],
        [ 9.3447e-02, -2.9563e-01,  1.2939e-02],
        [ 9.2591e-02, -2.5492e-01,  9.3677e-03],
        [ 9.7438e-02, -2.6463e-01,  9.0376e-04],
        [ 8.6885e-02, -6.3727e-02,  1.5854e-02],
        [ 9.0044e-02, -1.0710e-01,  1.1877e-02],
        [ 8.8896e-02, -7.3711e-02,  1.0650e-02],
        [ 9.5711e-02, -2.2580e-01,  3.3320e-03],
        [ 9.1466e-02, -2.2171e-01,  1.0971e-02],
        [ 9.5810e-02, -3.2495e-01,  4.1682e-03],
        [ 8.9319e-02, -1.6947e-01,  2.3485e-02],
        [ 8.3581e-02, -6.0363e-02,  4.6513e-02],
        [ 8.9086e-02, -1.9033e-01,  1.2766e-02],
        [ 9.3861e-02, -2.4689e-01,  7.2141e-03],
        [ 8.5394e-02, -1.7412e-01,  3.1887e-02],
        [ 8.3418e-02, -2.0164e-01,  4.2518e-02],
        [ 9.7133e-02, -3.4706e-01,  2.1342e-03],
        [ 9.2538e-02, -2.6778e-01,  6.0272e-03],
        [ 7.8096e-02, -2.0673e-01,  8.1681e-02],
        [ 8.2848e-02, -2.2594e-01,  6.5798e-02],
        [ 9.5074e-02, -2.7410e-01,  4.6702e-03],
        [ 7.7822e-02, -6.8176e-02,  5.2510e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 46
Episode Length = 82
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1280,  1.1232,  1.1270,  1.1378,  1.1465,  1.1507,  1.1466,  1.1382,
         1.1378,  1.1418,  1.1418,  1.1496,  1.1477,  1.1466, -4.0000,  0.0000,
         0.0000,  0.1527,  1.1412,  1.1471,  1.1513,  1.1506,  1.1604,  1.1567,
         1.1564,  1.1627,  1.1562,  1.1621,  1.1617,  1.1525,  1.1517,  1.1599,
         1.1645,  1.1623,  1.1693,  1.1592,  1.1551,  1.1560,  1.1544,  1.1572,
         1.1531,  1.1522,  1.1451,  1.0000], device='cuda:0')
target_q_episode tensor([ 8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000, 14.7296, 14.4522, 14.1602, 13.8529, 13.5293, 13.1888,
        12.8303, 12.4529, 12.0557, 11.6376, 11.1975, 10.7342, 10.2465,  9.7332,
         9.1928,  8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,
         3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1289,  1.1240,  1.1277,  1.1384,  1.1471,  1.1512,  1.1470,  1.1385,
         1.1379,  1.1418,  1.1417,  1.1494,  1.1474,  1.1461, -4.0000,  0.0000,
         0.0000,  0.1526,  1.1428,  1.1487,  1.1529,  1.1522,  1.1619,  1.1581,
         1.1578,  1.1641,  1.1575,  1.1634,  1.1630,  1.1537,  1.1528,  1.1610,
         1.1655,  1.1632,  1.1702,  1.1599,  1.1558,  1.1566,  1.1549,  1.1576,
         1.1534,  1.1524,  1.1452,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.4187e-02, -1.3543e-02,  2.5868e-03],
        [ 9.7928e-02, -1.1545e-01,  5.9354e-04],
        [ 9.7551e-02, -7.2774e-02,  7.8768e-04],
        [ 9.7012e-02, -1.4931e-01,  6.4132e-04],
        [ 9.8645e-02, -9.0412e-02,  2.5487e-04],
        [ 9.6609e-02, -4.8869e-02,  8.1477e-04],
        [ 9.8955e-02, -1.4161e-01,  1.5149e-04],
        [ 9.8097e-02, -1.8988e-02,  3.9086e-04],
        [ 9.9068e-02, -8.9000e-02,  1.2323e-04],
        [ 9.7516e-02,  1.9524e-02,  6.7708e-04],
        [ 9.7376e-02,  9.1916e-02,  8.8942e-04],
        [ 9.8174e-02,  8.5711e-02,  5.0005e-04],
        [ 9.8877e-02,  2.4194e-02,  1.9148e-04],
        [ 9.7848e-02,  9.1568e-03,  6.6569e-04],
        [ 9.8126e-02,  9.2908e-03,  6.4287e-04],
        [ 9.7719e-02,  2.6207e-02,  6.4409e-04],
        [ 9.7877e-02, -7.0797e-02,  7.1150e-04],
        [ 9.8547e-02, -7.5220e-02,  5.5629e-04],
        [ 9.8534e-02, -1.2962e-01,  3.4848e-04],
        [ 9.9338e-02, -2.7086e-01,  1.0586e-04],
        [ 9.9541e-02, -2.8165e-01,  7.4714e-05],
        [ 9.9859e-02, -3.7664e-01,  6.2287e-06],
        [ 9.9929e-02, -3.9066e-01,  1.6987e-06],
        [ 9.9922e-02, -3.8756e-01,  2.1160e-06],
        [ 9.9988e-02, -3.9855e-01,  5.9605e-08],
        [ 9.9591e-02, -3.4532e-01,  3.3289e-05],
        [ 9.9598e-02, -3.6357e-01,  3.7342e-05],
        [ 9.9392e-02, -3.5487e-01,  7.1913e-05],
        [ 9.9333e-02, -3.5806e-01,  8.6635e-05],
        [ 9.9840e-02, -3.9626e-01,  5.1558e-06],
        [ 9.8761e-02, -3.1580e-01,  1.8129e-04],
        [ 9.8300e-02, -3.2445e-01,  3.8794e-04],
        [ 9.4236e-02, -1.1956e-01,  1.2141e-02],
        [ 8.6468e-02,  1.4760e-02,  2.7851e-02],
        [ 8.6671e-02, -7.6807e-02,  2.3501e-02],
        [ 8.5277e-02, -9.0435e-02,  3.2388e-02],
        [ 7.4515e-02, -5.7759e-02,  1.2220e-01],
        [ 3.9524e-02, -4.6339e-02,  6.6616e-01],
        [ 9.5743e-02, -2.2855e-02,  1.2573e-03],
        [ 9.3666e-02, -8.5132e-03,  3.1620e-03],
        [ 9.4591e-02, -2.6744e-01,  2.0357e-03],
        [ 9.8301e-02, -2.4706e-01,  2.6402e-04],
        [ 9.6630e-02, -2.4884e-01,  8.7506e-04],
        [ 9.5520e-02, -2.7311e-01,  1.2927e-03],
        [ 9.8000e-02, -1.7927e-02,  5.5307e-04],
        [ 9.2277e-02,  1.7763e-02,  3.0366e-03],
        [ 9.4268e-02, -4.7823e-02,  1.7004e-03],
        [ 9.2892e-02,  4.4406e-02,  3.4854e-03],
        [ 9.5867e-02,  1.5716e-01,  1.7712e-03],
        [ 9.8269e-02,  1.4722e-02,  4.8342e-04],
        [ 9.6711e-02, -9.1480e-03,  1.8512e-03],
        [ 9.5642e-02,  1.4266e-01,  2.5070e-03],
        [ 9.6858e-02,  1.3954e-01,  1.1471e-03],
        [ 9.6945e-02,  7.0035e-02,  1.0110e-03],
        [ 9.7078e-02,  9.1312e-02,  1.6243e-03],
        [ 9.7143e-02,  9.7047e-02,  1.0609e-03],
        [ 9.7314e-02,  1.2034e-01,  1.5543e-03],
        [ 9.8502e-02, -5.5859e-02,  5.4342e-04],
        [ 9.7906e-02, -3.0689e-01,  8.2085e-04],
        [ 9.5010e-02, -6.0280e-02,  6.0781e-03],
        [ 9.8252e-02, -1.6767e-01,  5.7226e-04],
        [ 9.7856e-02, -8.6179e-02,  6.1849e-04],
        [ 9.7594e-02, -1.6722e-01,  6.0228e-04],
        [ 9.8574e-02, -2.7567e-01,  2.6107e-04],
        [ 9.8093e-02, -2.8521e-01,  2.7862e-04],
        [ 9.7604e-02, -2.5350e-01,  1.1107e-03],
        [ 9.9337e-02, -3.6955e-01,  1.7390e-04],
        [ 9.8583e-02, -3.1850e-01,  3.0077e-04],
        [ 9.9586e-02, -3.7151e-01,  3.2812e-05],
        [ 9.9741e-02, -3.8429e-01,  2.4199e-05],
        [ 9.9509e-02, -3.9011e-01,  7.3493e-05],
        [ 9.9034e-02, -3.8558e-01,  1.4910e-04],
        [ 9.9596e-02, -3.9428e-01,  2.1309e-05],
        [ 9.8019e-02, -3.5555e-01,  7.2679e-04],
        [ 9.6332e-02, -3.3906e-01,  1.5679e-03],
        [ 8.9033e-02, -2.3282e-01,  1.5282e-02],
        [ 8.8101e-02, -1.8774e-01,  3.0241e-02],
        [ 8.2561e-02, -1.6156e-01,  5.6597e-02],
        [ 6.5909e-02, -3.8565e-02,  1.9398e-01],
        [ 5.7929e-02, -1.6956e-02,  2.8615e-01],
        [ 3.9929e-02, -2.7538e-02,  5.2831e-01],
        [ 4.3512e-02, -8.0487e-02,  4.9753e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 47
Episode Length = 100
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1317,  1.1256,  1.1301, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1554,  1.1527,  1.1543,  1.1464,  1.1357,  1.1424,  1.1443,  1.1425,
         1.1461,  1.1457,  1.1414, -3.0000,  0.0000,  0.1547,  1.1420,  1.1390,
         1.1412,  1.1508,  1.1432,  1.1489,  1.1414, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1554,  1.1562,  1.1526,  1.1526,  1.1500,  1.1470,  1.1542,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1501,  1.1531,  1.1547,  1.1487,
         1.1500,  1.1501,  1.1450,  1.1387,  1.1364,  1.1408,  1.1524,  1.1525,
         1.1545,  1.0000], device='cuda:0')
target_q_episode tensor([-2.2917, -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  6.2291,  5.5043,  4.7413,  3.9382,  3.0929,  2.2030,  1.2664,
         0.2804, -0.7575, -1.8500, -3.0000,  0.0000,  0.0000,  2.5416,  1.6227,
         0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  9.7332,  9.1928,  8.6240,
         8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,  2.8525,
         1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1313,  1.1252,  1.1295, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1554,  1.1532,  1.1547,  1.1468,  1.1360,  1.1426,  1.1444,  1.1425,
         1.1460,  1.1455,  1.1411, -3.0000,  0.0000,  0.1547,  1.1421,  1.1391,
         1.1412,  1.1507,  1.1429,  1.1485,  1.1409, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1554,  1.1562,  1.1525,  1.1525,  1.1497,  1.1466,  1.1537,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1501,  1.1539,  1.1555,  1.1494,
         1.1507,  1.1507,  1.1456,  1.1392,  1.1369,  1.1411,  1.1526,  1.1527,
         1.1546,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.7289e-02, -1.2305e-01,  8.6755e-03],
        [ 9.2504e-02, -2.2073e-01,  2.7663e-03],
        [ 9.4629e-02, -2.1086e-01,  1.9431e-03],
        [ 9.1732e-02, -1.1721e-01,  4.9097e-03],
        [ 9.2227e-02, -1.2545e-01,  3.9984e-03],
        [ 9.6390e-02, -2.1704e-01,  6.3637e-04],
        [ 9.4602e-02, -1.7789e-01,  1.3707e-03],
        [ 9.5658e-02, -2.5166e-01,  1.0715e-03],
        [ 9.3891e-02, -1.1302e-01,  2.1810e-03],
        [ 9.4595e-02, -6.7378e-02,  1.2878e-03],
        [ 9.6097e-02, -1.2352e-01,  7.3436e-04],
        [ 9.7239e-02, -1.4425e-01,  3.0985e-04],
        [ 9.6551e-02, -9.9463e-02,  6.2346e-04],
        [ 9.5396e-02, -1.1896e-01,  9.1150e-04],
        [ 9.7911e-02, -1.1233e-01,  2.1419e-04],
        [ 9.7379e-02, -9.5613e-02,  2.6107e-04],
        [ 9.8247e-02, -1.5122e-01,  1.8924e-04],
        [ 9.8828e-02, -1.9713e-01,  8.6069e-05],
        [ 9.8892e-02, -1.7545e-01,  7.9334e-05],
        [ 9.9214e-02, -2.6094e-01,  3.0845e-05],
        [ 9.9233e-02, -1.5659e-01,  4.5180e-05],
        [ 9.9665e-02, -2.6230e-01,  7.7188e-06],
        [ 9.8015e-02, -2.1109e-01,  2.8911e-04],
        [ 9.8582e-02, -3.1148e-01,  2.6295e-04],
        [ 9.7768e-02, -2.8919e-01,  6.4442e-04],
        [ 9.4959e-02, -1.7572e-01,  3.9053e-03],
        [ 9.9361e-02, -3.8955e-01,  2.9266e-05],
        [ 9.5855e-02, -2.6692e-01,  1.5987e-03],
        [ 9.9048e-02, -3.5162e-01,  1.9717e-04],
        [ 9.9710e-02, -3.9505e-01,  1.5646e-05],
        [ 9.4572e-02, -7.6719e-02,  3.6245e-03],
        [ 7.4029e-02, -1.9264e-02,  5.4750e-02],
        [ 8.3094e-02, -8.8438e-02,  2.9893e-02],
        [ 9.9955e-02, -3.9953e-01,  4.7684e-07],
        [ 9.9624e-02, -3.9574e-01,  3.3975e-05],
        [ 9.9820e-02, -3.9423e-01,  1.1772e-05],
        [ 9.9813e-02, -3.9426e-01,  9.8944e-06],
        [ 9.8596e-02, -3.3258e-01,  7.9277e-04],
        [ 9.5954e-02, -2.3392e-01,  3.2710e-03],
        [ 8.9540e-02, -1.6539e-01,  2.7505e-02],
        [ 7.3809e-02, -2.1714e-01,  9.6525e-02],
        [-3.1342e-02,  4.7956e-02,  9.6465e-01],
        [ 8.2983e-02, -1.0664e-01,  1.3645e-02],
        [ 8.7986e-02, -1.0149e-01,  6.8143e-03],
        [ 8.8022e-02, -1.4760e-01,  9.4084e-03],
        [ 9.0659e-02, -1.6987e-01,  4.7758e-03],
        [ 8.4818e-02, -9.6187e-02,  1.4956e-02],
        [ 9.2862e-02, -2.0334e-01,  2.5583e-03],
        [ 9.3128e-02, -1.8513e-01,  2.7254e-03],
        [ 9.8859e-02, -3.7129e-01,  9.5934e-05],
        [ 9.7780e-02, -3.5156e-01,  2.6843e-04],
        [ 9.6850e-02, -3.2969e-01,  7.3525e-04],
        [ 9.9601e-02, -3.9232e-01,  1.3620e-05],
        [ 9.9790e-02, -3.9674e-01,  5.3644e-06],
        [ 9.7609e-02, -2.7812e-01,  4.2510e-04],
        [ 9.6172e-02, -2.5720e-01,  1.0732e-03],
        [ 9.7932e-02, -3.4045e-01,  2.8285e-04],
        [ 9.6182e-02, -2.1542e-01,  1.2526e-03],
        [ 9.7943e-02, -3.0464e-01,  4.3008e-04],
        [ 9.6921e-02, -2.5379e-01,  1.5486e-03],
        [ 9.6715e-02, -2.4816e-01,  2.1717e-03],
        [ 9.0872e-02, -1.0527e-01,  1.0718e-02],
        [ 9.6565e-02, -2.4520e-01,  1.4717e-03],
        [ 9.6916e-02, -1.0594e-01,  1.3328e-03],
        [ 9.7748e-02, -1.0725e-01,  4.0835e-04],
        [ 9.6657e-02, -2.0253e-01,  1.5198e-03],
        [ 9.5306e-02, -2.0880e-01,  3.7985e-03],
        [ 9.4410e-02, -1.5160e-01,  5.6471e-03],
        [ 9.7602e-02, -2.4427e-01,  1.8218e-03],
        [ 9.7524e-02, -3.0564e-01,  1.4509e-03],
        [ 9.3465e-02, -2.2659e-01,  5.4435e-03],
        [ 8.9130e-02, -1.8722e-01,  1.3929e-02],
        [ 9.4979e-02, -2.6163e-01,  2.8271e-03],
        [ 9.7782e-02, -3.0615e-01,  8.6364e-04],
        [ 8.9370e-02, -2.4579e-01,  2.1763e-02],
        [ 9.5894e-02, -3.1332e-01,  4.3375e-03],
        [ 9.9880e-02, -3.9814e-01,  1.3202e-05],
        [ 9.6571e-02, -3.2780e-01,  2.4657e-03],
        [ 9.9003e-02, -3.9373e-01,  1.3775e-04],
        [ 9.7103e-02, -3.5782e-01,  9.9099e-04],
        [ 9.9095e-02, -3.8698e-01,  1.0127e-04],
        [ 9.4900e-02, -3.4535e-01,  5.5900e-03],
        [ 9.7347e-02, -3.7462e-01,  1.8257e-03],
        [ 6.8532e-02, -6.0749e-02,  1.7263e-01],
        [ 6.8328e-02, -8.7820e-03,  2.5280e-01],
        [ 9.9073e-02, -3.9807e-01,  1.7667e-04],
        [ 9.3856e-02, -3.4884e-01,  8.8815e-03],
        [ 9.7302e-02, -3.6288e-01,  1.8883e-03],
        [ 9.7712e-02, -3.8285e-01,  1.3602e-03],
        [ 9.9158e-02, -3.9542e-01,  1.7598e-04],
        [ 9.7541e-02, -3.6462e-01,  2.1144e-03],
        [ 9.1220e-02, -2.4540e-01,  1.9735e-02],
        [ 5.2990e-02, -3.6003e-02,  4.5144e-01],
        [ 3.7697e-02, -6.8906e-03,  5.2132e-01],
        [ 6.7750e-02, -1.0062e-01,  3.2299e-01],
        [ 8.3296e-02, -2.7366e-01,  7.3454e-02],
        [ 8.2975e-02, -3.5811e-01,  1.2331e-01],
        [ 7.7452e-02, -3.1695e-01,  1.8570e-01],
        [ 7.2741e-03, -6.9754e-02,  8.9316e-01],
        [ 5.4129e-02, -2.2323e-01,  2.7698e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 48
Episode Length = 89
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1347,  1.1307,  1.1200,  1.1191,  1.1223,  1.1249,  1.1321,  1.1456,
         1.1435,  1.1333,  1.1352,  1.1406,  1.1399,  1.1452, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1534,  1.1522,  1.1365,  1.1411,  1.1282,  1.1487,
        -4.0000,  0.0000,  0.0000,  0.1545,  1.1432,  1.1424,  1.1328, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1665,  1.1644,  1.1626,  1.1623,  1.1474,
         1.1404,  1.1478,  1.1532,  1.1444,  1.1462,  1.1580,  1.1609,  1.1498,
         1.1499,  1.1417,  1.0000], device='cuda:0')
target_q_episode tensor([ 7.8081,  7.1664,  6.4910,  5.7800,  5.0316,  4.2438,  3.4145,  2.5416,
         1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000,
        -4.0000,  0.0000,  0.0000,  0.0000, -1.4344, -2.5625, -3.7500, -5.0000,
         0.0000,  0.0000,  0.0000,  0.0000, 10.7342, 10.2465,  9.7332,  9.1928,
         8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,
         2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1353,  1.1312,  1.1204,  1.1194,  1.1226,  1.1251,  1.1322,  1.1457,
         1.1435,  1.1333,  1.1351,  1.1404,  1.1396,  1.1448, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1534,  1.1523,  1.1364,  1.1409,  1.1279,  1.1483,
        -4.0000,  0.0000,  0.0000,  0.1545,  1.1430,  1.1421,  1.1324, -5.0000,
         0.0000,  0.0000,  0.0000,  0.1665,  1.1651,  1.1634,  1.1631,  1.1481,
         1.1410,  1.1484,  1.1538,  1.1448,  1.1466,  1.1584,  1.1611,  1.1500,
         1.1500,  1.1417,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.6913e-02, -2.0067e-01,  8.1375e-04],
        [ 9.8520e-02, -1.9125e-01,  2.0957e-04],
        [ 9.6423e-02, -1.5953e-01,  1.1252e-03],
        [ 9.8321e-02, -2.3216e-01,  2.2772e-04],
        [ 9.8502e-02, -2.1388e-01,  2.5159e-04],
        [ 9.7509e-02, -1.5552e-01,  4.0013e-04],
        [ 9.8515e-02, -1.5073e-01,  2.1768e-04],
        [ 9.8466e-02, -1.7845e-01,  2.5517e-04],
        [ 9.7521e-02, -8.7250e-02,  5.7358e-04],
        [ 9.8545e-02, -1.1680e-01,  1.8266e-04],
        [ 9.8770e-02, -1.2251e-01,  1.7408e-04],
        [ 9.8722e-02, -9.3182e-02,  1.6195e-04],
        [ 9.8858e-02, -1.0833e-01,  1.5566e-04],
        [ 9.8859e-02, -1.5274e-01,  1.4898e-04],
        [ 9.9061e-02, -1.6779e-01,  1.3447e-04],
        [ 9.9544e-02, -2.5607e-01,  2.8729e-05],
        [ 9.9145e-02, -1.8518e-01,  1.4725e-04],
        [ 9.9594e-02, -2.7890e-01,  3.2216e-05],
        [ 9.9611e-02, -2.9502e-01,  3.8266e-05],
        [ 9.9493e-02, -3.0026e-01,  4.3243e-05],
        [ 9.9776e-02, -3.5743e-01,  1.5676e-05],
        [ 9.9943e-02, -3.8665e-01,  1.0729e-06],
        [ 9.9968e-02, -3.9465e-01,  4.4703e-07],
        [ 9.9975e-02, -3.9758e-01,  2.3842e-07],
        [ 9.9981e-02, -3.9819e-01,  1.1921e-07],
        [ 9.9900e-02, -3.8814e-01,  1.7583e-06],
        [ 9.9901e-02, -3.8995e-01,  2.7120e-06],
        [ 9.9886e-02, -3.8666e-01,  3.9637e-06],
        [ 9.9917e-02, -3.9508e-01,  2.0862e-06],
        [ 9.9699e-02, -3.9063e-01,  1.3620e-05],
        [ 9.8836e-02, -3.4894e-01,  1.8844e-04],
        [ 9.8411e-02, -3.2517e-01,  3.2616e-04],
        [ 9.6371e-02, -2.2164e-01,  3.7327e-03],
        [ 9.0393e-02, -6.9354e-02,  1.7873e-02],
        [ 8.8035e-02, -1.0015e-01,  1.9014e-02],
        [ 8.5590e-02, -2.2740e-01,  2.8224e-02],
        [ 7.5706e-02, -1.5696e-01,  1.0561e-01],
        [ 3.2640e-02, -4.6451e-02,  7.3903e-01],
        [ 9.4455e-02, -1.9072e-01,  1.0960e-03],
        [ 9.2605e-02, -1.5372e-01,  2.8191e-03],
        [ 9.6302e-02, -2.0884e-01,  7.7310e-04],
        [ 8.8136e-02, -1.4058e-01,  7.5200e-03],
        [ 9.6187e-02, -2.5667e-01,  6.9413e-04],
        [ 9.4624e-02, -2.2291e-01,  1.8491e-03],
        [ 9.5164e-02, -2.9002e-01,  1.0244e-03],
        [ 9.4872e-02, -2.8114e-01,  1.5564e-03],
        [ 9.4917e-02, -2.0088e-01,  1.8971e-03],
        [ 9.3829e-02, -2.8629e-01,  1.8498e-03],
        [ 9.2188e-02, -2.3429e-01,  2.7929e-03],
        [ 9.5077e-02, -1.6395e-01,  1.8191e-03],
        [ 9.5353e-02, -2.1724e-01,  1.4133e-03],
        [ 9.4950e-02, -1.6043e-01,  1.9892e-03],
        [ 9.4989e-02, -2.4031e-01,  1.9280e-03],
        [ 9.7113e-02, -3.0490e-01,  6.3142e-04],
        [ 9.6290e-02, -3.0622e-01,  1.1575e-03],
        [ 9.1956e-02, -1.1869e-01,  7.6806e-03],
        [ 9.3712e-02, -1.9765e-01,  4.6258e-03],
        [ 9.6148e-02, -1.8621e-02,  1.5361e-03],
        [ 9.5055e-02,  9.0019e-02,  3.5923e-03],
        [ 9.7940e-02, -9.7558e-02,  6.3998e-04],
        [ 9.4748e-02, -8.0782e-02,  5.6516e-03],
        [ 9.8598e-02, -3.2659e-01,  4.9549e-04],
        [ 9.7404e-02, -2.4339e-01,  1.7241e-03],
        [ 9.9364e-02, -3.5767e-01,  1.0481e-04],
        [ 9.8470e-02, -1.8547e-01,  3.9071e-04],
        [ 9.7603e-02, -1.8172e-01,  6.5851e-04],
        [ 9.8876e-02, -3.3723e-01,  2.8554e-04],
        [ 9.8468e-02, -2.2761e-01,  3.8812e-04],
        [ 9.9123e-02, -3.1277e-01,  2.1192e-04],
        [ 9.7391e-02, -2.5768e-01,  1.2377e-03],
        [ 9.6856e-02, -3.4780e-01,  1.3915e-03],
        [ 9.8142e-02, -3.3754e-01,  6.2457e-04],
        [ 9.9575e-02, -3.8474e-01,  1.0061e-04],
        [ 9.7832e-02, -3.5830e-01,  9.5159e-04],
        [ 9.9570e-02, -3.9400e-01,  4.9651e-05],
        [ 9.8491e-02, -3.8281e-01,  2.2915e-04],
        [ 9.9066e-02, -3.6760e-01,  1.0258e-04],
        [ 9.7100e-02, -3.5615e-01,  1.2453e-03],
        [ 9.3747e-02, -1.4609e-01,  7.1720e-03],
        [ 9.1879e-02, -8.7141e-02,  1.5329e-02],
        [ 8.7732e-02, -1.7483e-01,  2.0226e-02],
        [ 8.1657e-02, -1.6019e-01,  5.1751e-02],
        [ 8.9884e-02, -3.0841e-01,  3.3724e-02],
        [ 9.2797e-02, -2.6308e-01,  1.2235e-02],
        [ 6.5945e-02, -1.4399e-01,  2.0049e-01],
        [ 7.8998e-02, -1.1899e-01,  5.4050e-02],
        [ 7.8113e-02, -1.4435e-01,  6.6592e-02],
        [ 7.5688e-02, -1.3768e-01,  8.3271e-02],
        [ 5.0311e-02, -6.7788e-02,  3.1867e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 49
Episode Length = 106
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1368,  1.1386,  1.1331,  1.1285,  1.1280,  1.1348,  1.1396,  1.1336,
         1.1263,  1.1275,  1.1331, -5.0000,  0.0000,  0.0000,  0.0000,  0.1566,
         1.1529,  1.1426,  1.1433,  1.1429,  1.1458,  1.1407,  1.1439,  1.1448,
         1.1471,  1.1468,  1.1423,  1.1418,  1.1387,  1.1422,  1.1422, -3.0000,
         0.0000,  0.1445,  1.1471,  1.1514,  1.1424,  1.1396,  1.1344,  1.1357,
         1.1356,  1.1482,  1.1485,  1.1502, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1571,  1.1514,  1.1431,  1.1414,  1.1395,  1.1428,  1.1441,
         1.1479,  1.1466,  1.1492,  1.1448, -4.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q_episode tensor([ 5.7800,  5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555, -0.3627,
        -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         9.3443,  8.7835,  8.1931,  7.5717,  6.9176,  6.2291,  5.5043,  4.7413,
         3.9382,  3.0929,  2.2030,  1.2664,  0.2804, -0.7575, -1.8500, -3.0000,
         0.0000,  0.0000,  4.4328,  3.6135,  2.7511,  1.8432,  0.8876, -0.1183,
        -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  5.6303,  4.8740,  4.0779,  3.2399,  2.3578,  1.4293,
         0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q tensor([ 1.1371,  1.1389,  1.1333,  1.1286,  1.1281,  1.1348,  1.1395,  1.1335,
         1.1262,  1.1273,  1.1328, -5.0000,  0.0000,  0.0000,  0.0000,  0.1566,
         1.1535,  1.1431,  1.1438,  1.1433,  1.1462,  1.1410,  1.1442,  1.1451,
         1.1473,  1.1469,  1.1424,  1.1418,  1.1386,  1.1421,  1.1420, -3.0000,
         0.0000,  0.1445,  1.1473,  1.1516,  1.1425,  1.1396,  1.1344,  1.1356,
         1.1355,  1.1480,  1.1482,  1.1498, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1571,  1.1517,  1.1434,  1.1416,  1.1397,  1.1429,  1.1441,
         1.1478,  1.1465,  1.1490,  1.1445, -4.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.4399e-02, -1.7142e-01,  1.0490e-02],
        [ 8.5628e-02, -1.5377e-01,  7.9319e-03],
        [ 8.1382e-02, -1.8086e-01,  1.5446e-02],
        [ 8.5327e-02, -1.6597e-01,  1.4209e-02],
        [ 8.0339e-02, -1.2646e-01,  2.0257e-02],
        [ 8.6241e-02, -1.7286e-01,  8.7386e-03],
        [ 9.4808e-02, -1.9899e-01,  1.2991e-03],
        [ 9.8177e-02, -3.4394e-01,  1.9827e-04],
        [ 9.6909e-02, -2.8730e-01,  6.9931e-04],
        [ 9.8178e-02, -2.8835e-01,  2.1124e-04],
        [ 9.8137e-02, -2.8584e-01,  2.4420e-04],
        [ 9.7562e-02, -2.1775e-01,  4.2057e-04],
        [ 9.8493e-02, -2.3236e-01,  9.7722e-05],
        [ 9.9072e-02, -3.1071e-01,  2.5719e-05],
        [ 9.9304e-02, -3.1399e-01,  1.6123e-05],
        [ 9.9590e-02, -3.2707e-01,  5.3048e-06],
        [ 9.9487e-02, -3.3270e-01,  7.5996e-06],
        [ 9.9758e-02, -3.5913e-01,  1.9670e-06],
        [ 9.9843e-02, -3.5562e-01,  1.4007e-06],
        [ 9.9826e-02, -3.7093e-01,  1.5497e-06],
        [ 9.9884e-02, -3.7491e-01,  8.0466e-07],
        [ 9.9865e-02, -3.6410e-01,  1.4603e-06],
        [ 9.9860e-02, -3.7445e-01,  1.2815e-06],
        [ 9.9705e-02, -3.4925e-01,  7.9572e-06],
        [ 9.9796e-02, -3.7130e-01,  3.7849e-06],
        [ 9.9690e-02, -3.6296e-01,  4.6492e-06],
        [ 9.9805e-02, -3.7973e-01,  2.2650e-06],
        [ 9.9765e-02, -3.6528e-01,  4.6194e-06],
        [ 9.9841e-02, -3.7234e-01,  2.2352e-06],
        [ 9.9701e-02, -3.4726e-01,  6.1691e-06],
        [ 9.9692e-02, -3.4141e-01,  1.0639e-05],
        [ 9.9610e-02, -3.2026e-01,  1.5825e-05],
        [ 9.9523e-02, -3.4392e-01,  2.6196e-05],
        [ 9.8985e-02, -3.0759e-01,  1.5914e-04],
        [ 9.8785e-02, -2.9351e-01,  2.3940e-04],
        [ 9.8328e-02, -2.9736e-01,  4.7439e-04],
        [ 9.9033e-02, -3.1512e-01,  2.2390e-04],
        [ 9.5163e-02, -2.8006e-01,  3.7438e-03],
        [ 8.8179e-02, -2.5111e-01,  3.2375e-02],
        [ 8.2463e-02, -2.5684e-01,  6.5504e-02],
        [ 5.8636e-02, -1.7516e-01,  4.1298e-01],
        [ 1.4338e-02, -1.0640e-01,  8.1183e-01],
        [ 8.1243e-02, -1.2426e-01,  1.2841e-02],
        [ 8.6643e-02, -1.4197e-01,  6.0535e-03],
        [ 8.3414e-02, -1.6121e-01,  1.0491e-02],
        [ 8.7527e-02, -2.2127e-01,  4.6670e-03],
        [ 9.5229e-02, -2.7582e-01,  7.5167e-04],
        [ 9.5225e-02, -2.6329e-01,  1.6089e-03],
        [ 9.9202e-02, -3.6269e-01,  9.3877e-05],
        [ 9.4468e-02, -2.2962e-01,  2.9094e-03],
        [ 9.7474e-02, -2.9900e-01,  6.2820e-04],
        [ 9.9517e-02, -3.6195e-01,  4.9323e-05],
        [ 9.9100e-02, -2.8069e-01,  7.4118e-05],
        [ 9.9719e-02, -3.9166e-01,  7.9274e-06],
        [ 9.9670e-02, -3.8990e-01,  1.0639e-05],
        [ 9.9206e-02, -3.6475e-01,  6.0290e-05],
        [ 9.9587e-02, -3.7723e-01,  2.4050e-05],
        [ 9.9425e-02, -3.6005e-01,  5.1051e-05],
        [ 9.8914e-02, -2.7305e-01,  1.2413e-04],
        [ 9.7566e-02, -2.2557e-01,  2.3443e-04],
        [ 9.4348e-02, -1.5957e-01,  1.4405e-03],
        [ 9.8172e-02, -2.3359e-01,  2.2051e-04],
        [ 9.7573e-02, -2.5131e-01,  3.4377e-04],
        [ 9.9494e-02, -3.4096e-01,  1.6570e-05],
        [ 9.9678e-02, -3.5638e-01,  5.6326e-06],
        [ 9.8863e-02, -2.2704e-01,  1.0684e-04],
        [ 9.6612e-02, -2.0500e-01,  1.0003e-03],
        [ 9.8098e-02, -2.3827e-01,  4.2042e-04],
        [ 9.9685e-02, -3.6724e-01,  5.0962e-06],
        [ 9.6104e-02, -2.4468e-01,  1.9808e-03],
        [ 9.8065e-02, -2.5614e-01,  4.7877e-04],
        [ 9.6791e-02, -2.3794e-01,  1.0530e-03],
        [ 9.9007e-02, -3.1069e-01,  1.9252e-04],
        [ 9.9174e-02, -3.6796e-01,  1.0666e-04],
        [ 9.7292e-02, -2.9688e-01,  6.8322e-04],
        [ 9.5177e-02, -2.5162e-01,  1.6228e-03],
        [ 9.7252e-02, -2.4418e-01,  6.6769e-04],
        [ 9.7650e-02, -3.1693e-01,  3.1316e-04],
        [ 9.7356e-02, -3.3906e-01,  4.1375e-04],
        [ 9.4159e-02, -2.5698e-01,  6.2457e-03],
        [ 9.7458e-02, -3.1564e-01,  1.2928e-03],
        [ 9.0995e-02, -2.1300e-01,  9.2841e-03],
        [ 9.8082e-02, -3.3237e-01,  1.9497e-04],
        [ 9.4651e-02, -3.1596e-01,  4.1504e-03],
        [ 8.8818e-02, -2.5889e-01,  2.7438e-02],
        [ 9.3468e-02, -3.1200e-01,  4.8443e-03],
        [ 9.7441e-02, -3.3997e-01,  7.0217e-04],
        [ 9.5376e-02, -3.1174e-01,  1.9341e-03],
        [ 9.7453e-02, -2.6382e-01,  7.8708e-04],
        [ 9.6872e-02, -2.8929e-01,  2.5529e-03],
        [ 9.6845e-02, -3.6700e-01,  3.2836e-03],
        [ 9.2544e-02, -3.2386e-01,  1.3015e-02],
        [ 9.5300e-02, -3.2155e-01,  2.3103e-03],
        [ 8.1845e-02, -2.3850e-01,  4.7099e-02],
        [ 6.9198e-02, -7.5854e-02,  1.4104e-01],
        [ 6.7502e-02, -1.6522e-01,  1.4451e-01],
        [ 6.3246e-02, -1.8905e-01,  1.6950e-01],
        [ 5.6434e-02, -1.5265e-01,  2.0945e-01],
        [ 8.2359e-02, -2.2177e-01,  5.3178e-02],
        [ 6.9492e-02, -2.2886e-01,  1.3765e-01],
        [ 6.5803e-02, -2.2410e-01,  1.4367e-01],
        [ 7.0674e-02, -2.1789e-01,  1.3250e-01],
        [ 6.8216e-02, -1.5939e-01,  1.2939e-01],
        [ 7.6438e-02, -2.0490e-01,  7.1200e-02],
        [ 6.7817e-02, -1.6735e-01,  1.2851e-01],
        [ 8.5200e-02, -3.0473e-01,  3.9301e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 50
Episode Length = 78
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1316,  1.1351,  1.1305,  1.1357,  1.1291,  1.1353,  1.1335,  1.1359,
         1.1427, -4.0000,  0.0000,  0.0000,  0.1444,  1.1512,  1.1520, -8.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1439,  1.1531,
         1.1620,  1.1585,  1.1512,  1.1553,  1.1577,  1.1537,  1.1514,  1.1587,
         1.1700,  1.1606,  1.1628,  1.1598,  1.1590,  1.1576,  1.1565,  1.0000],
       device='cuda:0')
target_q_episode tensor([ 4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600,
        -2.8000, -4.0000,  0.0000,  0.0000,  0.0000, -5.2700, -6.6000, -8.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 11.6376,
        11.1975, 10.7342, 10.2465,  9.7332,  9.1928,  8.6240,  8.0253,  7.3950,
         6.7316,  6.0333,  5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000],
       device='cuda:0')
target_q tensor([ 1.1318,  1.1352,  1.1306,  1.1357,  1.1291,  1.1353,  1.1335,  1.1358,
         1.1425, -4.0000,  0.0000,  0.0000,  0.1444,  1.1509,  1.1515, -8.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1439,  1.1537,
         1.1625,  1.1590,  1.1517,  1.1557,  1.1581,  1.1541,  1.1518,  1.1590,
         1.1703,  1.1609,  1.1630,  1.1600,  1.1592,  1.1577,  1.1566,  1.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.7564e-02, -2.7087e-01,  3.7655e-04],
        [ 9.8411e-02, -2.7538e-01,  2.0725e-04],
        [ 9.8213e-02, -2.3368e-01,  2.5457e-04],
        [ 9.8852e-02, -3.0683e-01,  9.6112e-05],
        [ 9.8841e-02, -3.0295e-01,  8.2314e-05],
        [ 9.8636e-02, -2.6849e-01,  1.1352e-04],
        [ 9.9139e-02, -2.7754e-01,  5.2154e-05],
        [ 9.9341e-02, -2.9912e-01,  3.3319e-05],
        [ 9.9148e-02, -2.6625e-01,  6.5506e-05],
        [ 9.7848e-02, -2.0244e-01,  3.4580e-04],
        [ 9.8950e-02, -2.4846e-01,  9.2268e-05],
        [ 9.9174e-02, -2.4155e-01,  4.7296e-05],
        [ 9.8789e-02, -2.2480e-01,  9.8407e-05],
        [ 9.9229e-02, -2.8223e-01,  4.2379e-05],
        [ 9.8724e-02, -2.4387e-01,  1.3420e-04],
        [ 9.9463e-02, -3.1045e-01,  3.2395e-05],
        [ 9.9153e-02, -2.8446e-01,  7.1853e-05],
        [ 9.9577e-02, -3.2802e-01,  2.3305e-05],
        [ 9.9343e-02, -3.3602e-01,  5.2780e-05],
        [ 9.9771e-02, -3.7466e-01,  8.9109e-06],
        [ 9.9818e-02, -3.8033e-01,  4.7088e-06],
        [ 9.9968e-02, -3.9617e-01,  2.3842e-07],
        [ 9.9984e-02, -3.9868e-01,  5.9605e-08],
        [ 9.9986e-02, -3.9889e-01,  2.9802e-08],
        [ 9.9994e-02, -3.9957e-01,  0.0000e+00],
        [ 9.9972e-02, -3.9792e-01,  1.4901e-07],
        [ 9.9921e-02, -3.9117e-01,  1.8775e-06],
        [ 9.9887e-02, -3.8892e-01,  2.5332e-06],
        [ 9.9680e-02, -3.8630e-01,  1.6868e-05],
        [ 9.9957e-02, -3.9925e-01,  3.2783e-07],
        [ 9.9788e-02, -3.9182e-01,  4.5300e-06],
        [ 9.9164e-02, -3.6123e-01,  9.3669e-05],
        [ 9.8657e-02, -3.3530e-01,  5.4526e-04],
        [ 9.4357e-02, -1.6923e-01,  3.7634e-03],
        [ 9.4191e-02, -1.9896e-01,  2.9921e-03],
        [ 8.7861e-02, -2.1921e-01,  2.0878e-02],
        [ 7.0252e-02, -1.5759e-01,  1.4132e-01],
        [ 4.3101e-02, -1.3398e-01,  6.8680e-01],
        [ 9.4091e-02, -2.4350e-01,  2.3566e-03],
        [ 9.6326e-02, -2.5805e-01,  7.4413e-04],
        [ 9.8044e-02, -2.7754e-01,  2.2173e-04],
        [ 9.8605e-02, -2.9520e-01,  1.5673e-04],
        [ 9.7949e-02, -2.6860e-01,  3.2479e-04],
        [ 9.9178e-02, -3.4160e-01,  5.2989e-05],
        [ 9.8925e-02, -3.2940e-01,  8.3119e-05],
        [ 9.8161e-02, -2.9833e-01,  2.2677e-04],
        [ 9.8363e-02, -3.0016e-01,  2.3732e-04],
        [ 9.8912e-02, -2.5037e-01,  9.1553e-05],
        [ 9.8765e-02, -2.5137e-01,  1.0896e-04],
        [ 9.8594e-02, -1.5098e-01,  1.8969e-04],
        [ 9.8575e-02, -1.9619e-01,  1.5080e-04],
        [ 9.9028e-02, -2.5134e-01,  8.6457e-05],
        [ 9.8147e-02, -1.2671e-01,  2.7138e-04],
        [ 9.6755e-02, -2.6325e-01,  6.7461e-04],
        [ 9.4678e-02, -2.3887e-01,  3.0096e-03],
        [ 9.7970e-02, -3.5158e-01,  5.6025e-04],
        [ 9.8113e-02, -3.3227e-01,  3.6445e-04],
        [ 9.7337e-02, -2.2064e-01,  5.4672e-04],
        [ 9.8754e-02, -2.0452e-01,  1.3965e-04],
        [ 9.8126e-02, -2.1507e-01,  5.4413e-04],
        [ 9.8216e-02, -2.7377e-01,  6.1277e-04],
        [ 9.8005e-02, -2.3749e-01,  6.8209e-04],
        [ 9.8810e-02, -3.1183e-01,  2.2945e-04],
        [ 9.6022e-02, -1.6495e-01,  2.3634e-03],
        [ 9.9603e-02, -3.8184e-01,  3.4332e-05],
        [ 9.9663e-02, -3.8232e-01,  3.3826e-05],
        [ 9.9521e-02, -3.7609e-01,  3.8207e-05],
        [ 9.7496e-02, -3.2383e-01,  6.2883e-04],
        [ 9.6733e-02, -2.7975e-01,  7.8806e-04],
        [ 9.9116e-02, -3.6920e-01,  9.4056e-05],
        [ 9.9171e-02, -3.8882e-01,  8.8990e-05],
        [ 9.9622e-02, -3.9373e-01,  3.2872e-05],
        [ 9.7431e-02, -3.8086e-01,  6.8739e-04],
        [ 9.8400e-02, -3.6648e-01,  3.5003e-04],
        [ 9.5737e-02, -3.4420e-01,  1.6968e-03],
        [ 9.6065e-02, -3.2903e-01,  2.0103e-03],
        [ 8.8816e-02, -2.7021e-01,  1.2169e-02],
        [ 8.6924e-02, -1.9083e-01,  2.3322e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Saving checkpoint
Run No. 51
Episode Length = 116
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1253,   1.1280,   1.1354,   1.1486,   1.1218,  -4.0000,   0.0000,
          0.0000,   0.1229,   1.1510,   1.1554,   1.1480,   1.1500, -10.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.1606,   1.1512,   1.1575,   1.1602,   1.1575,   1.1533,
          1.1502,   1.1568,   1.1588,   1.1598,   1.1580,   1.1556,   1.1466,
          1.1498,   1.1568,   1.1610,   1.1590,   1.1648,   1.1622,   1.1610,
          1.1550,   1.1604,   1.1644,  -4.0000,   0.0000,   0.0000,   0.1522,
          1.1526,   1.1609,   1.1499,   1.1541,   1.1585,   1.1622,   1.1518,
          1.1572,  -6.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1465,
          1.1387,   1.1530,   1.1531,   1.1467,   1.1423,   1.1478,   1.1496,
          1.1502,   1.1410,   1.1398,   1.0000], device='cuda:0')
target_q_episode tensor([  1.4293,   0.4519,  -0.5770,  -1.6600,  -2.8000,  -4.0000,   0.0000,
          0.0000,   0.0000,  -4.4352,  -5.7213,  -7.0750,  -8.5000, -10.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,  12.2352,  11.8265,  11.3963,  10.9435,  10.4669,
          9.9651,   9.4370,   8.8810,   8.2958,   7.6798,   7.0314,   6.3488,
          5.6303,   4.8740,   4.0779,   3.2399,   2.3578,   1.4293,   0.4519,
         -0.5770,  -1.6600,  -2.8000,  -4.0000,   0.0000,   0.0000,   0.0000,
          2.7511,   1.8432,   0.8876,  -0.1183,  -1.1772,  -2.2917,  -3.4650,
         -4.7000,  -6.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          8.6240,   8.0253,   7.3950,   6.7316,   6.0333,   5.2982,   4.5244,
          3.7099,   2.8525,   1.9500,   1.0000], device='cuda:0')
target_q tensor([  1.1253,   1.1279,   1.1353,   1.1485,   1.1216,  -4.0000,   0.0000,
          0.0000,   0.1229,   1.1507,   1.1551,   1.1477,   1.1495, -10.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.1606,   1.1517,   1.1580,   1.1607,   1.1579,   1.1537,
          1.1506,   1.1571,   1.1591,   1.1601,   1.1582,   1.1559,   1.1469,
          1.1500,   1.1570,   1.1611,   1.1591,   1.1648,   1.1622,   1.1610,
          1.1550,   1.1603,   1.1642,  -4.0000,   0.0000,   0.0000,   0.1522,
          1.1527,   1.1609,   1.1499,   1.1540,   1.1584,   1.1620,   1.1516,
          1.1570,  -6.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.1465,
          1.1390,   1.1533,   1.1534,   1.1469,   1.1425,   1.1480,   1.1497,
          1.1503,   1.1411,   1.1399,   1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.3869e-02, -2.9599e-01,  1.5228e-03],
        [ 9.4858e-02, -2.9277e-01,  1.1308e-03],
        [ 9.6855e-02, -3.1103e-01,  4.9049e-04],
        [ 8.7759e-02, -1.4301e-01,  9.0167e-03],
        [ 9.1615e-02, -1.4968e-01,  3.7838e-03],
        [ 9.6172e-02, -2.7280e-01,  7.1743e-04],
        [ 9.5403e-02, -2.4865e-01,  9.7409e-04],
        [ 9.6952e-02, -2.9359e-01,  5.2509e-04],
        [ 9.5123e-02, -1.9897e-01,  1.2823e-03],
        [ 9.5475e-02, -2.1262e-01,  6.8003e-04],
        [ 9.6269e-02, -2.2902e-01,  4.0114e-04],
        [ 9.6549e-02, -2.3379e-01,  4.2132e-04],
        [ 9.6810e-02, -2.4897e-01,  4.1848e-04],
        [ 9.7882e-02, -2.8572e-01,  1.3044e-04],
        [ 9.7060e-02, -2.4291e-01,  3.1021e-04],
        [ 9.7758e-02, -2.7285e-01,  1.9249e-04],
        [ 9.8805e-02, -2.9293e-01,  7.6562e-05],
        [ 9.9435e-02, -3.4324e-01,  1.1981e-05],
        [ 9.9628e-02, -3.6140e-01,  6.1691e-06],
        [ 9.9609e-02, -3.4970e-01,  6.2585e-06],
        [ 9.9418e-02, -3.4525e-01,  1.4335e-05],
        [ 9.9638e-02, -3.5222e-01,  4.7684e-06],
        [ 9.9217e-02, -3.3216e-01,  2.8372e-05],
        [ 9.9454e-02, -3.6995e-01,  3.0816e-05],
        [ 9.8782e-02, -3.5103e-01,  1.2779e-04],
        [ 9.9050e-02, -3.5496e-01,  1.2961e-04],
        [ 9.9255e-02, -3.9184e-01,  2.3901e-05],
        [ 9.9573e-02, -3.8982e-01,  1.4782e-05],
        [ 9.9369e-02, -3.7821e-01,  6.8069e-05],
        [ 9.9839e-02, -3.9783e-01,  3.6359e-06],
        [ 9.8638e-02, -3.0238e-01,  2.2379e-04],
        [ 9.6617e-02, -2.4370e-01,  6.1890e-04],
        [ 9.5827e-02, -2.8250e-01,  1.8706e-03],
        [ 9.9803e-02, -3.9795e-01,  8.1956e-06],
        [ 9.8110e-02, -3.7685e-01,  7.2563e-04],
        [ 9.9934e-02, -3.9842e-01,  7.7486e-07],
        [ 9.9777e-02, -3.9498e-01,  8.5533e-06],
        [ 9.9042e-02, -3.4514e-01,  2.1616e-04],
        [ 9.8733e-02, -3.1461e-01,  2.6298e-04],
        [ 9.3832e-02, -2.0279e-01,  8.1911e-03],
        [ 8.4712e-02, -2.3272e-01,  2.8950e-02],
        [-1.0475e-02,  6.0851e-02,  9.2203e-01],
        [ 7.7451e-02, -1.4931e-01,  1.7839e-02],
        [ 9.0505e-02, -2.2688e-01,  4.4253e-03],
        [ 8.5613e-02, -1.6734e-01,  1.1595e-02],
        [ 9.0983e-02, -2.0946e-01,  5.4718e-03],
        [ 8.8601e-02, -1.8990e-01,  6.6994e-03],
        [ 8.6563e-02, -1.5737e-01,  7.8453e-03],
        [ 9.5989e-02, -2.8922e-01,  9.4837e-04],
        [ 9.4465e-02, -2.2853e-01,  1.6807e-03],
        [ 9.8788e-02, -3.6745e-01,  9.9540e-05],
        [ 9.9719e-02, -3.9167e-01,  6.9141e-06],
        [ 9.8867e-02, -3.8174e-01,  5.9396e-05],
        [ 9.9114e-02, -3.7165e-01,  6.0558e-05],
        [ 9.9240e-02, -3.8118e-01,  3.3259e-05],
        [ 9.7091e-02, -2.6996e-01,  3.8409e-04],
        [ 9.8261e-02, -2.7697e-01,  3.9658e-04],
        [ 9.5225e-02, -2.3475e-01,  1.2437e-03],
        [ 9.7564e-02, -2.8553e-01,  3.6609e-04],
        [ 9.7623e-02, -3.5833e-01,  2.5588e-04],
        [ 9.9427e-02, -3.8992e-01,  2.6464e-05],
        [ 9.9132e-02, -3.7389e-01,  6.1572e-05],
        [ 9.9215e-02, -3.6686e-01,  6.8635e-05],
        [ 9.8719e-02, -3.5706e-01,  1.3182e-04],
        [ 9.9357e-02, -3.5569e-01,  7.2628e-05],
        [ 9.7017e-02, -3.1723e-01,  4.5666e-04],
        [ 9.6908e-02, -3.4259e-01,  8.1596e-04],
        [ 9.8833e-02, -3.8649e-01,  1.2928e-04],
        [ 9.8188e-02, -3.4927e-01,  4.8083e-04],
        [ 9.6084e-02, -2.6714e-01,  3.0769e-03],
        [ 9.5528e-02, -3.2594e-01,  2.9489e-03],
        [ 9.7727e-02, -2.9130e-01,  8.9499e-04],
        [ 9.8108e-02, -3.5640e-01,  4.4018e-04],
        [ 9.8260e-02, -3.1013e-01,  2.3854e-04],
        [ 9.7990e-02, -3.0940e-01,  2.7004e-04],
        [ 8.9500e-02, -1.8219e-01,  1.3275e-02],
        [ 9.8249e-02, -3.4917e-01,  4.7219e-04],
        [ 9.4184e-02, -2.6412e-01,  6.0858e-03],
        [ 9.5082e-02, -3.0078e-01,  4.3313e-03],
        [ 9.7019e-02, -3.2737e-01,  1.9948e-03],
        [ 9.4681e-02, -3.4387e-01,  3.1094e-03],
        [ 9.8093e-02, -3.7787e-01,  4.7013e-04],
        [ 9.3262e-02, -3.3267e-01,  6.0617e-03],
        [ 8.6309e-02, -2.7915e-01,  3.0293e-02],
        [ 8.1598e-02, -2.3160e-01,  5.4404e-02],
        [ 9.4395e-02, -3.2785e-01,  6.2982e-03],
        [ 9.4852e-02, -3.6239e-01,  4.9211e-03],
        [ 9.9562e-02, -3.9785e-01,  2.8431e-05],
        [ 9.9765e-02, -3.9769e-01,  8.9407e-06],
        [ 9.9359e-02, -3.8832e-01,  5.7071e-05],
        [ 9.8433e-02, -3.7524e-01,  3.6067e-04],
        [ 9.9671e-02, -3.9211e-01,  3.7521e-05],
        [ 9.8145e-02, -3.7726e-01,  6.3580e-04],
        [ 9.9530e-02, -3.9619e-01,  3.1412e-05],
        [ 9.9417e-02, -3.9535e-01,  2.9802e-05],
        [ 9.9206e-02, -3.8947e-01,  1.1301e-04],
        [ 9.7388e-02, -3.8312e-01,  1.2029e-03],
        [ 9.7800e-02, -3.6031e-01,  9.7904e-04],
        [ 9.3979e-02, -2.8211e-01,  4.3155e-03],
        [ 8.3230e-02, -1.6892e-01,  2.8390e-02],
        [ 7.9075e-02, -1.6071e-01,  4.1009e-02],
        [ 8.3467e-02, -2.8541e-01,  2.8659e-02],
        [ 5.9304e-02, -5.9444e-02,  2.4950e-01],
        [ 8.4107e-02, -2.6273e-01,  6.5052e-02],
        [ 9.8995e-02, -3.9148e-01,  3.8582e-04],
        [ 9.5134e-02, -3.5289e-01,  7.0811e-03],
        [ 9.8659e-02, -3.8582e-01,  4.5419e-04],
        [ 9.9443e-02, -3.9534e-01,  4.2647e-05],
        [ 9.5808e-02, -3.3148e-01,  3.1394e-03],
        [ 9.1236e-02, -1.8033e-01,  2.1402e-02],
        [ 8.9875e-02, -1.8827e-01,  2.9891e-02],
        [ 9.1134e-02, -2.7930e-01,  1.8028e-02],
        [ 8.1251e-02, -2.5673e-01,  8.3096e-02],
        [ 4.8790e-02, -1.6908e-01,  5.1125e-01],
        [ 5.1738e-02, -1.5248e-01,  4.4501e-01],
        [ 5.4757e-02, -1.5771e-01,  2.5548e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 52
Episode Length = 84
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1364,  1.1355,  1.1408,  1.1450,  1.1473,  1.1429,  1.1356,  1.1348,
         1.1339, -3.0000,  0.0000,  0.1559,  1.1366,  1.1485,  1.1474, -7.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1241,  1.1408,  1.1515,
         1.1554,  1.1601,  1.1595,  1.1541,  1.1567,  1.1460,  1.1526,  1.1645,
         1.1685,  1.1572,  1.1575,  1.1710,  1.1665,  1.1620,  1.1704,  1.1715,
         1.1751,  1.1640,  1.1552,  1.1566,  1.1635,  1.0000], device='cuda:0')
target_q_episode tensor([ 5.5043,  4.7413,  3.9382,  3.0929,  2.2030,  1.2664,  0.2804, -0.7575,
        -1.8500, -3.0000,  0.0000,  0.0000, -3.1491, -4.3675, -5.6500, -7.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 14.1602, 13.8529,
        13.5293, 13.1888, 12.8303, 12.4529, 12.0557, 11.6376, 11.1975, 10.7342,
        10.2465,  9.7332,  9.1928,  8.6240,  8.0253,  7.3950,  6.7316,  6.0333,
         5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1366,  1.1356,  1.1409,  1.1450,  1.1473,  1.1429,  1.1355,  1.1348,
         1.1338, -3.0000,  0.0000,  0.1559,  1.1365,  1.1483,  1.1472, -7.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1241,  1.1413,  1.1520,
         1.1558,  1.1606,  1.1599,  1.1545,  1.1571,  1.1464,  1.1530,  1.1648,
         1.1688,  1.1575,  1.1578,  1.1712,  1.1668,  1.1622,  1.1706,  1.1716,
         1.1752,  1.1641,  1.1553,  1.1567,  1.1635,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.5468e-02, -2.1059e-01,  1.2284e-03],
        [ 9.4489e-02, -1.7749e-01,  1.5033e-03],
        [ 9.6550e-02, -2.4447e-01,  7.1231e-04],
        [ 9.8391e-02, -2.9838e-01,  1.7819e-04],
        [ 9.9191e-02, -3.2454e-01,  4.3601e-05],
        [ 9.9293e-02, -2.7443e-01,  3.8892e-05],
        [ 9.8528e-02, -2.1895e-01,  1.7667e-04],
        [ 9.9467e-02, -2.7842e-01,  2.0027e-05],
        [ 9.8073e-02, -1.9115e-01,  2.8783e-04],
        [ 9.8786e-02, -2.5282e-01,  1.1188e-04],
        [ 9.7968e-02, -1.9665e-01,  2.4003e-04],
        [ 9.8901e-02, -2.4458e-01,  8.5711e-05],
        [ 9.8261e-02, -2.1740e-01,  2.2295e-04],
        [ 9.8747e-02, -2.2451e-01,  1.1784e-04],
        [ 9.8519e-02, -2.5251e-01,  1.8620e-04],
        [ 9.8634e-02, -2.6503e-01,  1.5143e-04],
        [ 9.8869e-02, -2.7896e-01,  1.1823e-04],
        [ 9.8765e-02, -2.9797e-01,  1.2842e-04],
        [ 9.9337e-02, -3.3620e-01,  6.2376e-05],
        [ 9.9701e-02, -3.5983e-01,  1.7434e-05],
        [ 9.9740e-02, -3.7422e-01,  1.0550e-05],
        [ 9.9875e-02, -3.8699e-01,  2.4438e-06],
        [ 9.9953e-02, -3.9651e-01,  2.3842e-07],
        [ 9.9945e-02, -3.9700e-01,  3.5763e-07],
        [ 9.9979e-02, -3.9801e-01,  8.9407e-08],
        [ 9.9944e-02, -3.9663e-01,  3.5763e-07],
        [ 9.9874e-02, -3.8713e-01,  2.6822e-06],
        [ 9.9859e-02, -3.9092e-01,  3.0994e-06],
        [ 9.9776e-02, -3.9070e-01,  1.0341e-05],
        [ 9.9919e-02, -3.9867e-01,  8.0466e-07],
        [ 9.9781e-02, -3.8779e-01,  5.6326e-06],
        [ 9.8726e-02, -3.2430e-01,  1.1954e-04],
        [ 9.8343e-02, -2.8556e-01,  6.6394e-04],
        [ 8.9298e-02, -8.8320e-02,  8.7155e-03],
        [ 8.9479e-02, -1.6261e-01,  7.4703e-03],
        [ 8.3003e-02, -1.9312e-01,  2.9008e-02],
        [ 6.1553e-02, -1.3535e-01,  2.3895e-01],
        [ 8.5776e-03, -4.2541e-02,  8.8850e-01],
        [ 9.6317e-02, -2.8997e-01,  6.9666e-04],
        [ 9.4187e-02, -2.3671e-01,  1.7290e-03],
        [ 9.7210e-02, -2.5842e-01,  4.6283e-04],
        [ 9.8866e-02, -3.2506e-01,  6.1899e-05],
        [ 9.6386e-02, -1.8336e-01,  7.0810e-04],
        [ 9.5330e-02, -1.4448e-01,  1.1333e-03],
        [ 9.5068e-02, -1.9177e-01,  1.2183e-03],
        [ 9.6176e-02, -1.9232e-01,  8.6737e-04],
        [ 9.5806e-02, -1.4123e-01,  8.0535e-04],
        [ 9.7935e-02, -2.6885e-01,  2.2617e-04],
        [ 9.8358e-02, -2.6337e-01,  2.1732e-04],
        [ 9.5180e-02, -1.5049e-01,  1.6957e-03],
        [ 9.5502e-02, -2.4090e-01,  1.5283e-03],
        [ 9.3676e-02, -1.9234e-01,  2.2015e-03],
        [ 9.2142e-02, -2.6299e-01,  3.2330e-03],
        [ 9.0671e-02, -1.9874e-01,  4.7452e-03],
        [ 9.6273e-02, -3.2286e-01,  1.8144e-03],
        [ 9.6473e-02, -3.3119e-01,  7.8288e-04],
        [ 9.8095e-02, -2.9230e-01,  4.2963e-04],
        [ 9.5767e-02, -1.9995e-01,  2.2300e-03],
        [ 9.6589e-02, -1.8936e-01,  8.1357e-04],
        [ 9.8557e-02, -1.1360e-01,  9.9957e-05],
        [ 9.8734e-02, -3.1415e-01,  1.7202e-04],
        [ 9.7571e-02, -3.1004e-01,  5.5474e-04],
        [ 9.4937e-02, -2.0877e-01,  1.8322e-03],
        [ 9.8393e-02, -3.5603e-01,  3.4890e-04],
        [ 9.7443e-02, -2.4873e-01,  5.9837e-04],
        [ 9.8669e-02, -2.6718e-01,  1.3012e-04],
        [ 9.8643e-02, -2.4317e-01,  1.4380e-04],
        [ 9.7994e-02, -2.7165e-01,  2.9498e-04],
        [ 9.9226e-02, -3.5501e-01,  5.9098e-05],
        [ 9.9769e-02, -3.8515e-01,  5.9009e-06],
        [ 9.9185e-02, -3.8095e-01,  1.0070e-04],
        [ 9.9402e-02, -3.9430e-01,  3.0369e-05],
        [ 9.8833e-02, -3.8073e-01,  1.9494e-04],
        [ 9.9548e-02, -3.7872e-01,  9.1404e-05],
        [ 9.9115e-02, -3.8518e-01,  9.8616e-05],
        [ 9.9667e-02, -3.9766e-01,  1.5497e-05],
        [ 9.8148e-02, -3.7750e-01,  3.2654e-04],
        [ 9.8628e-02, -3.8033e-01,  1.8302e-04],
        [ 9.6174e-02, -3.7319e-01,  8.6591e-04],
        [ 9.8563e-02, -3.7571e-01,  2.5600e-04],
        [ 9.4479e-02, -3.2676e-01,  2.1309e-03],
        [ 9.7629e-02, -3.3936e-01,  4.6432e-04],
        [ 9.4445e-02, -2.7120e-01,  3.0936e-03],
        [ 9.3358e-02, -1.9036e-01,  6.3670e-03]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 53
Episode Length = 108
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1446,  1.1389,  1.1370,  1.1436,  1.1401,  1.1297,  1.1332,  1.1442,
         1.1340,  1.1368,  1.1317,  1.1375,  1.1377,  1.1450,  1.1426,  1.1502,
         1.1497, -4.0000,  0.0000,  0.0000,  0.1299,  1.1574,  1.1434,  1.1468,
         1.1441,  1.1483, -5.0000,  0.0000,  0.0000,  0.0000,  0.1424,  1.1446,
         1.1575,  1.1616,  1.1499,  1.1573, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1542,  1.1623,  1.1543,  1.1525,  1.1533,  1.1546,  1.1385,
         1.1468, -5.0000,  0.0000,  0.0000,  0.0000,  0.1468,  1.1443,  1.1450,
         1.1427,  1.1444,  1.1536,  1.1558,  1.1557, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 9.9651,  9.4370,  8.8810,  8.2958,  7.6798,  7.0314,  6.3488,  5.6303,
         4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600,
        -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  0.6555, -0.3627, -1.4344,
        -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1183,
        -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625,
        -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.5416,  1.6227,
         0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1449,  1.1392,  1.1373,  1.1438,  1.1403,  1.1299,  1.1333,  1.1443,
         1.1341,  1.1368,  1.1318,  1.1375,  1.1378,  1.1449,  1.1426,  1.1501,
         1.1495, -4.0000,  0.0000,  0.0000,  0.1299,  1.1573,  1.1434,  1.1467,
         1.1440,  1.1481, -5.0000,  0.0000,  0.0000,  0.0000,  0.1424,  1.1445,
         1.1574,  1.1615,  1.1498,  1.1571, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1542,  1.1623,  1.1543,  1.1525,  1.1533,  1.1545,  1.1384,
         1.1466, -5.0000,  0.0000,  0.0000,  0.0000,  0.1468,  1.1443,  1.1450,
         1.1427,  1.1443,  1.1535,  1.1557,  1.1556, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 6.5411e-02, -1.0811e-01,  5.6162e-02],
        [ 6.1704e-02, -7.4312e-02,  6.5971e-02],
        [ 5.8441e-02, -9.8106e-02,  1.0253e-01],
        [ 6.1093e-02, -9.1722e-02,  7.6986e-02],
        [ 7.4646e-02, -1.3786e-01,  2.8420e-02],
        [ 7.7497e-02, -1.4988e-01,  1.9010e-02],
        [ 9.4121e-02, -2.3523e-01,  1.3738e-03],
        [ 8.8110e-02, -1.7884e-01,  7.0892e-03],
        [ 9.2020e-02, -2.0537e-01,  3.2549e-03],
        [ 9.1746e-02, -1.9853e-01,  2.9556e-03],
        [ 9.5846e-02, -2.3413e-01,  7.2411e-04],
        [ 9.5401e-02, -2.4210e-01,  1.1542e-03],
        [ 9.5762e-02, -2.0455e-01,  6.4361e-04],
        [ 9.7483e-02, -2.5186e-01,  1.4743e-04],
        [ 9.9082e-02, -3.1594e-01,  2.0772e-05],
        [ 9.9433e-02, -3.4712e-01,  7.3314e-06],
        [ 9.8948e-02, -3.2573e-01,  3.0279e-05],
        [ 9.9291e-02, -3.3849e-01,  1.6600e-05],
        [ 9.9463e-02, -3.4647e-01,  8.4937e-06],
        [ 9.9448e-02, -3.3681e-01,  1.0431e-05],
        [ 9.9673e-02, -3.6415e-01,  4.1723e-06],
        [ 9.9774e-02, -3.6830e-01,  2.3246e-06],
        [ 9.9794e-02, -3.7405e-01,  1.4603e-06],
        [ 9.9784e-02, -3.7795e-01,  2.4140e-06],
        [ 9.9640e-02, -3.5105e-01,  6.8247e-06],
        [ 9.9680e-02, -3.5697e-01,  5.1856e-06],
        [ 9.9459e-02, -3.4198e-01,  1.5140e-05],
        [ 9.9482e-02, -3.5032e-01,  1.2368e-05],
        [ 9.9615e-02, -3.5088e-01,  6.1989e-06],
        [ 9.9587e-02, -3.4320e-01,  1.0520e-05],
        [ 9.9601e-02, -3.5232e-01,  9.6858e-06],
        [ 9.9289e-02, -3.0218e-01,  3.2753e-05],
        [ 9.9137e-02, -3.1513e-01,  5.0485e-05],
        [ 9.9118e-02, -3.1849e-01,  5.6148e-05],
        [ 9.9141e-02, -3.3184e-01,  4.4495e-05],
        [ 9.8497e-02, -2.5970e-01,  2.6536e-04],
        [ 9.8905e-02, -3.1608e-01,  1.8069e-04],
        [ 9.6278e-02, -2.4408e-01,  1.9755e-03],
        [ 9.6639e-02, -2.7437e-01,  1.4380e-03],
        [ 9.3504e-02, -2.5616e-01,  5.2403e-03],
        [ 7.0022e-02, -1.3714e-01,  1.4905e-01],
        [ 4.7681e-02, -7.1277e-02,  4.2818e-01],
        [ 6.9895e-02, -1.4578e-01,  4.2111e-02],
        [ 8.1595e-02, -2.2055e-01,  1.5127e-02],
        [ 9.0410e-02, -2.9800e-01,  2.8044e-03],
        [ 9.1528e-02, -2.5225e-01,  3.5326e-03],
        [ 9.2709e-02, -2.4483e-01,  2.5356e-03],
        [ 8.7243e-02, -1.7408e-01,  7.2396e-03],
        [ 9.2022e-02, -1.8313e-01,  2.2788e-03],
        [ 9.1574e-02, -1.9043e-01,  2.7339e-03],
        [ 9.3919e-02, -2.5680e-01,  1.5104e-03],
        [ 9.7149e-02, -3.2446e-01,  2.7549e-04],
        [ 8.8955e-02, -1.9998e-01,  4.6625e-03],
        [ 9.7335e-02, -3.3546e-01,  3.5974e-04],
        [ 9.5922e-02, -2.3666e-01,  1.2537e-03],
        [ 9.6522e-02, -2.3836e-01,  7.5260e-04],
        [ 9.8398e-02, -3.6307e-01,  1.4412e-04],
        [ 8.6928e-02, -1.8427e-01,  6.3357e-03],
        [ 9.4465e-02, -2.0703e-01,  2.1464e-03],
        [ 8.4267e-02, -9.1026e-02,  1.8288e-02],
        [ 8.4523e-02, -1.6690e-01,  1.2364e-02],
        [ 8.9502e-02, -2.6545e-01,  5.9614e-03],
        [ 9.1606e-02, -1.6155e-01,  7.4320e-03],
        [ 9.3904e-02, -1.6604e-01,  2.2059e-03],
        [ 9.5774e-02, -2.2257e-01,  7.3102e-04],
        [ 9.3842e-02, -1.8371e-01,  1.4038e-03],
        [ 9.6804e-02, -2.9279e-01,  4.3434e-04],
        [ 9.5489e-02, -2.6236e-01,  9.6330e-04],
        [ 9.2794e-02, -1.8337e-01,  2.8047e-03],
        [ 9.4848e-02, -2.0470e-01,  2.1490e-03],
        [ 9.6601e-02, -2.3483e-01,  6.9621e-04],
        [ 9.2371e-02, -1.1406e-01,  4.6630e-03],
        [ 9.2897e-02, -2.2771e-01,  1.2829e-02],
        [ 9.7060e-02, -2.3547e-01,  1.6167e-03],
        [ 9.1278e-02, -2.5173e-01,  1.0392e-02],
        [ 9.7037e-02, -3.0908e-01,  2.0726e-03],
        [ 8.9728e-02, -1.5872e-01,  8.6808e-03],
        [ 9.2510e-02, -2.2392e-01,  4.0004e-03],
        [ 9.8657e-02, -3.3871e-01,  6.2048e-05],
        [ 9.4587e-02, -2.0781e-01,  1.4463e-03],
        [ 9.5834e-02, -2.5333e-01,  8.9070e-04],
        [ 9.1101e-02, -1.7656e-01,  7.0873e-03],
        [ 8.7807e-02, -1.9830e-01,  2.3710e-02],
        [ 9.8825e-02, -3.9195e-01,  2.5436e-04],
        [ 9.9191e-02, -3.8897e-01,  1.3399e-04],
        [ 9.7699e-02, -3.6787e-01,  1.0063e-03],
        [ 9.7479e-02, -3.5839e-01,  1.3368e-03],
        [ 9.7292e-02, -3.5165e-01,  8.8596e-04],
        [ 9.4464e-02, -3.2172e-01,  5.8223e-03],
        [ 9.6362e-02, -2.9657e-01,  1.4802e-03],
        [ 9.3101e-02, -2.4726e-01,  6.3494e-03],
        [ 9.0425e-02, -2.3961e-01,  1.6731e-02],
        [ 9.9092e-02, -3.9283e-01,  1.1966e-04],
        [ 9.9847e-02, -3.9882e-01,  1.8865e-05],
        [ 9.7987e-02, -3.6652e-01,  1.1045e-03],
        [ 9.4573e-02, -2.8339e-01,  3.8125e-03],
        [ 9.4342e-02, -1.7550e-01,  2.3420e-03],
        [ 9.2724e-02, -2.2819e-01,  2.4807e-03],
        [ 8.9535e-02, -2.2451e-01,  8.0521e-03],
        [ 8.6135e-02, -1.9240e-01,  2.9329e-02],
        [ 9.1136e-02, -2.6371e-01,  1.4139e-02],
        [ 8.5705e-02, -2.4019e-01,  2.6801e-02],
        [ 6.4176e-02, -1.7670e-01,  1.6913e-01],
        [ 7.0354e-02, -1.7162e-01,  1.0621e-01],
        [ 7.4177e-02, -1.5731e-01,  6.4901e-02],
        [ 7.6766e-02, -1.5899e-01,  5.9573e-02],
        [ 6.7690e-02, -1.2006e-01,  1.0289e-01],
        [ 6.6530e-02, -1.4058e-01,  8.7377e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 54
Episode Length = 94
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1297,  1.1315,  1.1162,  1.1273,  1.1369,  1.1378, -3.0000,  0.0000,
         0.1374,  1.1312,  1.1374,  1.1389,  1.1414,  1.1555,  1.1513,  1.1605,
         1.1449,  1.1497,  1.1511,  1.1518, -5.0000,  0.0000,  0.0000,  0.0000,
         0.1629,  1.1555,  1.1478,  1.1506,  1.1496,  1.1418,  1.1439, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1776,  1.1669,  1.1713,  1.1770,
         1.1657,  1.1626,  1.1653,  1.1689,  1.1736,  1.1682,  1.1530,  1.1600,
         1.1543, -3.0000,  0.0000,  0.1772,  1.1546,  1.1547,  1.1565,  1.0000],
       device='cuda:0')
target_q_episode tensor([ 3.0929,  2.2030,  1.2664,  0.2804, -0.7575, -1.8500, -3.0000,  0.0000,
         0.0000,  5.7800,  5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555,
        -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.8876, -0.1183, -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  7.5717,  6.9176,  6.2291,
         5.5043,  4.7413,  3.9382,  3.0929,  2.2030,  1.2664,  0.2804, -0.7575,
        -1.8500, -3.0000,  0.0000,  0.0000,  3.7099,  2.8525,  1.9500,  1.0000],
       device='cuda:0')
target_q tensor([ 1.1297,  1.1316,  1.1162,  1.1273,  1.1368,  1.1377, -3.0000,  0.0000,
         0.1374,  1.1313,  1.1375,  1.1390,  1.1415,  1.1555,  1.1513,  1.1605,
         1.1449,  1.1497,  1.1510,  1.1516, -5.0000,  0.0000,  0.0000,  0.0000,
         0.1629,  1.1555,  1.1478,  1.1506,  1.1495,  1.1417,  1.1437, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1776,  1.1670,  1.1714,  1.1771,
         1.1658,  1.1627,  1.1654,  1.1689,  1.1736,  1.1682,  1.1530,  1.1599,
         1.1542, -3.0000,  0.0000,  0.1772,  1.1546,  1.1548,  1.1565,  1.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.0699e-02, -1.4566e-01,  5.2510e-03],
        [ 9.4640e-02, -2.2017e-01,  1.8514e-03],
        [ 9.4518e-02, -1.5530e-01,  1.5738e-03],
        [ 9.5455e-02, -2.0841e-01,  1.1477e-03],
        [ 9.8413e-02, -2.7640e-01,  1.7712e-04],
        [ 9.7082e-02, -1.6814e-01,  4.3446e-04],
        [ 9.8241e-02, -2.2012e-01,  1.8284e-04],
        [ 9.8900e-02, -2.1046e-01,  8.4639e-05],
        [ 9.7809e-02, -1.6603e-01,  2.8050e-04],
        [ 9.8899e-02, -2.5637e-01,  9.2596e-05],
        [ 9.7633e-02, -1.4684e-01,  2.5871e-04],
        [ 9.6995e-02, -1.2231e-01,  6.0269e-04],
        [ 9.7406e-02, -1.3996e-01,  4.6912e-04],
        [ 9.6917e-02, -1.5032e-01,  5.1779e-04],
        [ 9.8500e-02, -2.7877e-01,  1.4198e-04],
        [ 9.9421e-02, -2.9693e-01,  2.6971e-05],
        [ 9.8796e-02, -2.5326e-01,  1.3015e-04],
        [ 9.8664e-02, -2.3970e-01,  2.0647e-04],
        [ 9.9069e-02, -2.8477e-01,  7.5549e-05],
        [ 9.8932e-02, -2.9776e-01,  1.1376e-04],
        [ 9.9579e-02, -3.6667e-01,  1.8001e-05],
        [ 9.9878e-02, -3.8864e-01,  2.2948e-06],
        [ 9.9979e-02, -3.9829e-01,  8.9407e-08],
        [ 9.9957e-02, -3.9659e-01,  2.6822e-07],
        [ 9.9972e-02, -3.9784e-01,  8.9407e-08],
        [ 9.9889e-02, -3.9010e-01,  1.1623e-06],
        [ 9.9811e-02, -3.8217e-01,  8.6129e-06],
        [ 9.9682e-02, -3.7067e-01,  1.9789e-05],
        [ 9.8279e-02, -3.2865e-01,  3.2535e-04],
        [ 9.9357e-02, -3.8992e-01,  2.8938e-05],
        [ 9.9304e-02, -3.6345e-01,  3.8594e-05],
        [ 9.7218e-02, -2.7270e-01,  5.5683e-04],
        [ 8.7625e-02, -4.1692e-02,  2.4773e-02],
        [ 8.4722e-02, -1.5010e-02,  1.7682e-02],
        [ 7.6070e-02, -2.1827e-02,  4.4468e-02],
        [ 5.3417e-02, -1.5855e-02,  2.1574e-01],
        [ 4.3611e-02, -8.8874e-02,  4.3524e-01],
        [-2.4861e-02,  3.8050e-02,  9.6347e-01],
        [ 8.8417e-02, -1.4842e-01,  6.5187e-03],
        [ 9.0009e-02, -1.3716e-01,  4.9902e-03],
        [ 9.0748e-02, -1.3198e-01,  4.7311e-03],
        [ 9.1287e-02, -2.1068e-01,  3.5009e-03],
        [ 9.7120e-02, -2.6954e-01,  5.2074e-04],
        [ 9.1895e-02, -1.9687e-01,  3.3213e-03],
        [ 9.5759e-02, -1.6904e-01,  8.4212e-04],
        [ 9.5273e-02, -2.3156e-01,  1.1213e-03],
        [ 9.5035e-02, -2.0033e-01,  1.0532e-03],
        [ 9.2795e-02, -2.0107e-01,  2.3243e-03],
        [ 9.4050e-02, -2.4431e-01,  1.3452e-03],
        [ 9.4746e-02, -2.5850e-01,  1.0695e-03],
        [ 9.3896e-02, -2.0781e-01,  1.9915e-03],
        [ 9.3181e-02, -1.7839e-01,  2.4374e-03],
        [ 9.7748e-02, -3.0324e-01,  2.8870e-04],
        [ 8.6069e-02, -6.7166e-02,  9.8222e-03],
        [ 9.5292e-02, -2.5576e-01,  1.3218e-03],
        [ 9.1828e-02, -1.6279e-01,  4.3589e-03],
        [ 9.2887e-02, -2.2862e-01,  3.2331e-03],
        [ 7.8219e-02, -3.8191e-02,  4.6192e-02],
        [ 8.8765e-02, -1.1606e-01,  9.2894e-03],
        [ 9.1191e-02, -1.3117e-01,  6.2328e-03],
        [ 9.0708e-02, -7.1372e-02,  9.9666e-03],
        [ 9.7364e-02, -3.0551e-01,  8.9353e-04],
        [ 9.7403e-02, -1.9315e-01,  6.2031e-04],
        [ 9.4700e-02, -5.8536e-02,  2.7130e-03],
        [ 9.6501e-02, -2.4377e-01,  1.3793e-03],
        [ 9.3553e-02, -1.0221e-01,  2.5188e-03],
        [ 9.8407e-02, -3.0798e-01,  2.3243e-04],
        [ 9.7397e-02, -2.5565e-01,  5.1591e-04],
        [ 9.5683e-02, -2.2749e-01,  1.8149e-03],
        [ 9.7644e-02, -3.0408e-01,  6.5407e-04],
        [ 9.7796e-02, -3.4045e-01,  8.1491e-04],
        [ 9.8647e-02, -3.5530e-01,  3.2669e-04],
        [ 9.9142e-02, -3.7486e-01,  8.0228e-05],
        [ 9.8706e-02, -3.3847e-01,  2.4569e-04],
        [ 9.4157e-02, -1.8427e-01,  6.0016e-03],
        [ 9.7029e-02, -3.1919e-01,  1.3666e-03],
        [ 9.9001e-02, -3.8620e-01,  8.8573e-05],
        [ 9.5786e-02, -3.3388e-01,  1.9798e-03],
        [ 9.9341e-02, -3.9373e-01,  3.4839e-05],
        [ 9.1776e-02, -2.2147e-01,  4.7415e-03],
        [ 9.6434e-02, -2.8649e-01,  9.7325e-04],
        [ 9.6142e-02, -3.2750e-01,  1.2757e-03],
        [ 9.7478e-02, -3.6200e-01,  3.5450e-04],
        [ 9.4282e-02, -2.7712e-01,  3.3581e-03],
        [ 9.0311e-02, -2.5675e-01,  1.3299e-02],
        [ 8.6737e-02, -1.5310e-01,  1.9798e-02],
        [ 8.1862e-02, -1.0467e-01,  5.0580e-02],
        [ 6.8994e-02, -3.1384e-02,  1.1855e-01],
        [ 6.2116e-02, -5.9866e-02,  2.2639e-01],
        [ 5.3388e-02,  2.4098e-02,  3.3209e-01],
        [ 3.1896e-02,  4.0808e-03,  4.9209e-01],
        [ 5.8952e-02, -1.1427e-01,  2.0144e-01],
        [ 5.6831e-02, -1.2281e-01,  1.9576e-01],
        [ 6.3564e-02, -1.9601e-01,  1.2513e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 55
Episode Length = 95
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1333,  1.1456,  1.1378,  1.1394,  1.1354,  1.1422,  1.1395,  1.1473,
         1.1414,  1.1431,  1.1344,  1.1408,  1.1411,  1.1407,  1.1492, -4.0000,
         0.0000,  0.0000,  0.1337,  1.1480,  1.1521,  1.1531,  1.1486,  1.1556,
         1.1546,  1.1615,  1.1619,  1.1556,  1.1517,  1.1502, -4.0000,  0.0000,
         0.0000,  0.1729,  1.1624,  1.1598,  1.1634,  1.1664,  1.1699,  1.1660,
         1.1543,  1.1536,  1.1515, -4.0000,  0.0000,  0.0000,  0.1703,  1.1531,
         1.1536,  1.1560,  1.1517,  1.1520,  1.0000], device='cuda:0')
target_q_episode tensor([ 8.8810,  8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,  4.0779,
         3.2399,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,
         0.0000,  0.0000,  0.0000,  6.3488,  5.6303,  4.8740,  4.0779,  3.2399,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000,  4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519,
        -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  5.2982,
         4.5244,  3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1335,  1.1457,  1.1379,  1.1396,  1.1356,  1.1423,  1.1396,  1.1473,
         1.1414,  1.1431,  1.1344,  1.1408,  1.1410,  1.1406,  1.1491, -4.0000,
         0.0000,  0.0000,  0.1337,  1.1481,  1.1522,  1.1532,  1.1487,  1.1556,
         1.1546,  1.1615,  1.1619,  1.1555,  1.1516,  1.1501, -4.0000,  0.0000,
         0.0000,  0.1729,  1.1625,  1.1598,  1.1634,  1.1664,  1.1699,  1.1660,
         1.1542,  1.1535,  1.1514, -4.0000,  0.0000,  0.0000,  0.1703,  1.1532,
         1.1537,  1.1561,  1.1517,  1.1521,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 5.3186e-02, -6.1362e-02,  1.0358e-01],
        [ 8.2939e-02, -1.8604e-01,  1.2896e-02],
        [ 8.6667e-02, -1.7347e-01,  9.9694e-03],
        [ 7.8743e-02, -7.4117e-02,  2.7766e-02],
        [ 7.4417e-02, -3.3971e-02,  3.4721e-02],
        [ 8.7567e-02, -1.2834e-01,  7.9855e-03],
        [ 8.5572e-02, -1.1338e-01,  1.0387e-02],
        [ 8.6778e-02, -1.1401e-01,  7.9820e-03],
        [ 8.1256e-02, -4.0230e-02,  1.6205e-02],
        [ 8.0818e-02, -4.9148e-02,  1.2885e-02],
        [ 8.8805e-02, -9.8261e-02,  4.0664e-03],
        [ 9.4296e-02, -1.9357e-01,  9.3883e-04],
        [ 9.0485e-02, -1.8305e-01,  2.5512e-03],
        [ 9.2036e-02, -1.7247e-01,  2.0858e-03],
        [ 9.4630e-02, -1.8067e-01,  7.1624e-04],
        [ 9.5601e-02, -2.0115e-01,  5.5912e-04],
        [ 9.6045e-02, -1.9510e-01,  4.9213e-04],
        [ 9.6970e-02, -2.1438e-01,  3.2273e-04],
        [ 9.7209e-02, -2.1943e-01,  3.4833e-04],
        [ 9.8771e-02, -2.9162e-01,  5.4449e-05],
        [ 9.8373e-02, -2.7068e-01,  7.6473e-05],
        [ 9.9126e-02, -2.9195e-01,  2.5123e-05],
        [ 9.5955e-02, -1.8817e-01,  8.9613e-04],
        [ 9.7848e-02, -2.9365e-01,  3.6553e-04],
        [ 9.7190e-02, -3.0040e-01,  5.0119e-04],
        [ 9.7068e-02, -2.7046e-01,  6.8858e-04],
        [ 9.8570e-02, -3.7501e-01,  6.4701e-05],
        [ 9.7876e-02, -3.1092e-01,  4.0498e-04],
        [ 9.7057e-02, -3.0068e-01,  9.6649e-04],
        [ 9.6654e-02, -3.0853e-01,  7.6970e-04],
        [ 9.7867e-02, -2.1723e-01,  3.4684e-04],
        [ 8.9325e-02, -6.2178e-02,  5.7336e-03],
        [ 9.4315e-02, -1.3604e-01,  2.7210e-03],
        [ 9.9933e-02, -3.9889e-01,  6.8545e-07],
        [ 9.9042e-02, -3.8458e-01,  7.6175e-05],
        [ 9.9948e-02, -3.9744e-01,  4.1723e-07],
        [ 9.9605e-02, -3.7300e-01,  2.6286e-05],
        [ 9.9032e-02, -3.1995e-01,  1.2267e-04],
        [ 9.6086e-02, -1.1951e-01,  1.2546e-03],
        [ 9.2701e-02, -4.6470e-02,  7.3385e-03],
        [ 7.3306e-02, -5.7731e-02,  5.9311e-02],
        [-1.5687e-02,  1.2272e-01,  9.2011e-01],
        [ 8.6342e-02, -1.6373e-01,  7.0344e-03],
        [ 7.5154e-02, -9.6458e-02,  2.3488e-02],
        [ 7.4439e-02, -1.2046e-01,  2.4909e-02],
        [ 9.3808e-02, -2.6625e-01,  1.8826e-03],
        [ 9.7311e-02, -3.4661e-01,  2.5177e-04],
        [ 9.5529e-02, -2.8385e-01,  7.0485e-04],
        [ 9.2667e-02, -1.6898e-01,  2.4572e-03],
        [ 8.6478e-02, -8.2384e-02,  7.2192e-03],
        [ 9.5531e-02, -2.4499e-01,  7.5728e-04],
        [ 8.7575e-02, -1.0041e-01,  6.1269e-03],
        [ 9.6489e-02, -2.7768e-01,  3.5596e-04],
        [ 8.8261e-02, -9.1204e-02,  6.5531e-03],
        [ 9.5806e-02, -2.6620e-01,  7.1710e-04],
        [ 9.0185e-02, -2.0158e-01,  3.2884e-03],
        [ 9.4431e-02, -2.5575e-01,  9.0411e-04],
        [ 9.1578e-02, -2.1162e-01,  2.8454e-03],
        [ 9.1926e-02, -1.8778e-01,  2.9011e-03],
        [ 8.8398e-02, -1.2586e-01,  6.3868e-03],
        [ 8.3779e-02, -4.6961e-02,  1.3663e-02],
        [ 6.9680e-02,  4.0673e-02,  5.9579e-02],
        [ 8.0034e-02, -3.9295e-03,  3.7938e-02],
        [ 7.1840e-02,  2.1574e-02,  5.9434e-02],
        [ 7.9867e-02, -5.8696e-02,  2.5797e-02],
        [ 7.8757e-02, -7.8882e-02,  2.8909e-02],
        [ 8.8465e-02, -1.4769e-01,  1.1845e-02],
        [ 8.1933e-02, -7.3279e-02,  2.5123e-02],
        [ 8.8310e-02, -1.5465e-01,  1.1479e-02],
        [ 9.0140e-02, -1.8420e-01,  6.8446e-03],
        [ 9.1170e-02, -2.1960e-01,  7.3824e-03],
        [ 9.6231e-02, -2.6197e-01,  1.4249e-03],
        [ 8.5385e-02, -1.4848e-01,  2.6952e-02],
        [ 9.0614e-02, -2.7309e-01,  8.5978e-03],
        [ 9.3697e-02, -3.1568e-01,  3.7512e-03],
        [ 9.5107e-02, -2.9020e-01,  1.9508e-03],
        [ 9.2270e-02, -3.2345e-01,  2.2114e-03],
        [ 9.4091e-02, -3.1164e-01,  3.1144e-03],
        [ 9.7089e-02, -3.3400e-01,  1.5601e-03],
        [ 9.6857e-02, -3.5339e-01,  1.5103e-03],
        [ 9.9414e-02, -3.8587e-01,  8.6755e-05],
        [ 9.6069e-02, -3.0465e-01,  1.6703e-03],
        [ 9.7821e-02, -3.5217e-01,  3.3504e-04],
        [ 9.9684e-02, -3.8250e-01,  1.1057e-05],
        [ 9.9260e-02, -3.7662e-01,  3.4451e-05],
        [ 9.4658e-02, -2.4979e-01,  1.5706e-03],
        [ 9.8494e-02, -3.7851e-01,  3.7712e-04],
        [ 9.8119e-02, -3.5184e-01,  3.6955e-04],
        [ 9.9470e-02, -3.9125e-01,  2.7627e-05],
        [ 9.2764e-02, -1.1438e-01,  9.8356e-03],
        [ 7.5282e-02,  3.2384e-02,  6.4099e-02],
        [ 6.2652e-02,  5.8046e-02,  1.5347e-01],
        [ 5.5560e-02, -2.1129e-02,  2.1254e-01],
        [ 1.4388e-02,  3.6968e-02,  6.4682e-01],
        [ 4.0768e-02, -4.0720e-02,  3.7947e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 56
Episode Length = 96
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1444,  1.1419,  1.1325,  1.1363,  1.1334,  1.1425,  1.1412,  1.1374,
         1.1454,  1.1465,  1.1343,  1.1339,  1.1427,  1.1272,  1.1499,  1.1532,
         1.1435,  1.1337,  1.1477,  1.1508,  1.1538,  1.1595, -6.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1616,  1.1617,  1.1577,  1.1501,  1.1520,
         1.1548,  1.1679,  1.1650,  1.1691,  1.1756,  1.1693,  1.1588,  1.1555,
         1.1567, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1860,  1.1800,
         1.1698,  1.1747,  1.1776,  1.1722,  1.1758, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([11.5881, 11.1454, 10.6794, 10.1888,  9.6724,  9.1289,  8.5567,  7.9544,
         7.3204,  6.6531,  5.9506,  5.2112,  4.4328,  3.6135,  2.7511,  1.8432,
         0.8876, -0.1183, -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  6.6531,  5.9506,  5.2112,  4.4328,
         3.6135,  2.7511,  1.8432,  0.8876, -0.1183, -1.1772, -2.2917, -3.4650,
        -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.6227,
         0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1446,  1.1421,  1.1326,  1.1365,  1.1336,  1.1426,  1.1414,  1.1375,
         1.1455,  1.1466,  1.1344,  1.1340,  1.1427,  1.1272,  1.1500,  1.1532,
         1.1435,  1.1337,  1.1476,  1.1508,  1.1537,  1.1594, -6.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.1616,  1.1618,  1.1578,  1.1502,  1.1520,
         1.1548,  1.1680,  1.1650,  1.1691,  1.1756,  1.1692,  1.1587,  1.1554,
         1.1566, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1860,  1.1800,
         1.1697,  1.1747,  1.1775,  1.1721,  1.1757, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.4995e-02, -8.5678e-02,  1.0936e-02],
        [ 8.5742e-02, -1.1438e-01,  9.7844e-03],
        [ 8.9932e-02, -8.0571e-02,  6.9676e-03],
        [ 9.0488e-02, -1.2061e-01,  6.1919e-03],
        [ 9.5925e-02, -1.7786e-01,  9.4345e-04],
        [ 9.4495e-02, -1.1324e-01,  1.5412e-03],
        [ 9.2782e-02, -1.0010e-01,  3.2842e-03],
        [ 9.5520e-02, -1.2070e-01,  9.2143e-04],
        [ 9.4941e-02, -2.9146e-02,  1.4625e-03],
        [ 9.7274e-02, -1.5254e-01,  4.5204e-04],
        [ 9.3663e-02, -5.7617e-02,  1.7299e-03],
        [ 9.5203e-02, -4.7851e-02,  1.1142e-03],
        [ 9.5199e-02, -1.0146e-01,  1.1069e-03],
        [ 9.5583e-02, -4.9726e-02,  1.2238e-03],
        [ 9.4493e-02, -1.5061e-01,  1.5157e-03],
        [ 9.6233e-02, -1.3116e-01,  1.0760e-03],
        [ 9.5057e-02, -1.4604e-01,  1.3821e-03],
        [ 9.5814e-02, -1.2092e-01,  1.4832e-03],
        [ 9.7232e-02, -2.1582e-01,  5.8544e-04],
        [ 9.8192e-02, -2.6553e-01,  2.5347e-04],
        [ 9.8401e-02, -2.8695e-01,  1.8060e-04],
        [ 9.8914e-02, -3.0858e-01,  9.5695e-05],
        [ 9.9926e-02, -3.9266e-01,  5.6624e-07],
        [ 9.9877e-02, -3.9024e-01,  1.1921e-06],
        [ 9.9950e-02, -3.9644e-01,  2.0862e-07],
        [ 9.9750e-02, -3.7726e-01,  4.6194e-06],
        [ 9.9649e-02, -3.5842e-01,  1.2338e-05],
        [ 9.9169e-02, -3.2231e-01,  5.8234e-05],
        [ 9.7955e-02, -2.8078e-01,  3.3116e-04],
        [ 9.9329e-02, -3.8880e-01,  2.8849e-05],
        [ 9.7987e-02, -2.7356e-01,  3.0416e-04],
        [ 9.6054e-02, -2.1280e-01,  1.0157e-03],
        [ 8.9149e-02, -2.8083e-02,  1.4517e-02],
        [ 7.9552e-02,  7.9013e-02,  2.2945e-02],
        [ 7.6626e-02,  2.5649e-02,  3.5309e-02],
        [ 6.3895e-02,  6.9516e-03,  8.5389e-02],
        [ 3.9181e-02, -9.1516e-03,  3.8171e-01],
        [-3.6775e-03,  4.3614e-02,  8.5366e-01],
        [ 8.4516e-02, -9.9492e-02,  1.1330e-02],
        [ 8.6974e-02, -1.5089e-01,  7.4198e-03],
        [ 7.1860e-02, -2.0726e-02,  4.1569e-02],
        [ 8.3861e-02, -7.3269e-02,  1.3134e-02],
        [ 9.2459e-02, -1.6135e-01,  2.7663e-03],
        [ 9.6263e-02, -2.2666e-01,  9.1693e-04],
        [ 9.6958e-02, -2.3429e-01,  6.0877e-04],
        [ 8.5821e-02, -5.6149e-02,  9.1527e-03],
        [ 9.1707e-02, -4.9342e-02,  3.6073e-03],
        [ 9.6180e-02, -1.7565e-01,  7.7906e-04],
        [ 9.0078e-02, -4.0972e-02,  4.9007e-03],
        [ 9.3545e-02, -1.1277e-01,  1.9061e-03],
        [ 9.6447e-02, -2.5637e-01,  8.5044e-04],
        [ 9.5837e-02, -2.4461e-01,  8.2606e-04],
        [ 9.4875e-02, -1.7143e-01,  1.2676e-03],
        [ 9.4501e-02, -1.5956e-01,  1.3282e-03],
        [ 9.5801e-02, -1.8367e-01,  1.2593e-03],
        [ 9.0844e-02, -6.2034e-02,  4.7381e-03],
        [ 9.6849e-02, -1.9424e-01,  5.3278e-04],
        [ 8.4505e-02,  5.7190e-02,  1.3463e-02],
        [ 7.9239e-02,  1.0010e-01,  3.5410e-02],
        [ 9.1289e-02, -8.7761e-02,  7.9114e-03],
        [ 9.4194e-02, -2.3921e-01,  3.3038e-03],
        [ 9.2264e-02, -1.6806e-01,  4.5762e-03],
        [ 9.4924e-02, -1.6651e-01,  2.5330e-03],
        [ 8.7841e-02, -9.9632e-03,  1.4952e-02],
        [ 9.2348e-02, -1.0459e-01,  4.1423e-03],
        [ 9.7946e-02, -3.3302e-01,  3.1632e-04],
        [ 8.9875e-02,  2.5997e-02,  8.5717e-03],
        [ 9.4767e-02, -1.2394e-01,  2.9174e-03],
        [ 9.0537e-02, -9.1735e-02,  6.5355e-03],
        [ 9.3433e-02, -1.1925e-01,  2.1766e-03],
        [ 9.1321e-02, -2.1604e-01,  8.8456e-03],
        [ 9.2943e-02, -2.7936e-01,  5.0635e-03],
        [ 8.7322e-02, -1.3242e-01,  1.4773e-02],
        [ 9.7383e-02, -3.0872e-01,  4.8617e-04],
        [ 9.8405e-02, -3.5737e-01,  1.4174e-04],
        [ 9.3859e-02, -2.8150e-01,  1.6578e-03],
        [ 9.5666e-02, -3.1457e-01,  2.5931e-03],
        [ 9.5981e-02, -2.8770e-01,  1.5883e-03],
        [ 8.9236e-02, -1.2475e-01,  7.8587e-03],
        [ 9.5291e-02, -2.6939e-01,  2.3045e-03],
        [ 9.5934e-02, -2.5784e-01,  1.5643e-03],
        [ 9.6727e-02, -3.2304e-01,  1.6027e-03],
        [ 9.7527e-02, -2.9134e-01,  1.3345e-03],
        [ 9.1826e-02, -1.7573e-01,  9.4570e-03],
        [ 9.6971e-02, -3.5100e-01,  1.5589e-03],
        [ 9.8272e-02, -3.6395e-01,  5.2202e-04],
        [ 9.7769e-02, -3.7105e-01,  2.9972e-04],
        [ 8.7529e-02, -1.5962e-01,  1.2771e-02],
        [ 9.6643e-02, -3.5126e-01,  6.1119e-04],
        [ 9.5336e-02, -3.1664e-01,  1.3879e-03],
        [ 9.6282e-02, -3.5372e-01,  6.6784e-04],
        [ 9.8478e-02, -3.8114e-01,  1.2475e-04],
        [ 9.7213e-02, -3.3248e-01,  6.3643e-04],
        [ 8.3961e-02, -1.2196e-01,  2.8971e-02],
        [ 6.7343e-02,  8.7699e-02,  1.1537e-01],
        [ 6.0589e-02,  9.8537e-02,  1.3818e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 57
Episode Length = 105
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1309,  1.1447,  1.1544,  1.1460,  1.1409,  1.1380,  1.1297,  1.1483,
         1.1404,  1.1542,  1.1577,  1.1530,  1.1483,  1.1508,  1.1370,  1.1519,
         1.1491,  1.1606,  1.1664,  1.1687,  1.1528,  1.1515,  1.1505,  1.1524,
         1.1501,  1.1506,  1.1589,  1.1505,  1.1411,  1.1463,  1.1498,  1.1570,
         1.1580,  1.1588, -4.0000,  0.0000,  0.0000,  0.1582,  1.1639,  1.1651,
         1.1646, -5.0000,  0.0000,  0.0000,  0.0000,  0.1566,  1.1741,  1.1734,
        -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1748,  1.1759,  1.1689,
         1.1725,  1.1660,  1.1691,  1.1738,  1.1751,  1.1738,  1.0000],
       device='cuda:0')
target_q_episode tensor([15.8042, 15.5834, 15.3509, 15.1062, 14.8487, 14.5775, 14.2922, 13.9917,
        13.6755, 13.3426, 12.9923, 12.6234, 12.2352, 11.8265, 11.3963, 10.9435,
        10.4669,  9.9651,  9.4370,  8.8810,  8.2958,  7.6798,  7.0314,  6.3488,
         5.6303,  4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770,
        -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000, -1.4344, -2.5625,
        -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -3.4650, -4.7000,
        -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  7.3950,  6.7316,
         6.0333,  5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000],
       device='cuda:0')
target_q tensor([ 1.1311,  1.1449,  1.1546,  1.1462,  1.1411,  1.1382,  1.1299,  1.1484,
         1.1406,  1.1544,  1.1578,  1.1531,  1.1485,  1.1509,  1.1372,  1.1520,
         1.1492,  1.1607,  1.1665,  1.1688,  1.1529,  1.1516,  1.1506,  1.1525,
         1.1502,  1.1506,  1.1589,  1.1506,  1.1411,  1.1463,  1.1498,  1.1569,
         1.1580,  1.1588, -4.0000,  0.0000,  0.0000,  0.1582,  1.1639,  1.1650,
         1.1646, -5.0000,  0.0000,  0.0000,  0.0000,  0.1566,  1.1741,  1.1733,
        -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1748,  1.1760,  1.1690,
         1.1725,  1.1661,  1.1691,  1.1738,  1.1751,  1.1739,  1.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 5.8940e-02, -3.9619e-02,  7.3968e-02],
        [ 7.0657e-02, -6.7777e-02,  4.4541e-02],
        [ 4.3789e-02, -1.3675e-02,  1.7475e-01],
        [ 4.4236e-02, -2.0600e-02,  1.8491e-01],
        [ 5.3253e-02, -2.6015e-02,  8.9390e-02],
        [ 6.6721e-02, -5.4962e-02,  4.4773e-02],
        [ 8.6175e-02, -1.1890e-01,  6.3643e-03],
        [ 6.1003e-02, -5.3966e-03,  7.8348e-02],
        [ 8.3241e-02, -1.5185e-01,  1.2985e-02],
        [ 8.2291e-02, -8.0089e-02,  1.5778e-02],
        [ 8.4884e-02, -2.3012e-02,  1.0334e-02],
        [ 7.5777e-02, -5.6877e-02,  2.8844e-02],
        [ 9.1364e-02, -1.2213e-01,  2.2320e-03],
        [ 9.3043e-02, -1.3225e-01,  1.2259e-03],
        [ 9.4264e-02, -1.4734e-01,  9.1755e-04],
        [ 9.4953e-02, -1.5984e-01,  7.5054e-04],
        [ 9.7790e-02, -2.1730e-01,  1.2207e-04],
        [ 9.8760e-02, -2.5312e-01,  4.3750e-05],
        [ 9.8533e-02, -2.3313e-01,  6.1691e-05],
        [ 9.8713e-02, -2.6126e-01,  4.2260e-05],
        [ 9.9441e-02, -3.1416e-01,  9.6560e-06],
        [ 9.9213e-02, -2.6681e-01,  1.9550e-05],
        [ 9.8554e-02, -2.2447e-01,  6.8635e-05],
        [ 9.8173e-02, -1.9818e-01,  9.2298e-05],
        [ 9.8723e-02, -2.5620e-01,  4.6819e-05],
        [ 9.8870e-02, -2.4773e-01,  3.3498e-05],
        [ 9.9108e-02, -2.5887e-01,  2.5034e-05],
        [ 9.7499e-02, -1.3863e-01,  2.2900e-04],
        [ 9.8707e-02, -2.4246e-01,  8.4400e-05],
        [ 9.7383e-02, -1.4252e-01,  2.7835e-04],
        [ 9.7990e-02, -1.5346e-01,  1.4994e-04],
        [ 9.7254e-02, -1.4167e-01,  3.0521e-04],
        [ 9.7710e-02, -1.5060e-01,  2.2200e-04],
        [ 9.7824e-02, -1.6941e-01,  2.8566e-04],
        [ 9.7995e-02, -1.6367e-01,  2.8086e-04],
        [ 9.5743e-02, -8.2148e-02,  1.4458e-03],
        [ 9.2738e-02, -9.0793e-02,  5.5051e-03],
        [ 9.3795e-02, -9.0051e-02,  4.4221e-03],
        [ 8.9380e-02, -7.9665e-02,  1.1416e-02],
        [ 8.1804e-02, -7.4290e-02,  3.0123e-02],
        [ 6.5150e-02, -2.6884e-02,  1.6376e-01],
        [ 4.4934e-02, -6.1646e-03,  3.6241e-01],
        [ 6.7480e-02, -4.9318e-02,  6.2843e-02],
        [ 7.0476e-02, -3.3490e-02,  4.2379e-02],
        [ 7.0233e-02, -8.1929e-02,  5.0339e-02],
        [ 7.2038e-02, -7.4654e-02,  2.8198e-02],
        [ 5.7674e-02, -2.3888e-02,  7.8617e-02],
        [ 5.7320e-02, -5.0242e-02,  6.7649e-02],
        [ 6.6025e-02, -5.4911e-03,  4.4542e-02],
        [ 7.4728e-02, -8.1812e-02,  4.4093e-02],
        [ 7.9782e-02, -7.3420e-02,  2.7136e-02],
        [ 7.0102e-02, -2.7327e-02,  5.5847e-02],
        [ 6.6001e-02, -2.5675e-02,  7.1757e-02],
        [ 6.6420e-02, -2.4262e-02,  3.8567e-02],
        [ 8.3703e-02, -8.1455e-02,  9.3243e-03],
        [ 6.9065e-02, -2.3111e-02,  3.2983e-02],
        [ 8.2113e-02, -6.3031e-02,  1.3304e-02],
        [ 7.7808e-02, -4.2123e-02,  2.1062e-02],
        [ 6.9271e-02,  5.7211e-03,  6.4950e-02],
        [ 6.3040e-02, -4.3150e-03,  8.1184e-02],
        [ 6.9955e-02, -3.2009e-02,  7.7794e-02],
        [ 7.8348e-02, -5.8270e-02,  2.8217e-02],
        [ 8.9619e-02, -1.1048e-01,  3.6793e-03],
        [ 7.5581e-02, -5.7160e-02,  2.5592e-02],
        [ 7.9423e-02, -6.8045e-02,  1.6562e-02],
        [ 7.5144e-02, -6.1596e-02,  2.6419e-02],
        [ 7.4551e-02, -3.7117e-02,  3.3077e-02],
        [ 7.9615e-02, -4.1372e-02,  1.8902e-02],
        [ 8.3865e-02, -8.8067e-02,  1.0761e-02],
        [ 8.5308e-02, -7.2667e-02,  1.2051e-02],
        [ 9.4009e-02, -2.3494e-01,  2.0016e-03],
        [ 8.9969e-02, -1.1002e-01,  5.3736e-03],
        [ 8.3916e-02, -3.8066e-03,  9.4455e-03],
        [ 9.6434e-02, -2.3943e-01,  4.5252e-04],
        [ 9.6139e-02, -2.2122e-01,  4.6664e-04],
        [ 9.8096e-02, -2.7490e-01,  1.1036e-04],
        [ 9.5104e-02, -1.9556e-01,  8.4388e-04],
        [ 9.8168e-02, -2.7782e-01,  7.9423e-05],
        [ 8.3382e-02,  8.0475e-02,  2.0937e-02],
        [ 8.5168e-02, -3.6647e-02,  2.0837e-02],
        [ 9.2681e-02, -2.9823e-01,  5.5195e-03],
        [ 9.1975e-02, -2.0355e-01,  5.8520e-03],
        [ 8.8740e-02, -1.9931e-01,  1.8956e-02],
        [ 8.3632e-02, -7.1677e-02,  2.4021e-02],
        [ 8.5739e-02, -1.1479e-01,  1.4234e-02],
        [ 8.2010e-02,  2.3340e-02,  2.3063e-02],
        [ 8.2752e-02, -1.2165e-01,  3.7647e-02],
        [ 9.7807e-02, -3.7432e-01,  4.8894e-04],
        [ 9.8397e-02, -3.8794e-01,  1.9532e-04],
        [ 9.2834e-02, -3.3169e-01,  2.4777e-03],
        [ 8.1898e-02, -1.4565e-01,  1.9103e-02],
        [ 8.3546e-02, -1.7552e-01,  1.1618e-02],
        [ 8.6537e-02, -2.1117e-01,  9.6635e-03],
        [ 9.8207e-02, -3.6655e-01,  7.4589e-04],
        [ 9.9863e-02, -3.9844e-01,  4.5896e-06],
        [ 9.9422e-02, -3.6083e-01,  1.0410e-04],
        [ 8.9105e-02, -2.8402e-02,  1.0669e-02],
        [ 9.1625e-02, -5.5344e-02,  3.5989e-03],
        [ 7.6996e-02,  8.2016e-02,  3.0880e-02],
        [ 8.1650e-02, -4.0523e-02,  2.5388e-02],
        [ 7.8366e-02, -2.2456e-01,  3.6360e-02],
        [ 7.9019e-02, -1.3356e-01,  3.5998e-02],
        [ 7.0052e-02, -8.0303e-02,  9.5738e-02],
        [ 7.8222e-02, -1.0296e-01,  8.8070e-02],
        [ 8.7694e-02, -2.3818e-01,  9.3014e-03]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 58
Episode Length = 80
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1332,  1.1251,  1.1241, -4.0000,  0.0000,  0.0000,  0.1626,  1.1415,
         1.1457,  1.1246, -4.0000,  0.0000,  0.0000,  0.1682,  1.1501,  1.1572,
         1.1570,  1.1631,  1.1525,  1.1581,  1.1633,  1.1584,  1.1544,  1.1482,
         1.1664, -2.0000,  0.1797,  1.1701,  1.1744,  1.1712,  1.1730,  1.1776,
         1.1806,  1.1794,  1.1767,  1.1710,  1.1651,  1.1677,  1.1639,  1.1695,
         1.1658,  1.0000], device='cuda:0')
target_q_episode tensor([-0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000, -0.5770,
        -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  7.4864,  6.8278,
         6.1345,  5.4048,  4.6366,  3.8280,  2.9768,  2.0809,  1.1377,  0.1450,
        -0.9000, -2.0000,  0.0000, 10.7342, 10.2465,  9.7332,  9.1928,  8.6240,
         8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,  3.7099,  2.8525,
         1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1332,  1.1251,  1.1240, -4.0000,  0.0000,  0.0000,  0.1626,  1.1415,
         1.1457,  1.1246, -4.0000,  0.0000,  0.0000,  0.1682,  1.1502,  1.1573,
         1.1571,  1.1632,  1.1525,  1.1581,  1.1633,  1.1584,  1.1544,  1.1482,
         1.1664, -2.0000,  0.1797,  1.1702,  1.1745,  1.1713,  1.1731,  1.1776,
         1.1807,  1.1794,  1.1768,  1.1710,  1.1652,  1.1678,  1.1639,  1.1695,
         1.1659,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.6060e-02, -6.9658e-02,  1.0210e-02],
        [ 8.7818e-02, -8.3551e-02,  8.4634e-03],
        [ 8.6338e-02, -6.8797e-02,  9.4123e-03],
        [ 9.4838e-02, -1.1014e-01,  1.6578e-03],
        [ 9.6413e-02, -1.0689e-01,  9.0182e-04],
        [ 9.6225e-02, -8.2616e-02,  8.4955e-04],
        [ 9.7265e-02, -1.2923e-01,  3.2488e-04],
        [ 9.4223e-02, -4.1943e-02,  1.5307e-03],
        [ 9.0713e-02,  2.0861e-02,  3.7772e-03],
        [ 9.0480e-02,  5.6698e-03,  4.7444e-03],
        [ 9.4198e-02,  3.8001e-03,  1.6002e-03],
        [ 9.4600e-02, -4.8059e-03,  1.5081e-03],
        [ 9.0651e-02,  1.0500e-02,  4.5142e-03],
        [ 9.2547e-02, -2.5223e-02,  2.6186e-03],
        [ 9.5513e-02, -8.3171e-02,  1.1232e-03],
        [ 9.2894e-02, -7.3102e-02,  2.9997e-03],
        [ 9.4335e-02, -6.9267e-02,  2.1451e-03],
        [ 9.6605e-02, -1.2616e-01,  8.5500e-04],
        [ 9.7490e-02, -1.7464e-01,  5.0235e-04],
        [ 9.7583e-02, -1.8406e-01,  5.7304e-04],
        [ 9.8564e-02, -2.6461e-01,  2.3419e-04],
        [ 9.8915e-02, -2.9091e-01,  9.8526e-05],
        [ 9.9523e-02, -3.5573e-01,  1.6093e-05],
        [ 9.9884e-02, -3.8845e-01,  1.0431e-06],
        [ 9.9895e-02, -3.9042e-01,  7.7486e-07],
        [ 9.9820e-02, -3.8168e-01,  1.9968e-06],
        [ 9.9769e-02, -3.6076e-01,  9.6262e-06],
        [ 9.9398e-02, -3.3634e-01,  3.7700e-05],
        [ 9.7307e-02, -2.0716e-01,  5.0986e-04],
        [ 9.9220e-02, -3.8266e-01,  4.0710e-05],
        [ 9.8042e-02, -2.5528e-01,  2.0885e-04],
        [ 9.0500e-02, -9.5104e-03,  4.2149e-03],
        [ 8.9092e-02,  2.2145e-02,  1.6826e-02],
        [ 8.2521e-02,  1.2148e-01,  1.9598e-02],
        [ 8.0155e-02,  3.0810e-02,  2.3703e-02],
        [ 7.1845e-02, -1.8689e-02,  6.3336e-02],
        [ 5.5066e-02,  9.6485e-04,  2.0312e-01],
        [ 8.9708e-03,  4.0122e-02,  7.9305e-01],
        [ 8.8482e-02, -1.0646e-01,  7.4925e-03],
        [ 8.4885e-02, -4.9462e-02,  1.1212e-02],
        [ 9.4817e-02, -1.7828e-01,  1.8999e-03],
        [ 9.1783e-02, -1.3107e-01,  3.6362e-03],
        [ 8.3692e-02, -2.2853e-02,  1.2828e-02],
        [ 8.4302e-02, -4.3055e-02,  1.6358e-02],
        [ 9.2637e-02, -1.6552e-01,  3.0881e-03],
        [ 9.0791e-02, -1.7312e-02,  4.2737e-03],
        [ 8.1294e-02,  8.6372e-02,  1.5464e-02],
        [ 8.6720e-02, -1.9777e-02,  9.6691e-03],
        [ 8.3805e-02,  9.2960e-02,  1.2064e-02],
        [ 9.3655e-02, -1.5124e-01,  2.3986e-03],
        [ 9.2753e-02, -2.0103e-01,  3.8233e-03],
        [ 8.8689e-02,  7.2967e-03,  7.2157e-03],
        [ 7.6773e-02,  7.3422e-02,  3.7237e-02],
        [ 8.0480e-02, -9.3326e-03,  1.7445e-02],
        [ 9.2479e-02, -8.6582e-02,  3.7713e-03],
        [ 8.4155e-02, -5.3672e-02,  1.3715e-02],
        [ 9.4936e-02, -1.9789e-01,  2.6057e-03],
        [ 8.5435e-02, -3.3652e-02,  1.6239e-02],
        [ 9.1454e-02, -3.2002e-02,  4.8034e-03],
        [ 8.6570e-02, -4.6700e-02,  1.3979e-02],
        [ 8.3083e-02, -7.7246e-04,  2.2355e-02],
        [ 9.6068e-02, -1.9803e-01,  1.1643e-03],
        [ 9.4901e-02, -1.2661e-01,  2.3837e-03],
        [ 9.4859e-02, -1.3753e-01,  2.6148e-03],
        [ 9.6027e-02, -1.9608e-01,  1.9184e-03],
        [ 9.2636e-02, -1.0838e-01,  5.1538e-03],
        [ 9.6291e-02, -2.5632e-01,  1.5233e-03],
        [ 9.2022e-02, -1.4666e-01,  3.6374e-03],
        [ 9.8287e-02, -3.3413e-01,  1.3301e-04],
        [ 9.7844e-02, -3.5092e-01,  1.8653e-04],
        [ 9.1841e-02, -1.7067e-01,  3.8748e-03],
        [ 8.9779e-02, -1.4548e-01,  5.8181e-03],
        [ 9.4169e-02, -2.0997e-01,  2.7891e-03],
        [ 8.6213e-02, -1.1583e-01,  9.4475e-03],
        [ 7.8402e-02, -4.2968e-02,  2.7265e-02],
        [ 7.6115e-02, -5.2854e-02,  2.3492e-02],
        [ 6.2001e-02,  1.4341e-02,  1.0403e-01],
        [ 7.7083e-02, -1.3266e-01,  5.1269e-02],
        [ 7.0410e-02, -7.0122e-02,  6.8001e-02],
        [ 6.7531e-02,  4.1947e-02,  9.7226e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 59
Episode Length = 99
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1361,  1.1391,  1.1294,  1.1418,  1.1574,  1.1535,  1.1385,  1.1370,
         1.1467,  1.1585,  1.1467,  1.1412,  1.1362,  1.1425,  1.1407, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1699,  1.1473,  1.1582,  1.1558,
         1.1645,  1.1575,  1.1640,  1.1610,  1.1673,  1.1664,  1.1590,  1.1642,
         1.1762,  1.1762,  1.1669, -4.0000,  0.0000,  0.0000,  0.1650,  1.1743,
         1.1763,  1.1695, -4.0000,  0.0000,  0.0000,  0.1532,  1.1663,  1.1743,
         1.1746,  1.1683,  1.1658,  1.1735, -3.0000,  0.0000,  0.1463,  1.1654,
         1.0000], device='cuda:0')
target_q_episode tensor([ 7.9544,  7.3204,  6.6531,  5.9506,  5.2112,  4.4328,  3.6135,  2.7511,
         1.8432,  0.8876, -0.1183, -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.2958,  7.6798,  7.0314,
         6.3488,  5.6303,  4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519,
        -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000, -0.5770,
        -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  3.0929,  2.2030,
         1.2664,  0.2804, -0.7575, -1.8500, -3.0000,  0.0000,  0.0000,  1.9500,
         1.0000], device='cuda:0')
target_q tensor([ 1.1361,  1.1392,  1.1295,  1.1419,  1.1574,  1.1535,  1.1385,  1.1371,
         1.1467,  1.1585,  1.1466,  1.1411,  1.1362,  1.1424,  1.1406, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1699,  1.1473,  1.1582,  1.1558,
         1.1645,  1.1575,  1.1640,  1.1610,  1.1673,  1.1664,  1.1590,  1.1642,
         1.1762,  1.1761,  1.1669, -4.0000,  0.0000,  0.0000,  0.1650,  1.1742,
         1.1762,  1.1694, -4.0000,  0.0000,  0.0000,  0.1532,  1.1663,  1.1743,
         1.1746,  1.1683,  1.1658,  1.1735, -3.0000,  0.0000,  0.1463,  1.1654,
         1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.1230e-02, -8.7900e-02,  4.2606e-02],
        [ 7.0798e-02, -6.4118e-02,  3.7445e-02],
        [ 6.9381e-02, -5.0591e-02,  4.6577e-02],
        [ 7.1548e-02, -3.7104e-02,  5.2202e-02],
        [ 7.1855e-02,  3.1053e-03,  4.1153e-02],
        [ 8.0670e-02, -3.5903e-02,  1.8205e-02],
        [ 7.7097e-02, -2.0666e-02,  2.7566e-02],
        [ 8.1682e-02, -5.6748e-02,  1.9104e-02],
        [ 8.7620e-02, -4.7440e-02,  6.3849e-03],
        [ 8.2326e-02, -4.8016e-02,  9.0432e-03],
        [ 8.8522e-02, -7.6956e-02,  4.5061e-03],
        [ 9.2172e-02, -1.1607e-01,  1.5591e-03],
        [ 8.9476e-02, -9.5863e-02,  3.2922e-03],
        [ 9.4126e-02, -1.3946e-01,  8.0308e-04],
        [ 9.3513e-02, -1.2655e-01,  1.0768e-03],
        [ 9.5109e-02, -9.4957e-02,  7.4753e-04],
        [ 9.6624e-02, -1.4297e-01,  3.1641e-04],
        [ 9.7591e-02, -1.5677e-01,  2.1011e-04],
        [ 9.7603e-02, -1.8686e-01,  1.2538e-04],
        [ 9.7881e-02, -2.0711e-01,  1.4317e-04],
        [ 9.7677e-02, -1.8494e-01,  1.2857e-04],
        [ 9.7835e-02, -1.7394e-01,  1.0446e-04],
        [ 9.1397e-02, -5.2925e-02,  2.6996e-03],
        [ 9.4392e-02, -1.6904e-01,  2.2377e-03],
        [ 9.6599e-02, -2.7652e-01,  7.2515e-04],
        [ 9.2737e-02, -1.3661e-01,  3.0497e-03],
        [ 9.9279e-02, -3.8117e-01,  1.6212e-05],
        [ 9.7781e-02, -3.2061e-01,  3.9738e-04],
        [ 9.8131e-02, -2.6995e-01,  4.4358e-04],
        [ 9.9636e-02, -3.9249e-01,  1.4246e-05],
        [ 9.4716e-02,  3.4095e-02,  2.0228e-03],
        [ 8.9513e-02, -8.4952e-03,  5.1138e-03],
        [ 8.7638e-02,  5.5081e-02,  1.2078e-02],
        [ 9.9887e-02, -3.9733e-01,  1.1623e-06],
        [ 9.7357e-02, -3.2418e-01,  7.3662e-04],
        [ 9.9693e-02, -3.7410e-01,  1.3649e-05],
        [ 9.9825e-02, -3.8805e-01,  3.7551e-06],
        [ 9.7190e-02, -7.2068e-02,  9.5415e-04],
        [ 9.3288e-02,  5.7841e-02,  3.8698e-03],
        [ 8.7996e-02,  2.6437e-02,  1.1627e-02],
        [ 6.8426e-02,  1.5979e-02,  8.0202e-02],
        [-7.1221e-03,  8.7481e-02,  8.5810e-01],
        [ 8.5798e-02, -1.3757e-01,  8.5619e-03],
        [ 5.9815e-02, -2.0171e-02,  8.8461e-02],
        [ 7.4261e-02, -3.8436e-02,  3.7721e-02],
        [ 8.3096e-02, -6.5314e-02,  1.4825e-02],
        [ 8.8213e-02, -1.3007e-01,  8.0911e-03],
        [ 7.5405e-02, -5.1455e-02,  3.2346e-02],
        [ 7.4880e-02, -3.3869e-02,  2.1360e-02],
        [ 9.4266e-02, -1.5496e-01,  9.5883e-04],
        [ 7.4352e-02,  6.6367e-02,  3.2902e-02],
        [ 8.9129e-02, -9.9076e-02,  8.4984e-03],
        [ 7.7046e-02, -3.4445e-02,  2.8612e-02],
        [ 8.3006e-02, -4.6907e-02,  1.4005e-02],
        [ 7.9612e-02, -6.7902e-02,  3.0998e-02],
        [ 8.0296e-02, -1.4916e-02,  2.3230e-02],
        [ 8.4061e-02, -4.3266e-02,  1.4146e-02],
        [ 8.4192e-02,  7.4585e-03,  2.0774e-02],
        [ 8.3502e-02, -4.2926e-02,  1.7047e-02],
        [ 7.8261e-02, -2.9693e-02,  2.7852e-02],
        [ 8.8054e-02, -4.8204e-02,  1.0458e-02],
        [ 7.5250e-02, -1.2234e-02,  4.2773e-02],
        [ 8.4353e-02, -5.8587e-02,  1.2706e-02],
        [ 8.5807e-02, -9.7599e-03,  1.0741e-02],
        [ 8.7562e-02, -1.1895e-01,  8.4436e-03],
        [ 7.9522e-02, -8.1671e-02,  3.3624e-02],
        [ 8.7260e-02, -1.1175e-01,  1.1247e-02],
        [ 8.8964e-02, -1.9824e-01,  5.3419e-03],
        [ 8.1679e-02, -1.2354e-01,  2.0132e-02],
        [ 8.4557e-02, -1.3133e-01,  1.5806e-02],
        [ 9.0936e-02, -1.4463e-01,  4.1797e-03],
        [ 9.1636e-02, -1.0596e-01,  3.4007e-03],
        [ 7.9550e-02,  3.0593e-03,  2.3440e-02],
        [ 8.3368e-02, -1.1977e-01,  1.4377e-02],
        [ 8.0437e-02, -1.4027e-01,  4.3714e-02],
        [ 9.4490e-02, -2.9954e-01,  1.8475e-03],
        [ 9.7242e-02, -3.5464e-01,  5.0434e-04],
        [ 9.7770e-02, -2.9219e-01,  4.6262e-04],
        [ 9.8819e-02, -3.2148e-01,  1.4037e-04],
        [ 9.7800e-02, -2.3282e-01,  3.4901e-04],
        [ 9.4066e-02, -2.3614e-01,  1.7403e-03],
        [ 9.8293e-02, -3.6984e-01,  2.8968e-04],
        [ 8.9618e-02, -1.7005e-01,  7.3214e-03],
        [ 9.4518e-02, -3.1644e-01,  1.6564e-03],
        [ 9.7703e-02, -3.1555e-01,  4.4268e-04],
        [ 8.8019e-02,  9.3995e-02,  1.1738e-02],
        [ 9.2414e-02, -6.3187e-02,  4.2059e-03],
        [ 9.5101e-02, -1.7303e-01,  1.7968e-03],
        [ 9.9686e-02, -3.9320e-01,  6.3181e-06],
        [ 9.8534e-02, -3.6724e-01,  3.2821e-04],
        [ 9.9152e-02, -3.6932e-01,  8.1390e-05],
        [ 9.8061e-02, -3.3160e-01,  3.0240e-04],
        [ 9.4286e-02, -2.4776e-01,  2.0654e-03],
        [ 8.4627e-02,  5.5114e-02,  2.3263e-02],
        [ 9.6515e-02, -2.4677e-01,  1.8810e-03],
        [ 7.6838e-02,  3.5134e-02,  5.8636e-02],
        [ 5.5179e-02,  1.0955e-01,  2.4221e-01],
        [ 5.6749e-02,  4.5260e-02,  3.2431e-01],
        [ 9.1181e-02, -2.2824e-01,  6.8475e-03]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 60
Episode Length = 84
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1447,  1.1461,  1.1575,  1.1513,  1.1424,  1.1425, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1694,  1.1626,  1.1617,  1.1645, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1453,  1.1557,  1.1514,  1.1548,
         1.1588,  1.1512,  1.1579,  1.1654,  1.1632,  1.1766,  1.1658,  1.1735,
        -3.0000,  0.0000,  0.1846,  1.1859,  1.1870,  1.1842,  1.1880,  1.1902,
         1.1876,  1.1797,  1.1695,  1.1719,  1.1794,  1.0000], device='cuda:0')
target_q_episode tensor([ 1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  6.9176,  6.2291,  5.5043,
         4.7413,  3.9382,  3.0929,  2.2030,  1.2664,  0.2804, -0.7575, -1.8500,
        -3.0000,  0.0000,  0.0000,  8.6240,  8.0253,  7.3950,  6.7316,  6.0333,
         5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1447,  1.1461,  1.1575,  1.1513,  1.1423,  1.1425, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1694,  1.1626,  1.1616,  1.1645, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1453,  1.1558,  1.1514,  1.1549,
         1.1588,  1.1512,  1.1579,  1.1654,  1.1632,  1.1766,  1.1658,  1.1735,
        -3.0000,  0.0000,  0.1846,  1.1859,  1.1870,  1.1842,  1.1881,  1.1902,
         1.1876,  1.1797,  1.1695,  1.1719,  1.1794,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.3010e-02, -5.8838e-02,  1.5784e-02],
        [ 8.1451e-02, -4.5327e-02,  1.6977e-02],
        [ 9.0467e-02, -7.6455e-02,  4.3244e-03],
        [ 9.5040e-02, -1.4000e-01,  1.7303e-03],
        [ 9.4732e-02, -1.3531e-01,  1.7129e-03],
        [ 9.6142e-02, -7.5608e-02,  8.3983e-04],
        [ 9.3587e-02, -3.2151e-02,  1.9141e-03],
        [ 9.4900e-02, -7.2094e-02,  1.3450e-03],
        [ 9.4034e-02, -4.6364e-03,  1.8031e-03],
        [ 9.2579e-02,  2.4626e-03,  2.7908e-03],
        [ 9.4531e-02, -3.5498e-02,  1.6772e-03],
        [ 9.5192e-02, -3.4442e-02,  9.9179e-04],
        [ 9.2248e-02,  1.2412e-03,  3.4286e-03],
        [ 9.3104e-02, -6.3941e-02,  1.9191e-03],
        [ 9.3277e-02, -6.3178e-02,  2.7305e-03],
        [ 9.2949e-02, -4.9013e-02,  3.0778e-03],
        [ 9.3130e-02, -5.4752e-02,  2.8756e-03],
        [ 9.6791e-02, -1.1736e-01,  6.3789e-04],
        [ 9.7686e-02, -1.7928e-01,  3.7810e-04],
        [ 9.9361e-02, -3.1450e-01,  4.3631e-05],
        [ 9.8742e-02, -2.3528e-01,  1.6779e-04],
        [ 9.8900e-02, -2.8017e-01,  1.3086e-04],
        [ 9.8974e-02, -2.8994e-01,  8.0734e-05],
        [ 9.9836e-02, -3.7947e-01,  2.3842e-06],
        [ 9.9902e-02, -3.9161e-01,  9.2387e-07],
        [ 9.9378e-02, -3.3762e-01,  2.4706e-05],
        [ 9.9709e-02, -3.6691e-01,  1.2547e-05],
        [ 9.9565e-02, -3.6348e-01,  2.0981e-05],
        [ 9.8332e-02, -3.0903e-01,  1.9309e-04],
        [ 9.9341e-02, -3.7646e-01,  3.8683e-05],
        [ 9.7290e-02, -1.6529e-01,  4.4376e-04],
        [ 9.1617e-02, -1.4888e-02,  3.6942e-03],
        [ 9.0159e-02, -5.2497e-03,  1.1766e-02],
        [ 8.2692e-02,  1.0319e-01,  1.4744e-02],
        [ 8.4038e-02,  3.1262e-02,  1.4459e-02],
        [ 8.1187e-02, -5.2179e-03,  2.7131e-02],
        [ 6.2176e-02,  1.6008e-02,  1.3039e-01],
        [ 2.4583e-02,  8.2101e-02,  6.5713e-01],
        [ 9.7893e-02, -3.0266e-01,  3.3468e-04],
        [ 9.4679e-02, -1.4952e-01,  1.7610e-03],
        [ 9.2789e-02, -5.6683e-02,  3.1824e-03],
        [ 8.5281e-02, -7.6953e-02,  9.4209e-03],
        [ 8.3360e-02,  7.5205e-02,  9.3458e-03],
        [ 8.8080e-02, -2.8835e-02,  4.5532e-03],
        [ 8.9702e-02, -9.5109e-02,  5.9325e-03],
        [ 8.8651e-02, -7.8607e-02,  6.4569e-03],
        [ 9.0150e-02, -2.1224e-01,  5.0145e-03],
        [ 9.1919e-02,  8.6039e-02,  3.7255e-03],
        [ 8.9938e-02, -5.3374e-03,  4.2131e-03],
        [ 8.9081e-02, -1.6615e-01,  7.4723e-03],
        [ 8.2746e-02, -3.7341e-03,  1.6245e-02],
        [ 7.6719e-02, -8.3120e-02,  3.4879e-02],
        [ 9.3434e-02, -2.7855e-01,  2.4194e-03],
        [ 9.1329e-02, -1.2762e-01,  3.6177e-03],
        [ 9.0231e-02, -7.0714e-02,  9.4144e-03],
        [ 9.0424e-02, -6.6635e-02,  6.9675e-03],
        [ 8.8635e-02, -1.8332e-02,  6.8685e-03],
        [ 8.6859e-02,  9.0237e-02,  1.5378e-02],
        [ 9.2150e-02,  1.0303e-01,  3.3574e-03],
        [ 9.2932e-02, -4.3159e-02,  2.9204e-03],
        [ 9.7969e-02, -2.8930e-01,  3.9181e-04],
        [ 9.3995e-02, -1.3355e-01,  4.2764e-03],
        [ 9.5598e-02, -1.7954e-01,  2.5588e-03],
        [ 9.3975e-02, -1.1036e-01,  4.2064e-03],
        [ 8.9493e-02,  4.7767e-02,  8.2249e-03],
        [ 9.5636e-02, -1.4671e-01,  1.4865e-03],
        [ 9.5545e-02, -1.3596e-01,  1.5492e-03],
        [ 9.8692e-02, -2.7958e-01,  1.3304e-04],
        [ 9.9021e-02, -3.4152e-01,  8.8841e-05],
        [ 9.9067e-02, -3.2017e-01,  7.2718e-05],
        [ 9.9278e-02, -3.7080e-01,  4.8041e-05],
        [ 9.8573e-02, -3.3779e-01,  2.2188e-04],
        [ 9.9116e-02, -3.6586e-01,  7.2956e-05],
        [ 9.9227e-02, -3.5943e-01,  1.1146e-04],
        [ 9.7355e-02, -2.6756e-01,  7.4205e-04],
        [ 9.3741e-02, -2.3295e-01,  2.7490e-03],
        [ 9.7088e-02, -3.4992e-01,  7.3090e-04],
        [ 9.8214e-02, -3.5315e-01,  1.7512e-04],
        [ 9.7946e-02, -3.6004e-01,  3.2622e-04],
        [ 9.3248e-02, -1.8553e-01,  3.7540e-03],
        [ 8.2458e-02,  2.7817e-02,  1.8692e-02],
        [ 8.1524e-02,  7.1668e-02,  2.4297e-02],
        [ 7.7098e-02,  8.3734e-02,  3.3133e-02],
        [ 5.6217e-02,  6.9445e-02,  1.9843e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Saving checkpoint
Run No. 61
Episode Length = 110
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1415,  1.1468,  1.1371,  1.1359,  1.1321,  1.1376,  1.1359,  1.1338,
         1.1487,  1.1525, -2.0000,  0.1197,  1.1510,  1.1459,  1.1566, -4.0000,
         0.0000,  0.0000,  0.1385,  1.1762,  1.1698,  1.1738,  1.1503,  1.1554,
         1.1591,  1.1526,  1.1638,  1.1551,  1.1644,  1.1532,  1.1458,  1.1734,
         1.1722,  1.1712,  1.1775,  1.1830,  1.1730,  1.1672,  1.1683,  1.1833,
         1.1712,  1.1677,  1.1686,  1.1581,  1.1526,  1.1561,  1.1596,  1.1618,
         1.1607,  1.1603,  1.1672,  1.1749,  1.1726,  1.1527,  1.1545,  1.1595,
         1.1474, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1767,  1.1613,
         1.1673,  1.1609,  1.1668,  1.0000], device='cuda:0')
target_q_episode tensor([ 6.8278,  6.1345,  5.4048,  4.6366,  3.8280,  2.9768,  2.0809,  1.1377,
         0.1450, -0.9000, -2.0000,  0.0000, -0.5770, -1.6600, -2.8000, -4.0000,
         0.0000,  0.0000,  0.0000, 16.2977, 16.1029, 15.8977, 15.6818, 15.4546,
        15.2153, 14.9635, 14.6984, 14.4194, 14.1257, 13.8165, 13.4911, 13.1485,
        12.7879, 12.4083, 12.0087, 11.5881, 11.1454, 10.6794, 10.1888,  9.6724,
         9.1289,  8.5567,  7.9544,  7.3205,  6.6531,  5.9506,  5.2112,  4.4328,
         3.6135,  2.7511,  1.8432,  0.8876, -0.1183, -1.1772, -2.2917, -3.4650,
        -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.5244,
         3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1416,  1.1468,  1.1371,  1.1359,  1.1321,  1.1377,  1.1359,  1.1338,
         1.1487,  1.1524, -2.0000,  0.1197,  1.1510,  1.1459,  1.1566, -4.0000,
         0.0000,  0.0000,  0.1385,  1.1763,  1.1699,  1.1738,  1.1504,  1.1555,
         1.1592,  1.1527,  1.1638,  1.1551,  1.1645,  1.1532,  1.1459,  1.1735,
         1.1722,  1.1713,  1.1776,  1.1830,  1.1730,  1.1672,  1.1684,  1.1833,
         1.1712,  1.1677,  1.1686,  1.1581,  1.1526,  1.1561,  1.1596,  1.1618,
         1.1608,  1.1603,  1.1672,  1.1749,  1.1726,  1.1527,  1.1545,  1.1595,
         1.1474, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1767,  1.1613,
         1.1674,  1.1609,  1.1668,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 5.9969e-02, -5.7939e-02,  8.0528e-02],
        [ 7.4433e-02, -8.4174e-02,  2.3208e-02],
        [ 4.9075e-02, -1.4117e-02,  1.3544e-01],
        [ 5.0906e-02, -3.9764e-02,  1.2567e-01],
        [ 7.0131e-02, -4.5580e-02,  3.6096e-02],
        [ 7.6809e-02, -4.2897e-02,  1.5268e-02],
        [ 8.8407e-02, -6.3555e-02,  4.2702e-03],
        [ 8.8094e-02, -1.2856e-01,  7.2848e-03],
        [ 8.7529e-02, -1.0740e-01,  7.9306e-03],
        [ 8.2090e-02,  1.4672e-02,  1.7852e-02],
        [ 8.6924e-02, -7.5759e-03,  6.9314e-03],
        [ 8.9764e-02, -7.3710e-02,  5.6065e-03],
        [ 9.6138e-02, -1.3062e-01,  5.0431e-04],
        [ 9.4636e-02, -8.8404e-02,  7.2700e-04],
        [ 9.5964e-02, -1.4170e-01,  4.4122e-04],
        [ 9.6580e-02, -9.3767e-02,  3.0881e-04],
        [ 9.8649e-02, -2.3103e-01,  4.1306e-05],
        [ 9.7910e-02, -1.8678e-01,  1.1018e-04],
        [ 9.7521e-02, -1.6647e-01,  1.6144e-04],
        [ 9.8713e-02, -2.1332e-01,  5.1111e-05],
        [ 9.8453e-02, -2.1470e-01,  6.9410e-05],
        [ 9.9124e-02, -2.4064e-01,  2.5868e-05],
        [ 9.7875e-02, -1.6525e-01,  1.2362e-04],
        [ 9.8511e-02, -2.0879e-01,  8.3029e-05],
        [ 9.7622e-02, -1.1213e-01,  2.1970e-04],
        [ 9.9408e-02, -2.5687e-01,  1.1384e-05],
        [ 9.8730e-02, -1.9667e-01,  5.5254e-05],
        [ 9.8040e-02, -1.2362e-01,  1.9267e-04],
        [ 9.7926e-02, -1.1052e-01,  1.9571e-04],
        [ 9.8257e-02, -1.0990e-01,  1.2833e-04],
        [ 9.8717e-02, -1.0218e-01,  9.6858e-05],
        [ 9.9003e-02, -1.5986e-01,  5.4449e-05],
        [ 9.8157e-02, -1.0258e-01,  2.2686e-04],
        [ 9.6555e-02,  4.5684e-02,  1.0463e-03],
        [ 9.6707e-02, -7.6376e-02,  6.9737e-04],
        [ 9.1859e-02,  3.1460e-02,  5.8338e-03],
        [ 9.4263e-02, -2.5250e-02,  3.3894e-03],
        [ 9.5210e-02, -7.4248e-02,  3.2507e-03],
        [ 9.0183e-02,  9.2551e-03,  1.1483e-02],
        [ 6.9446e-02,  2.8263e-02,  1.3083e-01],
        [ 5.4093e-02,  3.2425e-02,  2.8510e-01],
        [ 2.2447e-02,  7.3269e-02,  6.5715e-01],
        [ 5.3299e-02, -8.0327e-02,  1.0674e-01],
        [ 5.3409e-02, -6.9747e-02,  1.0679e-01],
        [ 4.9567e-02, -2.0600e-02,  1.4996e-01],
        [ 4.9732e-02, -1.8533e-02,  1.1926e-01],
        [ 5.5068e-02,  9.3544e-04,  1.0348e-01],
        [ 4.0975e-02,  4.3684e-02,  1.5902e-01],
        [ 5.5385e-02, -1.6397e-02,  8.6945e-02],
        [ 7.2570e-02, -1.9646e-02,  4.1375e-02],
        [ 8.9449e-02, -1.2649e-01,  9.6303e-03],
        [ 8.2684e-02, -7.2099e-02,  2.0456e-02],
        [ 6.0956e-02,  3.4660e-02,  7.7871e-02],
        [ 7.1269e-02, -3.7033e-03,  4.7490e-02],
        [ 8.4155e-02,  2.7792e-02,  1.3365e-02],
        [ 9.5034e-02, -2.5578e-01,  1.1234e-03],
        [ 9.5438e-02, -2.5115e-01,  1.5551e-03],
        [ 8.9961e-02, -4.8868e-02,  6.0675e-03],
        [ 7.3578e-02,  3.7238e-02,  4.2820e-02],
        [ 8.7777e-02,  3.2859e-02,  7.7590e-03],
        [ 8.7463e-02,  2.7344e-02,  8.4089e-03],
        [ 9.7012e-02, -2.8120e-01,  4.1214e-04],
        [ 9.9493e-02, -3.8969e-01,  1.5318e-05],
        [ 9.8242e-02, -2.8359e-01,  2.5210e-04],
        [ 9.6406e-02, -2.1400e-01,  6.7985e-04],
        [ 9.7226e-02, -2.3034e-01,  6.2746e-04],
        [ 9.3331e-02, -8.2337e-02,  2.3102e-03],
        [ 9.7423e-02, -2.5995e-01,  7.2059e-04],
        [ 9.7639e-02, -2.5282e-01,  4.8888e-04],
        [ 9.7940e-02, -1.6711e-01,  5.1749e-04],
        [ 8.8406e-02,  2.0493e-02,  1.5658e-02],
        [ 9.4762e-02, -1.1926e-01,  5.1807e-03],
        [ 9.8960e-02, -3.3950e-01,  2.2739e-04],
        [ 9.7379e-02, -1.9421e-01,  1.0458e-03],
        [ 9.8254e-02, -3.4302e-01,  4.1446e-04],
        [ 9.6938e-02, -2.8446e-01,  1.9850e-03],
        [ 9.2673e-02,  2.6147e-04,  3.3024e-03],
        [ 9.2611e-02, -2.4074e-02,  3.4256e-03],
        [ 9.2551e-02, -2.6547e-02,  3.8190e-03],
        [ 9.3711e-02, -1.3551e-01,  1.4761e-03],
        [ 9.6168e-02, -6.3539e-02,  8.1584e-04],
        [ 8.3752e-02, -2.7004e-02,  2.6029e-02],
        [ 7.7195e-02, -3.6206e-02,  4.7893e-02],
        [ 8.8712e-02, -1.4432e-01,  7.9012e-03],
        [ 7.5958e-02,  1.7243e-02,  4.4190e-02],
        [ 8.6665e-02, -1.2336e-01,  2.0336e-02],
        [ 8.3768e-02, -1.6864e-01,  1.7025e-02],
        [ 7.1530e-02,  8.0571e-02,  6.3964e-02],
        [ 5.5463e-02,  6.7854e-02,  2.5820e-01],
        [ 5.4697e-02,  3.1466e-02,  1.7602e-01],
        [ 9.0584e-02, -1.2068e-01,  6.0265e-03],
        [ 9.2734e-02, -1.7912e-01,  5.3816e-03],
        [ 7.8501e-02, -5.3184e-02,  3.2585e-02],
        [ 7.4174e-02, -5.9933e-02,  5.0004e-02],
        [ 9.4033e-02, -2.0569e-01,  2.7680e-03],
        [ 7.6128e-02,  4.8585e-02,  5.9784e-02],
        [ 7.0386e-02,  8.8918e-03,  7.8635e-02],
        [ 5.1547e-02,  7.1997e-02,  1.4285e-01],
        [ 7.5209e-02,  1.2152e-02,  3.5154e-02],
        [ 6.6916e-02,  3.1241e-02,  1.1761e-01],
        [ 8.0458e-02, -7.5902e-02,  2.7330e-02],
        [ 9.2241e-02, -2.4451e-01,  9.3065e-03],
        [ 9.4125e-02, -2.2781e-01,  4.6955e-03],
        [ 8.8389e-02, -1.5387e-01,  1.8112e-02],
        [ 8.8827e-02, -4.0799e-02,  1.3365e-02],
        [ 7.9250e-02,  3.3147e-02,  1.9828e-02],
        [ 6.1737e-02,  7.8846e-02,  1.1641e-01],
        [ 7.9895e-02, -5.9953e-02,  5.4034e-02],
        [ 8.5870e-02, -1.9656e-01,  1.9221e-02],
        [ 8.3191e-02, -1.8792e-01,  2.3469e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 62
Episode Length = 82
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1337,  1.1335,  1.1244,  1.1351, -4.0000,  0.0000,  0.0000,  0.1329,
         1.1207,  1.1415,  1.1418,  1.1486,  1.1666,  1.1437,  1.1482,  1.1563,
        -4.0000,  0.0000,  0.0000,  0.1585,  1.1559,  1.1385,  1.1615,  1.1753,
         1.1738,  1.1570,  1.1766, -3.0000,  0.0000,  0.1839,  1.1729,  1.1825,
         1.1890,  1.1827,  1.1906,  1.1845,  1.1608,  1.1717,  1.1673,  1.1699,
         1.1720,  1.1790,  1.1793,  1.0000], device='cuda:0')
target_q_episode tensor([ 0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,
         4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000,
        -4.0000,  0.0000,  0.0000,  0.0000,  3.9382,  3.0929,  2.2030,  1.2664,
         0.2804, -0.7575, -1.8500, -3.0000,  0.0000,  0.0000, 10.2465,  9.7332,
         9.1928,  8.6240,  8.0253,  7.3950,  6.7316,  6.0333,  5.2982,  4.5244,
         3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1337,  1.1335,  1.1244,  1.1351, -4.0000,  0.0000,  0.0000,  0.1329,
         1.1207,  1.1415,  1.1418,  1.1486,  1.1666,  1.1437,  1.1482,  1.1563,
        -4.0000,  0.0000,  0.0000,  0.1585,  1.1559,  1.1385,  1.1615,  1.1753,
         1.1738,  1.1570,  1.1766, -3.0000,  0.0000,  0.1839,  1.1729,  1.1826,
         1.1891,  1.1827,  1.1906,  1.1846,  1.1608,  1.1717,  1.1673,  1.1699,
         1.1720,  1.1790,  1.1793,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.5733e-02, -5.5280e-02,  9.3322e-03],
        [ 8.8210e-02, -4.0812e-02,  6.9456e-03],
        [ 8.7454e-02, -6.7462e-02,  6.8902e-03],
        [ 9.2624e-02, -1.1631e-01,  3.1577e-03],
        [ 9.6018e-02, -1.4009e-01,  1.0278e-03],
        [ 9.7281e-02, -7.3038e-02,  4.5672e-04],
        [ 9.8612e-02, -1.5378e-01,  1.4186e-04],
        [ 9.7208e-02, -5.4052e-02,  4.0507e-04],
        [ 9.5166e-02,  3.8629e-02,  1.1024e-03],
        [ 9.3494e-02,  3.1183e-03,  1.7413e-03],
        [ 9.5098e-02, -2.7319e-03,  1.0447e-03],
        [ 9.4591e-02,  1.9936e-02,  1.5029e-03],
        [ 9.3292e-02,  1.7586e-02,  1.9602e-03],
        [ 9.4771e-02, -5.1003e-02,  1.5693e-03],
        [ 9.6361e-02, -7.5696e-02,  7.0736e-04],
        [ 9.4185e-02,  1.2897e-03,  1.5650e-03],
        [ 9.6060e-02, -3.4966e-02,  9.8848e-04],
        [ 9.8019e-02, -1.8126e-01,  3.1292e-04],
        [ 9.7628e-02, -1.4008e-01,  4.1983e-04],
        [ 9.8213e-02, -1.8456e-01,  3.9366e-04],
        [ 9.9265e-02, -2.9244e-01,  6.5714e-05],
        [ 9.9692e-02, -3.2116e-01,  1.4871e-05],
        [ 9.9879e-02, -3.7720e-01,  2.0266e-06],
        [ 9.9750e-02, -3.5004e-01,  6.8247e-06],
        [ 9.9948e-02, -3.9410e-01,  2.3842e-07],
        [ 9.9873e-02, -3.8548e-01,  1.0729e-06],
        [ 9.9850e-02, -3.3164e-01,  3.7551e-06],
        [ 9.9664e-02, -3.5390e-01,  1.3888e-05],
        [ 9.9249e-02, -3.3267e-01,  5.7161e-05],
        [ 9.6952e-02, -1.6024e-01,  7.8362e-04],
        [ 9.8851e-02, -2.9664e-01,  1.0651e-04],
        [ 9.5570e-02, -1.1409e-01,  9.3514e-04],
        [ 8.6548e-02,  1.3151e-01,  2.0635e-02],
        [ 8.4798e-02,  1.1862e-01,  2.1061e-02],
        [ 8.7727e-02,  1.0672e-01,  7.6235e-03],
        [ 8.1159e-02,  7.6368e-02,  2.4165e-02],
        [ 6.5709e-02,  5.2116e-02,  1.4279e-01],
        [ 2.9131e-02,  9.6273e-02,  6.2220e-01],
        [ 8.6889e-02, -5.2701e-02,  9.3145e-03],
        [ 8.3906e-02, -6.3382e-02,  9.5335e-03],
        [ 9.8701e-02, -3.3735e-01,  1.2502e-04],
        [ 9.7277e-02, -1.8451e-01,  4.3449e-04],
        [ 9.7578e-02, -1.3679e-01,  3.6532e-04],
        [ 9.7492e-02, -1.5852e-01,  4.1246e-04],
        [ 9.9163e-02, -1.9222e-01,  5.8621e-05],
        [ 9.4266e-02,  1.7025e-02,  1.8591e-03],
        [ 9.3395e-02,  6.5478e-02,  1.9251e-03],
        [ 9.6009e-02, -2.3479e-01,  7.5698e-04],
        [ 9.5717e-02, -3.7094e-02,  9.4321e-04],
        [ 9.7135e-02, -2.2666e-01,  5.2798e-04],
        [ 9.6845e-02, -1.8699e-01,  8.0949e-04],
        [ 9.3110e-02,  1.2198e-01,  2.3039e-03],
        [ 8.9760e-02,  1.6868e-01,  4.2562e-03],
        [ 9.1382e-02,  5.4254e-02,  2.5390e-03],
        [ 9.2084e-02,  2.6281e-02,  2.4423e-03],
        [ 9.0107e-02,  2.3800e-02,  7.3610e-03],
        [ 9.7204e-02, -2.4194e-01,  1.4534e-03],
        [ 9.1806e-02,  4.0068e-02,  6.6308e-03],
        [ 9.3203e-02,  3.7250e-02,  3.5796e-03],
        [ 9.2968e-02, -8.4060e-03,  3.7435e-03],
        [ 9.4853e-02, -1.0841e-01,  2.6341e-03],
        [ 9.8362e-02, -2.4013e-01,  2.4018e-04],
        [ 9.9007e-02, -3.0475e-01,  8.9109e-05],
        [ 9.9079e-02, -3.1639e-01,  8.6963e-05],
        [ 9.6150e-02, -1.2016e-01,  8.5083e-04],
        [ 9.9277e-02, -3.4321e-01,  3.9488e-05],
        [ 9.9404e-02, -3.4214e-01,  2.7716e-05],
        [ 9.9223e-02, -2.1098e-01,  1.1584e-04],
        [ 9.8680e-02, -3.3297e-01,  2.2081e-04],
        [ 9.7418e-02, -2.3083e-01,  7.3355e-04],
        [ 9.7347e-02, -2.9116e-01,  8.7917e-04],
        [ 9.8591e-02, -3.5521e-01,  1.7163e-04],
        [ 9.1528e-02, -2.0715e-01,  5.2866e-03],
        [ 8.9418e-02, -1.2528e-01,  7.4644e-03],
        [ 8.2696e-02, -1.8120e-02,  2.1068e-02],
        [ 8.9101e-02, -8.1545e-02,  5.4430e-03],
        [ 8.3692e-02, -1.0758e-01,  2.3032e-02],
        [ 6.2269e-02,  1.2510e-01,  1.7421e-01],
        [ 6.2636e-02,  1.0198e-01,  2.2362e-01],
        [ 3.3050e-02,  1.4673e-01,  5.9653e-01],
        [ 6.3057e-02,  1.8951e-02,  1.5856e-01],
        [ 4.4682e-02,  4.6083e-02,  3.6554e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 63
Episode Length = 108
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1358,  1.1373,  1.1267,  1.1458,  1.1481,  1.1533,  1.1389,  1.1416,
         1.1536,  1.1459,  1.1568,  1.1575,  1.1539,  1.1484,  1.1488,  1.1659,
         1.1539,  1.1621, -4.0000,  0.0000,  0.0000,  0.1685,  1.1733,  1.1671,
         1.1549,  1.1552,  1.1588,  1.1726,  1.1635,  1.1664,  1.1620,  1.1798,
         1.1741,  1.1607, -5.0000,  0.0000,  0.0000,  0.0000,  0.1855,  1.1707,
         1.1732,  1.1730,  1.1630, -5.0000,  0.0000,  0.0000,  0.0000,  0.1845,
         1.1867,  1.1741,  1.1718,  1.1716,  1.1652,  1.1502,  1.1748, -3.0000,
         0.0000,  0.1830,  1.1748,  1.1775, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([10.4669,  9.9651,  9.4370,  8.8810,  8.2958,  7.6798,  7.0314,  6.3488,
         5.6303,  4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770,
        -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  6.4910,  5.7800,
         5.0316,  4.2438,  3.4145,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344,
        -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3627,
        -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         3.9382,  3.0929,  2.2030,  1.2664,  0.2804, -0.7575, -1.8500, -3.0000,
         0.0000,  0.0000, -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1358,  1.1373,  1.1268,  1.1458,  1.1481,  1.1533,  1.1389,  1.1416,
         1.1537,  1.1460,  1.1568,  1.1575,  1.1539,  1.1484,  1.1488,  1.1659,
         1.1539,  1.1621, -4.0000,  0.0000,  0.0000,  0.1685,  1.1733,  1.1672,
         1.1549,  1.1552,  1.1588,  1.1726,  1.1635,  1.1664,  1.1620,  1.1798,
         1.1741,  1.1607, -5.0000,  0.0000,  0.0000,  0.0000,  0.1855,  1.1707,
         1.1732,  1.1730,  1.1630, -5.0000,  0.0000,  0.0000,  0.0000,  0.1845,
         1.1867,  1.1741,  1.1718,  1.1716,  1.1652,  1.1502,  1.1748, -3.0000,
         0.0000,  0.1830,  1.1748,  1.1775, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 6.7354e-02, -6.1893e-02,  5.9401e-02],
        [ 7.6780e-02, -8.3526e-02,  2.8332e-02],
        [ 7.3119e-02, -3.5184e-02,  4.0062e-02],
        [ 7.8930e-02, -3.5401e-02,  2.2347e-02],
        [ 8.1969e-02,  1.1180e-02,  1.9197e-02],
        [ 8.0490e-02,  2.6940e-02,  2.0648e-02],
        [ 8.6967e-02, -2.8199e-02,  7.7879e-03],
        [ 7.9310e-02, -3.1047e-02,  2.0343e-02],
        [ 9.2259e-02, -7.9905e-02,  2.4720e-03],
        [ 8.9129e-02, -3.8457e-02,  3.6958e-03],
        [ 9.2920e-02, -8.9309e-02,  1.2694e-03],
        [ 9.4056e-02, -9.1381e-02,  9.0581e-04],
        [ 9.5774e-02, -8.0630e-02,  5.4055e-04],
        [ 9.5684e-02, -7.7683e-02,  4.4185e-04],
        [ 9.4366e-02, -5.7788e-02,  8.4341e-04],
        [ 9.7272e-02, -1.3654e-01,  2.1166e-04],
        [ 9.7813e-02, -9.4354e-02,  1.6215e-04],
        [ 9.7701e-02, -8.1887e-02,  1.6803e-04],
        [ 9.7340e-02, -1.4059e-01,  1.7425e-04],
        [ 9.8700e-02, -1.9775e-01,  5.0426e-05],
        [ 9.7877e-02, -1.0584e-01,  1.3253e-04],
        [ 9.9043e-02, -1.2907e-01,  3.0488e-05],
        [ 9.4545e-02, -5.1542e-02,  1.3435e-03],
        [ 9.7821e-02, -1.8383e-01,  3.3316e-04],
        [ 9.4697e-02, -1.2560e-01,  1.8293e-03],
        [ 9.6291e-02, -1.4510e-01,  7.7331e-04],
        [ 9.7991e-02, -3.2979e-01,  1.6379e-04],
        [ 9.8664e-02, -3.2097e-01,  1.6493e-04],
        [ 9.8555e-02, -3.0926e-01,  2.7582e-04],
        [ 9.9300e-02, -3.6721e-01,  3.7521e-05],
        [ 9.8353e-02, -3.6860e-02,  3.0059e-04],
        [ 9.2796e-02,  1.4211e-01,  3.1452e-03],
        [ 9.0424e-02,  1.6059e-01,  6.5542e-03],
        [ 9.8567e-02, -3.2091e-01,  2.4214e-04],
        [ 9.1159e-02, -1.0657e-01,  7.6541e-03],
        [ 9.8633e-02, -3.0681e-01,  2.3738e-04],
        [ 9.8444e-02, -2.1439e-01,  5.7349e-04],
        [ 9.8359e-02, -8.1117e-02,  4.7457e-04],
        [ 9.4235e-02,  1.1202e-01,  3.6556e-03],
        [ 9.5406e-02,  1.5391e-02,  2.3788e-03],
        [ 8.0517e-02,  6.1977e-03,  3.7926e-02],
        [ 2.0714e-02,  1.9407e-01,  6.6416e-01],
        [ 8.1358e-02, -7.3545e-02,  1.1684e-02],
        [ 7.8089e-02, -3.6108e-02,  1.4825e-02],
        [ 7.7009e-02, -8.5547e-03,  2.5292e-02],
        [ 7.2295e-02, -3.8336e-02,  4.5459e-02],
        [ 8.0508e-02, -3.7111e-02,  1.7568e-02],
        [ 8.7591e-02, -9.3250e-02,  1.0090e-02],
        [ 8.4325e-02, -7.8520e-02,  9.2266e-03],
        [ 7.9091e-02, -2.4568e-02,  2.0435e-02],
        [ 9.0799e-02, -6.4085e-02,  5.5773e-03],
        [ 9.1382e-02, -6.2891e-02,  4.5542e-03],
        [ 8.6059e-02,  5.2033e-04,  1.2349e-02],
        [ 8.4991e-02, -3.3793e-03,  1.6157e-02],
        [ 8.2405e-02,  2.4482e-02,  1.0902e-02],
        [ 8.9437e-02, -5.3676e-02,  4.1552e-03],
        [ 8.2960e-02,  1.6145e-03,  1.1757e-02],
        [ 8.5816e-02, -5.5006e-03,  1.0676e-02],
        [ 9.3186e-02, -1.0202e-01,  3.7304e-03],
        [ 8.5200e-02,  1.5531e-03,  1.1253e-02],
        [ 9.1718e-02, -8.9068e-02,  4.8088e-03],
        [ 9.2629e-02, -7.0223e-02,  3.5291e-03],
        [ 9.3133e-02, -5.6056e-02,  4.0094e-03],
        [ 9.3693e-02, -1.1830e-01,  3.3249e-03],
        [ 9.0879e-02, -1.3621e-01,  4.8950e-03],
        [ 9.5814e-02, -1.5389e-01,  1.8809e-03],
        [ 9.2815e-02, -5.7772e-03,  1.8525e-03],
        [ 9.4168e-02, -4.0599e-02,  1.3165e-03],
        [ 9.5440e-02, -1.0732e-01,  2.3090e-03],
        [ 9.6431e-02, -2.1611e-01,  1.2719e-03],
        [ 9.1133e-02, -2.9234e-02,  5.1822e-03],
        [ 9.5345e-02, -6.6487e-02,  1.0079e-03],
        [ 9.3478e-02, -5.7743e-02,  1.4327e-03],
        [ 9.3292e-02,  1.5589e-02,  1.4161e-03],
        [ 9.3798e-02, -1.5387e-01,  1.9081e-03],
        [ 9.7631e-02, -1.6987e-01,  1.7267e-04],
        [ 9.7436e-02, -1.2334e-01,  2.4316e-04],
        [ 8.9145e-02, -3.4632e-02,  5.3158e-03],
        [ 9.0891e-02, -2.9779e-02,  5.0971e-03],
        [ 9.0589e-02, -5.3419e-02,  7.6009e-03],
        [ 9.3010e-02, -2.1795e-01,  4.4488e-03],
        [ 8.6463e-02, -1.1345e-01,  1.7099e-02],
        [ 9.4745e-02, -2.6373e-01,  2.3488e-03],
        [ 9.0954e-02, -1.9254e-01,  5.2603e-03],
        [ 9.6170e-02, -3.1977e-01,  5.7179e-04],
        [ 9.9632e-02, -3.8720e-01,  8.9407e-06],
        [ 9.6205e-02, -2.1243e-01,  4.8283e-04],
        [ 9.7291e-02, -2.9785e-01,  2.6822e-04],
        [ 8.8688e-02,  3.2798e-02,  1.3761e-02],
        [ 9.8710e-02, -3.3567e-01,  2.2572e-04],
        [ 9.7952e-02, -3.3881e-01,  7.9721e-04],
        [ 9.0283e-02,  2.2104e-02,  9.0841e-03],
        [ 8.2604e-02,  6.7285e-02,  3.6880e-02],
        [ 7.7467e-02,  2.1376e-01,  4.7235e-02],
        [ 8.3521e-02,  1.0099e-01,  2.2664e-02],
        [ 6.5831e-02,  1.3172e-01,  1.4086e-01],
        [ 9.3849e-02, -1.8443e-01,  4.8374e-03],
        [ 8.9401e-02, -2.0580e-01,  8.1989e-03],
        [ 9.4575e-02, -4.6961e-02,  6.2469e-03],
        [ 6.8993e-02,  6.4149e-02,  1.7307e-01],
        [ 6.2791e-02,  1.7114e-02,  1.8401e-01],
        [ 6.0008e-02,  4.7382e-02,  2.6293e-01],
        [ 8.2594e-02, -8.4341e-02,  4.4770e-02],
        [ 6.9624e-02, -6.1254e-02,  1.1278e-01],
        [ 6.7188e-02,  5.4518e-02,  1.1137e-01],
        [ 5.6653e-02,  7.6735e-02,  2.9436e-01],
        [ 7.3558e-02, -4.1073e-02,  1.1060e-01],
        [ 3.9651e-02,  1.3089e-01,  3.2282e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 64
Episode Length = 92
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1402,  1.1336,  1.1197,  1.1328,  1.1229,  1.1309,  1.1368,  1.1285,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1351,  1.1451,  1.1485,  1.1743,
         1.1550,  1.1413,  1.1410,  1.1491,  1.1693,  1.1749,  1.1586,  1.1491,
         1.1478,  1.1475,  1.1578,  1.1710,  1.1548,  1.1546, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1890,  1.1855,  1.1880,  1.1870,
         1.1870,  1.1803,  1.1723,  1.1737, -4.0000,  0.0000,  0.0000,  0.1837,
         1.1762,  1.1738,  1.1666,  1.1589,  1.1702,  1.0000], device='cuda:0')
target_q_episode tensor([ 3.4145,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.7108,  8.1166,  7.4911,
         6.8328,  6.1398,  5.4103,  4.6424,  3.8341,  2.9833,  2.0876,  1.1449,
         0.1525, -0.8921, -1.9917, -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.2399,  2.3578,  1.4293,
         0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,
         5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1402,  1.1336,  1.1197,  1.1328,  1.1229,  1.1309,  1.1368,  1.1285,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1351,  1.1451,  1.1485,  1.1744,
         1.1550,  1.1413,  1.1410,  1.1491,  1.1693,  1.1749,  1.1586,  1.1491,
         1.1478,  1.1475,  1.1578,  1.1710,  1.1548,  1.1545, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1890,  1.1856,  1.1880,  1.1870,
         1.1870,  1.1803,  1.1723,  1.1737, -4.0000,  0.0000,  0.0000,  0.1837,
         1.1762,  1.1738,  1.1666,  1.1589,  1.1702,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.2753e-02, -7.8489e-02,  2.8572e-03],
        [ 9.1301e-02, -6.3960e-02,  3.3216e-03],
        [ 9.4059e-02, -9.0488e-02,  2.5448e-03],
        [ 9.5696e-02, -1.4034e-01,  1.2120e-03],
        [ 9.8265e-02, -1.8009e-01,  1.8570e-04],
        [ 9.8895e-02, -1.6549e-01,  9.5844e-05],
        [ 9.8131e-02, -1.2248e-01,  2.1717e-04],
        [ 9.5504e-02, -2.7314e-02,  1.0285e-03],
        [ 9.6708e-02,  3.7572e-03,  4.1786e-04],
        [ 9.7978e-02, -7.7611e-02,  1.9386e-04],
        [ 9.6961e-02, -9.3525e-03,  3.9792e-04],
        [ 9.6522e-02, -1.9558e-02,  6.4456e-04],
        [ 9.5371e-02, -1.5996e-02,  1.1734e-03],
        [ 9.7675e-02, -5.3470e-02,  2.7490e-04],
        [ 9.6763e-02, -6.5851e-02,  5.3775e-04],
        [ 9.7319e-02, -1.2521e-01,  3.8335e-04],
        [ 9.7250e-02, -6.3943e-02,  4.8855e-04],
        [ 9.8146e-02, -1.1683e-01,  2.8634e-04],
        [ 9.8424e-02, -1.6698e-01,  2.2599e-04],
        [ 9.8328e-02, -1.7060e-01,  2.1550e-04],
        [ 9.9126e-02, -2.3540e-01,  9.0599e-05],
        [ 9.9770e-02, -3.3770e-01,  6.9141e-06],
        [ 9.9759e-02, -3.5021e-01,  6.7055e-06],
        [ 9.9857e-02, -3.6589e-01,  2.4438e-06],
        [ 9.9977e-02, -3.9648e-01,  5.9605e-08],
        [ 9.9880e-02, -3.7932e-01,  1.4603e-06],
        [ 9.9875e-02, -3.7734e-01,  3.1888e-06],
        [ 9.9969e-02, -3.9564e-01,  2.6822e-07],
        [ 9.9468e-02, -3.1954e-01,  5.0485e-05],
        [ 9.9902e-02, -3.9670e-01,  1.5497e-06],
        [ 9.8537e-02, -1.6129e-01,  1.5828e-04],
        [ 9.5470e-02,  3.0707e-02,  1.0610e-03],
        [ 9.6475e-02, -7.2765e-02,  1.9169e-03],
        [ 9.2918e-02,  1.3170e-01,  2.9718e-03],
        [ 8.9027e-02,  1.1284e-01,  6.6755e-03],
        [ 8.8430e-02,  6.7771e-02,  8.0334e-03],
        [ 7.2742e-02,  1.0048e-01,  6.6226e-02],
        [ 3.2640e-02,  1.5502e-01,  6.7077e-01],
        [ 8.6585e-02, -6.9119e-02,  8.9940e-03],
        [ 9.5850e-02, -1.2939e-01,  8.9997e-04],
        [ 9.4228e-02, -1.3108e-01,  1.5628e-03],
        [ 9.7994e-02, -2.8998e-01,  2.1148e-04],
        [ 9.9450e-02, -3.2298e-01,  2.7239e-05],
        [ 9.8877e-02, -1.8431e-01,  7.2032e-05],
        [ 9.4783e-02, -4.6752e-02,  1.1540e-03],
        [ 8.8008e-02,  7.9214e-02,  4.8776e-03],
        [ 8.1540e-02,  1.0141e-01,  1.1589e-02],
        [ 8.9420e-02, -1.3741e-02,  4.6215e-03],
        [ 7.3271e-02,  5.3592e-02,  3.1113e-02],
        [ 9.5029e-02, -9.4572e-02,  1.8927e-03],
        [ 9.8378e-02, -2.5125e-01,  2.2715e-04],
        [ 9.9774e-02, -3.6351e-01,  5.7518e-06],
        [ 9.9240e-02, -3.0195e-01,  6.4641e-05],
        [ 9.5632e-02,  7.5726e-02,  1.0628e-03],
        [ 9.6181e-02,  1.0372e-01,  6.1056e-04],
        [ 9.2550e-02,  1.5359e-01,  2.4316e-03],
        [ 9.5349e-02,  2.7314e-02,  8.5834e-04],
        [ 9.7414e-02, -2.1177e-01,  9.6843e-04],
        [ 9.8275e-02, -2.6723e-01,  4.9031e-04],
        [ 9.4499e-02,  4.2032e-02,  3.5948e-03],
        [ 9.5294e-02,  4.8951e-02,  1.6527e-03],
        [ 9.7157e-02, -4.2132e-02,  5.9527e-04],
        [ 9.6637e-02,  5.5365e-02,  5.6404e-04],
        [ 9.7614e-02, -1.2503e-01,  4.1270e-04],
        [ 9.6628e-02, -1.4458e-01,  6.7481e-04],
        [ 9.5768e-02, -1.8031e-02,  1.8736e-03],
        [ 9.8759e-02, -2.5152e-01,  2.2942e-04],
        [ 9.8420e-02, -2.7842e-01,  2.7579e-04],
        [ 9.9762e-02, -3.6200e-01,  1.0252e-05],
        [ 9.9137e-02, -2.0850e-01,  8.1778e-05],
        [ 9.8775e-02, -2.3814e-01,  1.7583e-04],
        [ 9.6876e-02, -1.9653e-01,  8.3926e-04],
        [ 9.9888e-02, -3.9204e-01,  1.8775e-06],
        [ 9.8850e-02, -3.2648e-01,  1.2705e-04],
        [ 9.8854e-02, -3.1759e-01,  4.1762e-04],
        [ 9.9719e-02, -3.9531e-01,  2.9385e-05],
        [ 9.9877e-02, -3.9418e-01,  4.6194e-06],
        [ 9.9114e-02, -3.4931e-01,  7.9215e-05],
        [ 9.6862e-02, -2.5874e-01,  4.7764e-04],
        [ 9.8037e-02, -1.8593e-01,  2.8852e-04],
        [ 9.7579e-02, -1.3051e-01,  4.8369e-04],
        [ 9.7134e-02, -2.2620e-01,  5.6735e-04],
        [ 9.7417e-02, -2.0139e-01,  1.0661e-03],
        [ 9.7060e-02, -1.7798e-01,  1.3615e-03],
        [ 9.4253e-02, -1.1514e-01,  8.4977e-03],
        [ 9.1332e-02, -1.0099e-01,  7.7781e-03],
        [ 8.1904e-02,  1.0357e-01,  5.8144e-02],
        [ 5.1088e-02,  1.8763e-01,  2.2603e-01],
        [ 3.6210e-02,  1.5986e-01,  5.3034e-01],
        [ 7.7041e-02,  9.5353e-02,  4.6880e-02],
        [ 6.9164e-02,  7.1271e-02,  1.5376e-01],
        [ 6.0306e-02,  5.0431e-02,  3.6277e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 65
Episode Length = 106
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1397,  1.1452,  1.1425,  1.1499,  1.1419,  1.1356,  1.1470,  1.1638,
         1.1408,  1.1498, -4.0000,  0.0000,  0.0000,  0.1391,  1.1425,  1.1625,
         1.1575,  1.1685,  1.1609,  1.1637, -4.0000,  0.0000,  0.0000,  0.1490,
         1.1370,  1.1477,  1.1664,  1.1678,  1.1629,  1.1744, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1611,  1.1717,  1.1680,  1.1708,  1.1664,  1.1496,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1388,  1.1574,  1.1530,  1.1528,
         1.1447,  1.1513, -5.0000,  0.0000,  0.0000,  0.0000,  0.1561,  1.1612,
         1.1626,  1.1642,  1.1528,  1.1486,  1.1616,  1.1564,  1.1657,  1.0000],
       device='cuda:0')
target_q_episode tensor([ 5.6303,  4.8740,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770,
        -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  2.3578,  1.4293,
         0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,
         1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6555, -0.3627, -1.4344,
        -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  7.3950,
         6.7316,  6.0333,  5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000],
       device='cuda:0')
target_q tensor([ 1.1398,  1.1452,  1.1425,  1.1499,  1.1419,  1.1356,  1.1470,  1.1638,
         1.1407,  1.1498, -4.0000,  0.0000,  0.0000,  0.1391,  1.1426,  1.1625,
         1.1575,  1.1685,  1.1608,  1.1636, -4.0000,  0.0000,  0.0000,  0.1490,
         1.1370,  1.1477,  1.1664,  1.1678,  1.1629,  1.1744, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1611,  1.1717,  1.1680,  1.1708,  1.1664,  1.1496,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1388,  1.1574,  1.1530,  1.1528,
         1.1447,  1.1512, -5.0000,  0.0000,  0.0000,  0.0000,  0.1561,  1.1612,
         1.1626,  1.1642,  1.1528,  1.1486,  1.1616,  1.1564,  1.1657,  1.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.5105e-02, -9.9109e-02,  8.3618e-03],
        [ 8.1857e-02, -7.4141e-02,  1.1055e-02],
        [ 7.2934e-02, -6.2712e-02,  3.4219e-02],
        [ 8.4126e-02, -1.1512e-01,  1.2825e-02],
        [ 7.9109e-02, -3.6284e-03,  1.6866e-02],
        [ 9.1379e-02, -9.0262e-02,  2.5774e-03],
        [ 9.4148e-02, -8.6162e-02,  1.0701e-03],
        [ 9.2251e-02, -1.2775e-02,  3.5005e-03],
        [ 9.0471e-02, -3.1464e-02,  4.4582e-03],
        [ 9.1256e-02, -1.7943e-02,  3.3582e-03],
        [ 9.1786e-02, -2.5615e-03,  3.0743e-03],
        [ 9.3622e-02, -9.0115e-02,  2.1207e-03],
        [ 9.7521e-02, -1.7063e-01,  1.6326e-04],
        [ 9.7387e-02, -1.1564e-01,  1.7491e-04],
        [ 9.9102e-02, -2.3529e-01,  2.3752e-05],
        [ 9.9292e-02, -2.3387e-01,  1.2606e-05],
        [ 9.9534e-02, -2.3875e-01,  5.6028e-06],
        [ 9.9582e-02, -2.3525e-01,  5.5432e-06],
        [ 9.9420e-02, -2.0274e-01,  7.9870e-06],
        [ 9.9398e-02, -1.9207e-01,  1.0908e-05],
        [ 9.9514e-02, -2.5386e-01,  7.1526e-06],
        [ 9.9549e-02, -2.1474e-01,  1.0461e-05],
        [ 9.9348e-02, -2.4181e-01,  1.7464e-05],
        [ 9.9465e-02, -1.8646e-01,  1.5408e-05],
        [ 9.9305e-02, -1.8292e-01,  3.3587e-05],
        [ 9.9212e-02, -1.9245e-01,  2.1040e-05],
        [ 9.9419e-02, -1.8926e-01,  1.0341e-05],
        [ 9.8548e-02, -1.2431e-01,  7.6443e-05],
        [ 9.8438e-02, -1.1167e-01,  1.0517e-04],
        [ 9.8593e-02, -1.0711e-01,  8.1897e-05],
        [ 9.9587e-02, -1.9616e-01,  1.0490e-05],
        [ 9.9157e-02, -9.8398e-02,  4.6402e-05],
        [ 9.8881e-02, -5.2929e-02,  1.2314e-04],
        [ 9.8870e-02, -1.0381e-01,  9.9093e-05],
        [ 9.9483e-02, -1.5679e-01,  2.1160e-05],
        [ 9.7566e-02,  1.6223e-02,  6.7908e-04],
        [ 9.8564e-02, -5.8497e-02,  3.4514e-04],
        [ 9.7592e-02, -7.1249e-02,  1.0674e-03],
        [ 9.4898e-02,  3.8419e-02,  3.0442e-03],
        [ 8.9398e-02,  6.2904e-03,  1.6571e-02],
        [ 7.6080e-02,  7.8618e-02,  8.6918e-02],
        [ 4.3641e-02,  1.2054e-01,  3.8965e-01],
        [ 8.4179e-02, -1.0158e-01,  5.8265e-03],
        [ 9.3758e-02, -1.4349e-01,  1.1646e-03],
        [ 9.0365e-02, -1.1051e-01,  3.2739e-03],
        [ 7.9096e-02, -5.0473e-02,  1.9310e-02],
        [ 8.2068e-02, -2.4962e-02,  1.6684e-02],
        [ 7.6954e-02,  1.9550e-02,  2.2644e-02],
        [ 9.4116e-02, -8.5933e-02,  2.0198e-03],
        [ 9.6705e-02, -2.5075e-01,  1.0928e-03],
        [ 9.4530e-02, -6.1391e-02,  1.0484e-03],
        [ 8.2453e-02,  2.5960e-02,  1.0566e-02],
        [ 8.9876e-02, -4.9670e-02,  3.1419e-03],
        [ 8.7312e-02,  2.9653e-02,  4.0990e-03],
        [ 8.9022e-02, -6.0222e-03,  9.0177e-03],
        [ 8.9438e-02, -4.4345e-02,  6.4773e-03],
        [ 9.6056e-02, -2.8336e-01,  7.9277e-04],
        [ 9.6745e-02, -2.3931e-01,  7.8702e-04],
        [ 9.5211e-02, -7.5142e-03,  2.3457e-03],
        [ 9.5359e-02, -1.3915e-02,  2.0176e-03],
        [ 9.4929e-02,  4.3923e-02,  1.3888e-03],
        [ 9.7443e-02, -5.9555e-02,  1.8263e-04],
        [ 9.7642e-02, -1.1521e-01,  1.5274e-04],
        [ 9.8288e-02, -1.3454e-01,  8.4758e-05],
        [ 9.8098e-02, -8.7906e-02,  1.5584e-04],
        [ 9.8116e-02, -1.9537e-01,  6.1157e-04],
        [ 9.9002e-02, -3.3013e-01,  1.3697e-04],
        [ 9.9684e-02, -3.8655e-01,  1.5169e-05],
        [ 9.9848e-02, -3.9077e-01,  3.3677e-06],
        [ 9.9702e-02, -3.8188e-01,  1.3232e-05],
        [ 9.8982e-02, -1.6518e-01,  1.2425e-04],
        [ 9.8595e-02, -8.7807e-02,  1.7285e-04],
        [ 9.7342e-02,  1.3266e-01,  3.3066e-04],
        [ 9.8623e-02, -1.1806e-01,  7.1347e-05],
        [ 9.6213e-02, -1.4127e-01,  2.0195e-03],
        [ 8.9304e-02,  1.1377e-01,  1.1202e-02],
        [ 8.9273e-02,  4.1572e-02,  6.6803e-03],
        [ 9.7720e-02, -2.2741e-01,  5.9104e-04],
        [ 9.7143e-02, -1.5966e-01,  6.8602e-04],
        [ 9.3320e-02, -4.9941e-02,  1.9237e-03],
        [ 9.7714e-02, -1.8573e-01,  3.4007e-04],
        [ 8.3647e-02,  1.1110e-01,  2.2060e-02],
        [ 8.2999e-02,  1.0356e-01,  2.7285e-02],
        [ 7.9395e-02,  2.9245e-02,  4.8441e-02],
        [ 9.2555e-02, -1.5452e-01,  1.2049e-02],
        [ 7.6098e-02,  2.0441e-02,  8.3496e-02],
        [ 8.0957e-02,  2.2559e-02,  3.4126e-02],
        [ 8.9704e-02, -9.6590e-02,  9.5233e-03],
        [ 6.7238e-02,  5.9744e-02,  9.4007e-02],
        [ 8.0144e-02, -1.1156e-01,  5.8624e-02],
        [ 7.2243e-02, -6.9304e-02,  1.0149e-01],
        [ 7.6228e-02, -4.2781e-02,  6.1219e-02],
        [ 7.1194e-02, -4.4469e-02,  9.0559e-02],
        [ 7.7450e-02, -2.2564e-02,  5.8971e-02],
        [ 8.3206e-02, -7.9904e-02,  3.9063e-02],
        [ 7.9188e-02, -5.7035e-02,  4.6772e-02],
        [ 8.9492e-02, -1.3982e-01,  2.2882e-02],
        [ 8.3730e-02,  2.8609e-02,  3.2682e-02],
        [ 9.2256e-02, -1.6471e-01,  5.6358e-03],
        [ 8.4769e-02,  4.2534e-02,  1.3736e-02],
        [ 8.6992e-02,  8.5837e-03,  2.4107e-02],
        [ 7.5407e-02,  3.9864e-02,  4.9808e-02],
        [ 6.8744e-02,  9.0458e-02,  5.5572e-02],
        [ 7.1626e-02, -9.6924e-03,  9.4443e-02],
        [ 3.0596e-02,  1.0990e-01,  4.0513e-01],
        [ 4.5039e-02,  3.0665e-02,  3.7936e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 66
Episode Length = 85
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1393,  1.1411,  1.1456,  1.1361,  1.1222,  1.1195,  1.1416,  1.1412,
         1.1385,  1.1422, -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1492,  1.1602,  1.1589,  1.1413,  1.1585,  1.1478,  1.1419,  1.1464,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1706,  1.1514,  1.1619,  1.1771,
         1.1833,  1.1790,  1.1745,  1.1710,  1.1594,  1.1598,  1.1592,  1.1616,
         1.1676,  1.1713,  1.1754,  1.1682,  1.1636,  1.1624,  1.0000],
       device='cuda:0')
target_q_episode tensor([ 3.8341,  2.9833,  2.0876,  1.1449,  0.1525, -0.8921, -1.9917, -3.1491,
        -4.3675, -5.6500, -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, 12.0557, 11.6376, 11.1975,
        10.7342, 10.2465,  9.7332,  9.1928,  8.6240,  8.0253,  7.3950,  6.7316,
         6.0333,  5.2982,  4.5244,  3.7099,  2.8525,  1.9500,  1.0000],
       device='cuda:0')
target_q tensor([ 1.1393,  1.1411,  1.1456,  1.1361,  1.1222,  1.1195,  1.1416,  1.1412,
         1.1385,  1.1421, -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1492,  1.1602,  1.1589,  1.1413,  1.1585,  1.1478,  1.1419,  1.1464,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1706,  1.1515,  1.1619,  1.1771,
         1.1833,  1.1790,  1.1745,  1.1711,  1.1594,  1.1598,  1.1592,  1.1616,
         1.1676,  1.1713,  1.1754,  1.1682,  1.1636,  1.1624,  1.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.5894e-02, -8.3683e-02,  9.4414e-04],
        [ 9.4660e-02, -7.6824e-02,  1.4684e-03],
        [ 9.3365e-02, -7.4828e-02,  2.0849e-03],
        [ 9.7106e-02, -1.6739e-01,  4.6295e-04],
        [ 9.8460e-02, -2.1323e-01,  1.1709e-04],
        [ 9.8854e-02, -1.7377e-01,  7.5400e-05],
        [ 9.9461e-02, -2.0146e-01,  2.5779e-05],
        [ 9.9005e-02, -1.0033e-01,  6.4909e-05],
        [ 9.8897e-02, -3.3488e-02,  6.5148e-05],
        [ 9.8963e-02, -7.0274e-02,  5.6684e-05],
        [ 9.8531e-02, -3.8194e-02,  1.0964e-04],
        [ 9.8443e-02, -5.6641e-02,  1.1155e-04],
        [ 9.8553e-02, -1.2080e-01,  9.7185e-05],
        [ 9.8858e-02, -1.1505e-01,  7.0482e-05],
        [ 9.8974e-02, -1.0495e-01,  6.5655e-05],
        [ 9.9050e-02, -1.3963e-01,  4.9651e-05],
        [ 9.8607e-02, -1.1532e-01,  1.1930e-04],
        [ 9.9597e-02, -1.9677e-01,  1.7643e-05],
        [ 9.9374e-02, -2.1057e-01,  4.2975e-05],
        [ 9.8822e-02, -1.6230e-01,  1.3152e-04],
        [ 9.9745e-02, -3.2241e-01,  9.2387e-06],
        [ 9.9866e-02, -3.6463e-01,  2.6524e-06],
        [ 9.9843e-02, -3.2600e-01,  3.3081e-06],
        [ 9.9987e-02, -3.9799e-01,  2.9802e-08],
        [ 9.9952e-02, -3.8834e-01,  3.2783e-07],
        [ 9.9983e-02, -3.9773e-01,  2.9802e-08],
        [ 9.9983e-02, -3.9458e-01,  8.9407e-08],
        [ 9.9992e-02, -3.9931e-01,  2.9802e-08],
        [ 9.9936e-02, -3.9159e-01,  1.7881e-06],
        [ 9.9461e-02, -3.3133e-01,  4.0680e-05],
        [ 9.9733e-02, -3.7121e-01,  4.1425e-06],
        [ 9.8104e-02, -1.1013e-01,  2.1631e-04],
        [ 9.4344e-02,  1.5154e-02,  4.4069e-03],
        [ 9.2938e-02,  1.3013e-01,  3.1179e-03],
        [ 9.3176e-02,  8.7695e-02,  2.3668e-03],
        [ 9.0863e-02,  5.2189e-02,  4.3497e-03],
        [ 8.1240e-02,  9.1178e-02,  3.4613e-02],
        [ 5.2275e-02,  1.0269e-01,  4.4737e-01],
        [ 9.1392e-02, -1.0235e-01,  3.4706e-03],
        [ 9.6951e-02, -1.3209e-01,  4.1920e-04],
        [ 9.7543e-02, -1.6077e-01,  3.6353e-04],
        [ 9.6058e-02, -1.1707e-01,  6.9651e-04],
        [ 9.6102e-02, -5.5151e-02,  5.5560e-04],
        [ 9.8971e-02, -3.1586e-01,  8.1271e-05],
        [ 9.9330e-02, -3.0681e-01,  2.9087e-05],
        [ 9.8632e-02, -1.5896e-01,  1.1134e-04],
        [ 9.9409e-02, -3.0291e-01,  2.6822e-05],
        [ 9.8553e-02, -2.0582e-01,  1.2636e-04],
        [ 9.6058e-02,  2.0441e-02,  6.5213e-04],
        [ 9.3623e-02,  6.0574e-02,  1.6402e-03],
        [ 9.5619e-02, -5.3511e-02,  1.0967e-03],
        [ 9.8751e-02, -2.7584e-01,  1.0732e-04],
        [ 9.9447e-02, -3.2131e-01,  2.9445e-05],
        [ 9.8634e-02, -2.1831e-01,  1.4600e-04],
        [ 9.8991e-02, -2.1070e-01,  1.0169e-04],
        [ 9.8703e-02, -7.5287e-02,  1.6892e-04],
        [ 9.6521e-02,  1.4999e-01,  6.1333e-04],
        [ 9.3458e-02,  1.1776e-01,  1.9308e-03],
        [ 9.4667e-02,  9.4525e-02,  1.1352e-03],
        [ 9.6816e-02, -1.4767e-02,  8.6877e-04],
        [ 9.4879e-02,  2.2625e-02,  2.9519e-03],
        [ 9.6687e-02, -2.9291e-03,  1.1735e-03],
        [ 9.7061e-02, -1.1681e-01,  1.4918e-03],
        [ 9.8806e-02, -2.0215e-01,  1.8868e-04],
        [ 9.8523e-02, -2.0161e-01,  2.8247e-04],
        [ 9.6292e-02, -1.7088e-01,  9.4098e-04],
        [ 9.7422e-02, -1.9491e-01,  8.7917e-04],
        [ 9.2374e-02,  1.0011e-02,  5.6058e-03],
        [ 9.3407e-02, -6.1559e-02,  3.3543e-03],
        [ 9.1371e-02, -6.5195e-02,  6.4349e-03],
        [ 9.6038e-02, -2.4971e-01,  2.3354e-03],
        [ 9.8307e-02, -3.3672e-01,  2.8524e-04],
        [ 9.8040e-02, -3.1436e-01,  3.0708e-04],
        [ 9.5241e-02, -2.2374e-01,  1.4545e-03],
        [ 9.4723e-02, -1.7850e-01,  1.2842e-03],
        [ 9.6206e-02, -2.1457e-01,  8.8289e-04],
        [ 9.6659e-02, -2.1150e-01,  9.0754e-04],
        [ 9.2327e-02, -1.2687e-01,  3.1890e-03],
        [ 8.6079e-02,  4.0815e-02,  1.9603e-02],
        [ 9.5042e-02, -1.9784e-01,  5.2516e-03],
        [ 8.2557e-02,  7.7983e-02,  2.9921e-02],
        [ 9.1436e-02,  8.0461e-02,  3.6219e-03],
        [ 7.5490e-02,  5.2216e-02,  6.0197e-02],
        [ 7.9298e-02,  7.6139e-02,  2.9924e-02],
        [ 6.6825e-02,  8.3172e-02,  9.2012e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 67
Episode Length = 99
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1436,   1.1420,  -3.0000,   0.0000,   0.1545,   1.1502,   1.1520,
          1.1470,   1.1467,  -5.0000,   0.0000,   0.0000,   0.0000,   0.1246,
          1.1486,   1.1562,   1.1557,  -6.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.1265,   1.1324,   1.1502,   1.1551, -10.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.1773,   1.1682,   1.1711,   1.1630,   1.1728,   1.1789,   1.1765,
          1.1737,   1.1676,  -3.0000,   0.0000,   0.1370,   1.1695,   1.1766,
          1.1696,  -7.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000], device='cuda:0')
target_q_episode tensor([ -0.7575,  -1.8500,  -3.0000,   0.0000,   0.0000,  -0.3627,  -1.4344,
         -2.5625,  -3.7500,  -5.0000,   0.0000,   0.0000,   0.0000,   0.0000,
         -2.2917,  -3.4650,  -4.7000,  -6.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.0000,  -5.7213,  -7.0750,  -8.5000, -10.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   4.7413,   3.9382,   3.0929,   2.2030,   1.2664,   0.2804,
         -0.7575,  -1.8500,  -3.0000,   0.0000,   0.0000,  -3.1491,  -4.3675,
         -5.6500,  -7.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000], device='cuda:0')
target_q tensor([  1.1436,   1.1420,  -3.0000,   0.0000,   0.1545,   1.1502,   1.1520,
          1.1470,   1.1467,  -5.0000,   0.0000,   0.0000,   0.0000,   0.1246,
          1.1486,   1.1561,   1.1556,  -6.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   0.1265,   1.1324,   1.1502,   1.1551, -10.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.1773,   1.1682,   1.1711,   1.1630,   1.1728,   1.1789,   1.1765,
          1.1737,   1.1675,  -3.0000,   0.0000,   0.1370,   1.1695,   1.1766,
          1.1696,  -7.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.3760e-02, -2.8561e-02,  3.5445e-02],
        [ 8.0435e-02, -4.7180e-02,  2.2744e-02],
        [ 8.7072e-02, -7.2626e-02,  8.7353e-03],
        [ 8.2955e-02, -1.7076e-02,  1.3603e-02],
        [ 8.6976e-02, -4.9737e-02,  9.4841e-03],
        [ 8.8806e-02, -1.4222e-03,  6.1227e-03],
        [ 8.9681e-02,  1.2948e-02,  5.3122e-03],
        [ 8.6728e-02, -1.1764e-02,  8.8100e-03],
        [ 9.4263e-02, -8.9475e-02,  1.3511e-03],
        [ 9.2610e-02, -3.6377e-02,  1.3339e-03],
        [ 9.4255e-02, -5.3205e-02,  1.0114e-03],
        [ 9.3962e-02, -5.3780e-02,  9.5025e-04],
        [ 9.4616e-02, -4.0905e-02,  7.7891e-04],
        [ 9.5902e-02, -7.2334e-02,  5.1376e-04],
        [ 9.7783e-02, -1.0590e-01,  1.3506e-04],
        [ 9.7871e-02, -1.2157e-01,  1.5542e-04],
        [ 9.7969e-02, -7.1837e-02,  1.4728e-04],
        [ 9.7979e-02, -1.3963e-01,  1.8421e-04],
        [ 9.9179e-02, -1.6321e-01,  2.6286e-05],
        [ 9.8812e-02, -1.0628e-01,  4.0650e-05],
        [ 9.9360e-02, -1.8028e-01,  1.5080e-05],
        [ 9.9395e-02, -1.5800e-01,  1.0669e-05],
        [ 9.5926e-02, -4.5368e-03,  7.2151e-04],
        [ 9.7721e-02, -1.7077e-01,  3.2967e-04],
        [ 9.8498e-02, -2.6544e-01,  1.8978e-04],
        [ 9.9139e-02, -2.3421e-01,  6.6936e-05],
        [ 9.9682e-02, -3.8400e-01,  4.7088e-06],
        [ 9.9890e-02, -3.9091e-01,  1.8775e-06],
        [ 9.9338e-02, -3.1309e-01,  7.0274e-05],
        [ 9.9764e-02, -3.8579e-01,  9.8050e-06],
        [ 9.7374e-02,  1.1671e-01,  4.3595e-04],
        [ 9.6666e-02,  1.1016e-01,  4.7708e-04],
        [ 9.5433e-02,  1.3795e-01,  1.7578e-03],
        [ 9.9622e-02, -3.6363e-01,  2.6405e-05],
        [ 9.9096e-02, -3.4410e-01,  1.3885e-04],
        [ 9.9788e-02, -3.6661e-01,  8.2850e-06],
        [ 9.8661e-02, -1.5064e-01,  4.1884e-04],
        [ 9.8211e-02,  8.9177e-02,  7.0229e-04],
        [ 9.4325e-02,  1.2366e-01,  2.2789e-03],
        [ 9.7858e-02, -7.1914e-02,  5.6675e-04],
        [ 8.9304e-02,  3.0190e-02,  1.2134e-02],
        [ 3.2577e-02,  1.5566e-01,  6.8085e-01],
        [ 9.0409e-02, -1.5175e-01,  3.0710e-03],
        [ 9.2143e-02, -1.4386e-01,  2.5668e-03],
        [ 8.5311e-02, -4.7938e-02,  6.5886e-03],
        [ 7.7580e-02, -4.7610e-02,  2.3644e-02],
        [ 9.2236e-02, -1.4994e-01,  2.6136e-03],
        [ 9.5340e-02, -1.6938e-01,  1.0596e-03],
        [ 8.5491e-02, -2.1181e-02,  1.1170e-02],
        [ 9.0465e-02, -6.2557e-02,  3.8482e-03],
        [ 9.7377e-02, -2.7737e-01,  3.7023e-04],
        [ 9.8887e-02, -3.1658e-01,  1.2714e-04],
        [ 8.3912e-02,  6.2460e-02,  1.3223e-02],
        [ 9.2003e-02, -7.3240e-02,  3.2327e-03],
        [ 9.0317e-02,  6.7814e-02,  5.3105e-03],
        [ 9.7412e-02, -1.5499e-01,  3.2499e-04],
        [ 8.7859e-02,  1.3114e-02,  5.7209e-03],
        [ 8.8352e-02,  3.8558e-02,  5.0229e-03],
        [ 7.7783e-02,  6.2612e-02,  2.9638e-02],
        [ 8.5833e-02,  1.1080e-01,  1.2163e-02],
        [ 8.7841e-02, -2.0251e-03,  8.2064e-03],
        [ 7.6174e-02,  7.9932e-02,  2.7382e-02],
        [ 9.7987e-02, -2.4637e-01,  4.1163e-04],
        [ 7.5494e-02,  1.2151e-01,  4.7521e-02],
        [ 9.5427e-02, -2.5706e-02,  7.9167e-04],
        [ 9.0928e-02, -2.1068e-02,  7.8685e-03],
        [ 9.8382e-02, -2.6865e-01,  2.6309e-04],
        [ 9.7583e-02, -3.1897e-01,  6.9892e-04],
        [ 9.8843e-02, -3.2270e-01,  1.1232e-04],
        [ 9.4849e-02, -1.0484e-01,  2.1481e-03],
        [ 9.7365e-02, -7.8842e-02,  7.1669e-04],
        [ 9.9524e-02, -3.5628e-01,  3.0130e-05],
        [ 9.9158e-02, -3.1763e-01,  5.6863e-05],
        [ 9.8857e-02, -2.1298e-01,  1.6540e-04],
        [ 9.2368e-02,  1.5647e-01,  3.4780e-03],
        [ 9.7941e-02, -3.6298e-02,  1.5467e-04],
        [ 9.0194e-02,  6.0600e-02,  7.3503e-03],
        [ 9.4103e-02, -9.2212e-02,  1.9736e-03],
        [ 9.3888e-02, -1.1162e-01,  6.0612e-03],
        [ 9.8790e-02, -3.8151e-01,  5.8144e-05],
        [ 9.9468e-02, -3.8604e-01,  3.6716e-05],
        [ 9.9220e-02, -3.6709e-01,  7.9781e-05],
        [ 9.9766e-02, -3.9353e-01,  3.2425e-05],
        [ 9.9655e-02, -3.9000e-01,  2.9951e-05],
        [ 9.9477e-02, -3.6333e-01,  2.7180e-05],
        [ 9.9627e-02, -3.2797e-01,  1.8597e-05],
        [ 9.8054e-02, -2.9519e-03,  3.1012e-04],
        [ 9.8235e-02, -1.9392e-01,  3.9905e-04],
        [ 9.5154e-02,  2.1000e-02,  2.6039e-03],
        [ 9.8586e-02,  6.1277e-03,  3.1507e-04],
        [ 9.6380e-02, -1.9930e-01,  1.1519e-03],
        [ 9.7433e-02, -7.8231e-02,  1.1279e-03],
        [ 9.5959e-02, -2.0463e-01,  1.3420e-03],
        [ 9.4601e-02, -8.4743e-02,  2.8218e-03],
        [ 9.4281e-02,  4.7806e-02,  3.9683e-03],
        [ 9.5568e-02, -1.3206e-01,  3.2213e-03],
        [ 9.2742e-02, -4.4431e-02,  7.8612e-03],
        [ 9.2437e-02,  3.0479e-03,  7.3641e-03],
        [ 9.0827e-02,  2.0016e-02,  2.5161e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 68
Episode Length = 99
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1233,  1.1185,  1.1200, -4.0000,  0.0000,  0.0000,  0.1191,  1.1223,
         1.1298,  1.1454,  1.1398,  1.1574,  1.1457,  1.1332,  1.1405,  1.1561,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1661,  1.1401,  1.1388,  1.1426,
         1.1461,  1.1282,  1.1354,  1.1363, -5.0000,  0.0000,  0.0000,  0.0000,
         0.1579,  1.1364,  1.1455,  1.1493,  1.1732, -4.0000,  0.0000,  0.0000,
         0.1858,  1.1659,  1.1697,  1.1764,  1.1429,  1.1450,  1.1574,  1.1472,
        -4.0000,  0.0000,  0.0000,  0.1766,  1.1755,  1.1458,  1.1600,  1.1538,
         1.1696,  1.1672,  1.1620,  1.1542,  1.0000], device='cuda:0')
target_q_episode tensor([-0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  4.2438,
         3.4145,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.5416,  1.6227,  0.6555,
        -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,
         0.0000,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000,
        -4.0000,  0.0000,  0.0000,  0.0000,  7.3950,  6.7316,  6.0333,  5.2982,
         4.5244,  3.7099,  2.8525,  1.9500,  1.0000], device='cuda:0')
target_q tensor([ 1.1233,  1.1185,  1.1200, -4.0000,  0.0000,  0.0000,  0.1191,  1.1223,
         1.1298,  1.1454,  1.1398,  1.1574,  1.1457,  1.1332,  1.1405,  1.1561,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1661,  1.1401,  1.1388,  1.1426,
         1.1461,  1.1282,  1.1354,  1.1363, -5.0000,  0.0000,  0.0000,  0.0000,
         0.1579,  1.1364,  1.1455,  1.1493,  1.1732, -4.0000,  0.0000,  0.0000,
         0.1858,  1.1659,  1.1697,  1.1764,  1.1429,  1.1450,  1.1574,  1.1472,
        -4.0000,  0.0000,  0.0000,  0.1766,  1.1755,  1.1458,  1.1600,  1.1538,
         1.1696,  1.1672,  1.1620,  1.1542,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.2336e-02, -7.2094e-02,  3.1256e-03],
        [ 9.5014e-02, -6.1872e-02,  1.1803e-03],
        [ 9.4763e-02, -5.9258e-02,  1.4256e-03],
        [ 9.7469e-02, -1.1646e-01,  4.1103e-04],
        [ 9.8962e-02, -1.5385e-01,  6.7651e-05],
        [ 9.8743e-02, -1.5133e-01,  8.7649e-05],
        [ 9.8952e-02, -1.5473e-01,  7.3761e-05],
        [ 9.8644e-02, -6.5786e-02,  1.1972e-04],
        [ 9.8542e-02, -3.0561e-02,  1.1709e-04],
        [ 9.9182e-02, -6.4849e-02,  4.5031e-05],
        [ 9.8597e-02, -1.9419e-02,  1.0681e-04],
        [ 9.8956e-02, -5.0208e-02,  6.0678e-05],
        [ 9.8345e-02, -4.1170e-02,  1.6579e-04],
        [ 9.8686e-02, -5.2121e-02,  9.5904e-05],
        [ 9.8120e-02, -4.3987e-02,  1.7917e-04],
        [ 9.9383e-02, -1.5698e-01,  2.4259e-05],
        [ 9.9099e-02, -1.1193e-01,  5.4717e-05],
        [ 9.9226e-02, -1.2672e-01,  5.6922e-05],
        [ 9.9296e-02, -1.5652e-01,  5.8591e-05],
        [ 9.9397e-02, -1.8522e-01,  5.2780e-05],
        [ 9.9620e-02, -2.6663e-01,  1.9312e-05],
        [ 9.9916e-02, -3.5954e-01,  1.0431e-06],
        [ 9.9944e-02, -3.7403e-01,  4.4703e-07],
        [ 9.9986e-02, -3.9493e-01,  5.9605e-08],
        [ 9.9983e-02, -3.9473e-01,  5.9605e-08],
        [ 9.9984e-02, -3.9511e-01,  5.9605e-08],
        [ 9.9984e-02, -3.9644e-01,  5.9605e-08],
        [ 9.9989e-02, -3.9828e-01,  2.9802e-08],
        [ 9.9892e-02, -3.8337e-01,  1.8477e-06],
        [ 9.9543e-02, -3.3312e-01,  3.1114e-05],
        [ 9.9810e-02, -3.5241e-01,  2.8908e-06],
        [ 9.8671e-02, -1.8640e-01,  1.1003e-04],
        [ 9.8380e-02, -3.4635e-02,  5.4258e-04],
        [ 9.2839e-02,  2.1053e-01,  4.3373e-03],
        [ 9.0010e-02,  1.8195e-01,  6.2720e-03],
        [ 8.7131e-02,  1.5634e-01,  1.1829e-02],
        [ 7.3403e-02,  1.2487e-01,  8.5285e-02],
        [ 4.8106e-02,  8.0980e-02,  5.7270e-01],
        [ 8.5407e-02, -6.7982e-02,  1.1121e-02],
        [ 8.5940e-02, -4.7415e-02,  9.8224e-03],
        [ 9.1669e-02, -7.0703e-02,  3.5819e-03],
        [ 9.9255e-02, -3.1997e-01,  4.7952e-05],
        [ 9.9205e-02, -2.5324e-01,  5.0336e-05],
        [ 9.8902e-02, -1.4614e-01,  6.5684e-05],
        [ 9.6218e-02, -5.9672e-02,  6.1348e-04],
        [ 9.1762e-02,  5.1966e-02,  2.0932e-03],
        [ 8.9446e-02,  1.1733e-01,  3.6237e-03],
        [ 9.1734e-02, -2.8700e-02,  3.0802e-03],
        [ 9.6377e-02, -1.6841e-01,  8.9934e-04],
        [ 9.2328e-02,  9.7724e-04,  3.6449e-03],
        [ 9.4440e-02, -3.7823e-02,  2.2329e-03],
        [ 9.5017e-02, -3.2801e-02,  1.4831e-03],
        [ 8.5371e-02,  1.3845e-01,  8.6189e-03],
        [ 9.1430e-02,  1.7854e-02,  3.5590e-03],
        [ 8.9260e-02, -5.0928e-03,  7.6355e-03],
        [ 8.3529e-02,  5.0266e-02,  1.7317e-02],
        [ 8.5773e-02, -2.9911e-02,  2.0989e-02],
        [ 9.9059e-02, -1.9276e-01,  1.2520e-04],
        [ 9.8071e-02, -9.1661e-02,  9.4998e-04],
        [ 9.7712e-02,  1.9734e-03,  5.3325e-04],
        [ 9.6446e-02,  8.1201e-02,  5.9965e-04],
        [ 9.8376e-02,  1.7947e-02,  1.9658e-04],
        [ 9.8276e-02,  5.6854e-03,  1.9982e-04],
        [ 9.8828e-02, -8.8037e-02,  1.5447e-04],
        [ 9.8356e-02, -1.8192e-01,  5.2291e-04],
        [ 9.9729e-02, -3.2902e-01,  1.2070e-05],
        [ 9.9818e-02, -3.6184e-01,  5.6326e-06],
        [ 9.9933e-02, -3.8299e-01,  1.2815e-06],
        [ 9.9099e-02, -6.6141e-02,  7.3463e-05],
        [ 9.9561e-02, -2.2183e-01,  1.4454e-05],
        [ 9.9852e-02, -3.8184e-01,  4.2617e-06],
        [ 9.9823e-02, -3.5748e-01,  6.1393e-06],
        [ 9.9867e-02, -3.8367e-01,  4.4107e-06],
        [ 9.9855e-02, -3.7422e-01,  2.8312e-06],
        [ 9.9058e-02, -3.3622e-01,  4.6641e-05],
        [ 9.9651e-02, -3.5710e-01,  1.2368e-05],
        [ 9.9894e-02, -3.8503e-01,  2.2054e-06],
        [ 9.9980e-02, -3.9935e-01,  1.4901e-07],
        [ 9.9215e-02, -2.8929e-01,  9.5725e-05],
        [ 9.9616e-02, -3.6015e-01,  1.6481e-05],
        [ 9.6359e-02,  3.5518e-02,  1.3312e-03],
        [ 9.9103e-02, -2.4617e-01,  7.2181e-05],
        [ 9.8540e-02, -1.6076e-01,  2.7472e-04],
        [ 9.7691e-02, -1.7856e-01,  7.3719e-04],
        [ 9.6114e-02, -1.5925e-01,  1.1948e-03],
        [ 9.8998e-02, -2.9661e-01,  1.1373e-04],
        [ 9.9681e-02, -3.7391e-01,  1.3530e-05],
        [ 9.8042e-02, -2.7618e-01,  5.7027e-04],
        [ 9.9268e-02, -3.1823e-01,  1.0002e-04],
        [ 9.1625e-02,  1.9001e-02,  1.4728e-02],
        [ 9.5273e-02,  6.3536e-02,  4.5929e-03],
        [ 8.3193e-02,  1.9505e-01,  4.0354e-02],
        [ 6.6503e-02,  1.7451e-01,  1.5463e-01],
        [ 8.2243e-02,  1.0442e-01,  8.0813e-02],
        [ 7.1809e-02,  1.3457e-01,  1.7594e-01],
        [ 8.2884e-02, -4.5804e-02,  1.2996e-01],
        [ 6.1184e-02,  8.5217e-02,  2.5400e-01],
        [ 5.9388e-02,  8.5074e-02,  3.5606e-01],
        [ 6.2877e-02,  7.5322e-02,  2.5211e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 69
Episode Length = 100
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1340,  1.1326,  1.1231,  1.1408,  1.1537,  1.1389,  1.1446,  1.1445,
         1.1356,  1.1399,  1.1329,  1.1293,  1.1437,  1.1499,  1.1501,  1.1457,
        -4.0000,  0.0000,  0.0000,  0.1572,  1.1622,  1.1530,  1.1573,  1.1555,
        -4.0000,  0.0000,  0.0000,  0.1334,  1.1552,  1.1434,  1.1396,  1.1415,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1421,  1.1536,  1.1591,  1.1556,
         1.1538, -5.0000,  0.0000,  0.0000,  0.0000,  0.1458,  1.1501,  1.1589,
         1.1508,  1.1539, -5.0000,  0.0000,  0.0000,  0.0000,  0.1437,  1.1412,
        -2.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 9.4370,  8.8810,  8.2958,  7.6798,  7.0314,  6.3488,  5.6303,  4.8740,
         4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000,
        -4.0000,  0.0000,  0.0000,  0.0000,  0.4519, -0.5770, -1.6600, -2.8000,
        -4.0000,  0.0000,  0.0000,  0.0000, -0.3627, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3627, -1.4344, -2.5625,
        -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3627, -1.4344,
        -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.9000,
        -2.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1340,  1.1326,  1.1231,  1.1408,  1.1537,  1.1389,  1.1446,  1.1445,
         1.1356,  1.1399,  1.1329,  1.1293,  1.1437,  1.1499,  1.1501,  1.1457,
        -4.0000,  0.0000,  0.0000,  0.1572,  1.1622,  1.1530,  1.1573,  1.1555,
        -4.0000,  0.0000,  0.0000,  0.1334,  1.1552,  1.1434,  1.1396,  1.1415,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1421,  1.1536,  1.1591,  1.1556,
         1.1538, -5.0000,  0.0000,  0.0000,  0.0000,  0.1458,  1.1501,  1.1588,
         1.1508,  1.1539, -5.0000,  0.0000,  0.0000,  0.0000,  0.1437,  1.1411,
        -2.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.7288e-02, -7.4645e-02,  7.0511e-03],
        [ 8.7585e-02, -2.1609e-02,  6.5615e-03],
        [ 8.7650e-02, -5.7991e-02,  7.0845e-03],
        [ 8.9197e-02, -8.3195e-02,  5.9077e-03],
        [ 8.6304e-02, -1.3375e-03,  5.7841e-03],
        [ 9.2868e-02, -2.7550e-02,  1.6550e-03],
        [ 9.7935e-02, -1.0477e-01,  1.6117e-04],
        [ 9.5372e-02, -3.9554e-02,  1.2775e-03],
        [ 9.7300e-02, -2.1544e-02,  6.0424e-04],
        [ 9.6945e-02, -9.0034e-03,  5.6234e-04],
        [ 9.6949e-02,  4.4225e-02,  5.7945e-04],
        [ 9.6740e-02, -1.9953e-02,  5.0277e-04],
        [ 9.9083e-02, -1.1759e-01,  3.9309e-05],
        [ 9.9080e-02, -9.4144e-02,  3.6448e-05],
        [ 9.8800e-02, -8.9327e-02,  4.5657e-05],
        [ 9.9211e-02, -9.9348e-02,  1.9729e-05],
        [ 9.9382e-02, -1.0558e-01,  1.6391e-05],
        [ 9.9479e-02, -1.3336e-01,  1.3560e-05],
        [ 9.9567e-02, -1.4585e-01,  8.9109e-06],
        [ 9.9491e-02, -1.4744e-01,  1.1325e-05],
        [ 9.9732e-02, -1.7715e-01,  3.7253e-06],
        [ 9.9763e-02, -1.7367e-01,  3.4273e-06],
        [ 9.9830e-02, -2.3275e-01,  2.1458e-06],
        [ 9.9890e-02, -2.8522e-01,  9.8348e-07],
        [ 9.9835e-02, -2.1407e-01,  2.3246e-06],
        [ 9.9622e-02, -1.3738e-01,  7.3612e-06],
        [ 9.9533e-02, -6.8629e-02,  1.1206e-05],
        [ 9.9338e-02, -4.7490e-02,  2.5988e-05],
        [ 9.9497e-02, -1.0783e-01,  1.4633e-05],
        [ 9.9588e-02, -1.0354e-01,  1.7077e-05],
        [ 9.9730e-02, -9.2831e-02,  6.3479e-06],
        [ 9.9190e-02,  1.8731e-02,  6.4373e-05],
        [ 9.9518e-02, -3.1028e-02,  2.5362e-05],
        [ 9.9459e-02, -2.1128e-02,  3.4839e-05],
        [ 9.9266e-02, -3.0787e-02,  7.7635e-05],
        [ 9.7405e-02,  5.1312e-02,  1.0796e-03],
        [ 9.7614e-02,  4.8428e-02,  9.4384e-04],
        [ 9.8034e-02,  9.3582e-03,  7.0080e-04],
        [ 9.5699e-02,  8.4067e-02,  4.2497e-03],
        [ 8.3579e-02,  8.9440e-02,  6.5684e-02],
        [ 5.3842e-02,  1.2863e-01,  4.3649e-01],
        [ 4.5835e-02,  1.3437e-01,  5.3563e-01],
        [ 7.6695e-02, -4.5716e-02,  3.9797e-02],
        [ 8.0225e-02, -4.8832e-02,  2.0103e-02],
        [ 8.8614e-02, -6.5033e-02,  6.6325e-03],
        [ 8.6140e-02, -3.5193e-02,  5.9923e-03],
        [ 8.8058e-02,  6.1535e-03,  6.1806e-03],
        [ 9.7473e-02, -1.5036e-01,  3.0687e-04],
        [ 9.3848e-02, -6.5577e-02,  1.5225e-03],
        [ 9.5078e-02, -7.3400e-02,  1.0509e-03],
        [ 8.7090e-02,  2.1284e-02,  7.3278e-03],
        [ 8.3569e-02,  7.5001e-02,  1.2213e-02],
        [ 8.9089e-02,  3.7011e-02,  5.5713e-03],
        [ 8.4684e-02,  5.1532e-02,  1.0481e-02],
        [ 9.6739e-02, -1.6879e-01,  4.7174e-04],
        [ 9.7985e-02, -1.7559e-01,  2.9254e-04],
        [ 9.8126e-02, -1.1202e-01,  1.3313e-04],
        [ 9.7158e-02, -1.3975e-01,  4.4796e-04],
        [ 9.5327e-02,  2.7670e-02,  8.9285e-04],
        [ 9.3479e-02,  6.2926e-02,  1.7590e-03],
        [ 9.3965e-02,  4.9769e-02,  2.7996e-03],
        [ 9.6234e-02, -7.0931e-02,  9.7632e-04],
        [ 9.8658e-02, -2.2551e-01,  1.7744e-04],
        [ 9.8761e-02, -2.2220e-01,  1.4099e-04],
        [ 9.9791e-02, -3.5028e-01,  5.6922e-06],
        [ 9.9473e-02, -1.7359e-01,  1.8567e-05],
        [ 9.9845e-02, -3.4840e-01,  1.6391e-06],
        [ 9.9926e-02, -3.9261e-01,  5.0664e-07],
        [ 9.9888e-02, -3.1630e-01,  7.7486e-07],
        [ 9.9640e-02, -2.9543e-01,  8.9407e-06],
        [ 9.9534e-02, -3.1281e-01,  1.1325e-05],
        [ 9.9669e-02, -3.5836e-01,  9.7752e-06],
        [ 9.9700e-02, -3.6583e-01,  4.8280e-06],
        [ 9.9287e-02, -3.1768e-01,  3.4332e-05],
        [ 9.2800e-02,  1.9658e-01,  3.7910e-03],
        [ 9.7584e-02, -1.6488e-01,  8.0839e-04],
        [ 9.5439e-02, -3.6723e-02,  1.8882e-03],
        [ 9.6967e-02,  4.0478e-03,  9.5871e-04],
        [ 9.3437e-02,  1.0413e-01,  5.5933e-03],
        [ 8.8453e-02,  1.7763e-01,  1.8677e-02],
        [ 8.1980e-02,  2.0830e-01,  6.3644e-02],
        [ 9.3749e-02,  2.4711e-02,  5.1938e-03],
        [ 9.8161e-02, -1.8133e-01,  3.9920e-04],
        [ 8.6750e-02,  1.2519e-01,  4.0206e-02],
        [ 8.3075e-02,  1.0941e-01,  5.6651e-02],
        [ 9.6720e-02, -7.7469e-02,  1.1488e-03],
        [ 8.9249e-02,  7.6951e-02,  2.8433e-02],
        [ 8.0702e-02,  6.3619e-02,  1.1490e-01],
        [ 7.1749e-02,  5.2872e-02,  1.9808e-01],
        [ 9.1062e-02, -1.7134e-02,  1.4058e-02],
        [ 8.9976e-02,  3.8335e-02,  9.7958e-03],
        [ 9.8419e-02, -8.9674e-02,  4.6948e-04],
        [ 9.5530e-02, -5.6633e-02,  2.6684e-03],
        [ 9.3212e-02,  9.7318e-03,  6.6344e-03],
        [ 9.5508e-02, -2.6212e-02,  2.9626e-03],
        [ 9.7258e-02, -1.4343e-01,  7.1201e-04],
        [ 9.7877e-02, -2.7566e-01,  1.0883e-03],
        [ 9.0930e-02,  3.6158e-02,  1.4064e-02],
        [ 9.5373e-02, -1.8519e-01,  7.0202e-03],
        [ 8.7491e-02, -1.9639e-03,  2.5966e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 70
Episode Length = 99
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1418,  1.1433,  1.1373, -3.0000,  0.0000,  0.1111,  1.1248,  1.1215,
         1.1186,  1.1284,  1.1359,  1.1345,  1.1244,  1.1283, -4.0000,  0.0000,
         0.0000,  0.1563,  1.1483,  1.1522,  1.1557, -3.0000,  0.0000,  0.1167,
         1.1429,  1.1426,  1.1413,  1.1374,  1.1522,  1.1472, -3.0000,  0.0000,
         0.1447,  1.1522,  1.1621,  1.1566,  1.1660,  1.1585,  1.1510,  1.1439,
         1.1411,  1.1510, -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1658,  1.1518,  1.1488,  1.1484,  1.1501,  1.1631,  1.1615,  1.1549,
         1.1494, -4.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 0.2804, -0.7575, -1.8500, -3.0000,  0.0000,  0.0000,  4.0779,  3.2399,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000,  0.2804, -0.7575, -1.8500, -3.0000,  0.0000,  0.0000,
         3.0929,  2.2030,  1.2664,  0.2804, -0.7575, -1.8500, -3.0000,  0.0000,
         0.0000,  2.9833,  2.0876,  1.1449,  0.1525, -0.8921, -1.9917, -3.1491,
        -4.3675, -5.6500, -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  4.0779,  3.2399,  2.3578,  1.4293,  0.4519, -0.5770, -1.6600,
        -2.8000, -4.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1418,  1.1433,  1.1373, -3.0000,  0.0000,  0.1111,  1.1248,  1.1215,
         1.1186,  1.1284,  1.1359,  1.1345,  1.1244,  1.1283, -4.0000,  0.0000,
         0.0000,  0.1563,  1.1483,  1.1522,  1.1556, -3.0000,  0.0000,  0.1167,
         1.1429,  1.1426,  1.1413,  1.1374,  1.1522,  1.1472, -3.0000,  0.0000,
         0.1447,  1.1522,  1.1621,  1.1566,  1.1659,  1.1585,  1.1510,  1.1439,
         1.1411,  1.1510, -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.1658,  1.1518,  1.1488,  1.1484,  1.1501,  1.1631,  1.1615,  1.1549,
         1.1494, -4.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.6003e-02, -6.9135e-02,  9.3010e-04],
        [ 9.5442e-02, -3.0856e-02,  1.1416e-03],
        [ 9.8475e-02, -9.5434e-02,  1.6299e-04],
        [ 9.8732e-02, -1.1881e-01,  1.0082e-04],
        [ 9.9233e-02, -1.5057e-01,  4.6283e-05],
        [ 9.8706e-02, -1.1172e-01,  9.2864e-05],
        [ 9.9124e-02, -9.5800e-02,  5.3138e-05],
        [ 9.9415e-02, -1.3358e-01,  2.2501e-05],
        [ 9.9224e-02, -3.2916e-02,  4.1276e-05],
        [ 9.9156e-02, -1.2313e-02,  5.9992e-05],
        [ 9.8523e-02, -1.0603e-02,  1.3056e-04],
        [ 9.8745e-02, -1.0203e-02,  7.5787e-05],
        [ 9.8194e-02, -6.4115e-02,  1.7580e-04],
        [ 9.9218e-02, -7.7880e-02,  3.4004e-05],
        [ 9.8827e-02, -4.4292e-02,  7.7665e-05],
        [ 9.9222e-02, -9.6854e-02,  4.4078e-05],
        [ 9.9320e-02, -6.8509e-02,  4.0740e-05],
        [ 9.8846e-02, -5.1114e-02,  9.4324e-05],
        [ 9.8499e-02, -9.7912e-02,  1.8996e-04],
        [ 9.9530e-02, -2.2637e-01,  2.4319e-05],
        [ 9.9494e-02, -1.8074e-01,  3.0428e-05],
        [ 9.9908e-02, -3.4771e-01,  1.3709e-06],
        [ 9.9972e-02, -3.8423e-01,  1.7881e-07],
        [ 9.9960e-02, -3.8151e-01,  2.6822e-07],
        [ 9.9988e-02, -3.9505e-01,  2.9802e-08],
        [ 9.9981e-02, -3.9115e-01,  5.9605e-08],
        [ 9.9985e-02, -3.9673e-01,  5.9605e-08],
        [ 9.9994e-02, -3.9889e-01,  2.9802e-08],
        [ 9.9958e-02, -3.9312e-01,  4.1723e-07],
        [ 9.9859e-02, -3.8826e-01,  3.6955e-06],
        [ 9.9811e-02, -3.1354e-01,  4.3511e-06],
        [ 9.8962e-02, -6.9718e-02,  6.5178e-05],
        [ 9.8513e-02,  4.0178e-02,  5.2163e-04],
        [ 9.3161e-02,  2.0760e-01,  3.3080e-03],
        [ 9.2128e-02,  1.9871e-01,  4.9779e-03],
        [ 8.2862e-02,  1.6125e-01,  2.9275e-02],
        [ 7.3958e-02,  1.5700e-01,  8.1512e-02],
        [ 1.4409e-02,  1.6578e-01,  8.8732e-01],
        [ 9.5515e-02, -5.4955e-02,  1.0274e-03],
        [ 9.2147e-02, -1.1344e-02,  2.5228e-03],
        [ 9.4829e-02, -5.7987e-02,  1.2611e-03],
        [ 9.2517e-02, -7.2165e-02,  2.7277e-03],
        [ 9.4675e-02, -7.0686e-02,  1.2638e-03],
        [ 9.7343e-02, -7.5723e-02,  3.8666e-04],
        [ 9.9560e-02, -2.7075e-01,  1.3918e-05],
        [ 9.7616e-02, -1.5029e-01,  4.4650e-04],
        [ 9.8697e-02, -1.5796e-01,  1.1763e-04],
        [ 9.4222e-02,  9.3987e-03,  1.8434e-03],
        [ 9.0454e-02,  8.3961e-02,  3.1448e-03],
        [ 8.9005e-02,  1.2811e-02,  4.8619e-03],
        [ 8.9259e-02,  4.1438e-02,  5.6923e-03],
        [ 8.3595e-02,  4.0588e-02,  1.2412e-02],
        [ 8.1524e-02,  4.5592e-02,  2.0026e-02],
        [ 9.0131e-02,  1.0870e-02,  6.4462e-03],
        [ 7.6721e-02,  9.6551e-02,  4.0580e-02],
        [ 8.1653e-02,  9.0353e-05,  2.4465e-02],
        [ 9.8916e-02, -2.2602e-01,  1.1700e-04],
        [ 9.9919e-02, -3.5647e-01,  1.2815e-06],
        [ 9.9644e-02, -2.7911e-01,  2.9683e-05],
        [ 9.9122e-02,  3.2723e-02,  5.3138e-05],
        [ 9.8186e-02,  1.2440e-01,  3.0941e-04],
        [ 9.8986e-02,  6.4284e-02,  7.2777e-05],
        [ 9.9659e-02, -2.2213e-01,  1.7792e-05],
        [ 9.9680e-02, -3.2303e-01,  1.8418e-05],
        [ 9.9764e-02, -2.9350e-01,  7.7486e-06],
        [ 9.9742e-02, -2.8552e-01,  1.1921e-05],
        [ 9.9880e-02, -3.0928e-01,  2.1458e-06],
        [ 9.9011e-02, -1.0034e-01,  9.7007e-05],
        [ 9.9817e-02, -2.3937e-01,  4.6790e-06],
        [ 9.9973e-02, -3.8551e-01,  1.1921e-07],
        [ 9.9672e-02, -2.4414e-01,  1.9819e-05],
        [ 9.6565e-02, -5.6736e-02,  1.1298e-03],
        [ 9.9404e-02, -3.2318e-01,  7.8499e-05],
        [ 9.9968e-02, -3.9553e-01,  2.6822e-07],
        [ 9.9832e-02, -3.7964e-01,  3.6657e-06],
        [ 9.9973e-02, -3.9837e-01,  1.1921e-07],
        [ 9.9943e-02, -3.9330e-01,  1.4603e-06],
        [ 9.9961e-02, -3.9397e-01,  7.1526e-07],
        [ 9.9978e-02, -3.9875e-01,  3.2783e-07],
        [ 9.9973e-02, -3.9337e-01,  3.2783e-07],
        [ 9.9976e-02, -3.9304e-01,  3.2783e-07],
        [ 9.9939e-02, -3.8058e-01,  1.4603e-06],
        [ 9.9985e-02, -3.9757e-01,  1.4901e-07],
        [ 9.9973e-02, -3.9869e-01,  4.1723e-07],
        [ 9.9809e-02, -3.7629e-01,  9.5069e-06],
        [ 9.9922e-02, -3.9608e-01,  3.1888e-06],
        [ 9.9922e-02, -3.7899e-01,  1.9670e-06],
        [ 9.9627e-02, -2.3838e-01,  2.3961e-05],
        [ 9.6757e-02,  1.8474e-01,  1.9173e-03],
        [ 9.3657e-02,  1.5349e-01,  1.0770e-02],
        [ 9.8278e-02, -5.8075e-02,  1.2251e-03],
        [ 9.7027e-02, -7.6162e-02,  4.0897e-03],
        [ 8.4405e-02,  1.6569e-01,  8.5079e-02],
        [ 8.1697e-02,  9.7525e-02,  1.1340e-01],
        [ 7.9752e-02,  1.8823e-01,  1.3802e-01],
        [ 7.9337e-02,  1.3374e-01,  1.5469e-01],
        [ 6.4960e-02,  6.8504e-02,  3.6158e-01],
        [ 7.0762e-02,  1.0923e-01,  1.9632e-01],
        [ 4.0546e-02,  1.3431e-01,  7.0265e-01]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Saving checkpoint
Run No. 71
Episode Length = 100
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1317,  1.1229,  1.1146,  1.1301,  1.1269,  1.1392,  1.1442,  1.1340,
         1.1276,  1.1272,  1.1391,  1.1356,  1.1328,  1.1393,  1.1375,  1.1451,
        -3.0000,  0.0000,  0.1207,  1.1406,  1.1342,  1.1403,  1.1492,  1.1369,
         1.1375,  1.1424,  1.1398,  1.1362,  1.1470,  1.1383,  1.1345, -7.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1678,  1.1601,  1.1641,
         1.1601,  1.1507,  1.1486,  1.1579,  1.1557,  1.1529,  1.1409,  1.1442,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1677,  1.1620,  1.1500,  1.1372,
        -2.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 9.8771,  9.3443,  8.7835,  8.1931,  7.5717,  6.9176,  6.2291,  5.5043,
         4.7413,  3.9382,  3.0929,  2.2030,  1.2664,  0.2804, -0.7575, -1.8500,
        -3.0000,  0.0000,  0.0000,  5.4103,  4.6424,  3.8341,  2.9833,  2.0876,
         1.1449,  0.1525, -0.8921, -1.9917, -3.1491, -4.3675, -5.6500, -7.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  5.0316,  4.2438,
         3.4145,  2.5416,  1.6227,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.1377,  0.1450, -0.9000,
        -2.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1317,  1.1229,  1.1146,  1.1301,  1.1269,  1.1392,  1.1442,  1.1340,
         1.1276,  1.1272,  1.1391,  1.1356,  1.1328,  1.1393,  1.1375,  1.1451,
        -3.0000,  0.0000,  0.1207,  1.1406,  1.1342,  1.1403,  1.1492,  1.1369,
         1.1375,  1.1424,  1.1398,  1.1362,  1.1470,  1.1383,  1.1345, -7.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1678,  1.1601,  1.1641,
         1.1601,  1.1507,  1.1486,  1.1579,  1.1557,  1.1529,  1.1409,  1.1442,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1677,  1.1620,  1.1500,  1.1372,
        -2.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 7.7708e-02, -2.9829e-03,  2.5842e-02],
        [ 8.1905e-02, -3.2597e-02,  1.5224e-02],
        [ 7.7969e-02,  2.7054e-02,  2.3766e-02],
        [ 8.5833e-02,  9.1877e-03,  1.2190e-02],
        [ 8.8184e-02,  3.3897e-02,  7.9948e-03],
        [ 8.9902e-02,  3.8474e-02,  5.1095e-03],
        [ 9.3562e-02,  2.0662e-02,  2.5374e-03],
        [ 8.5509e-02,  2.8741e-02,  1.1090e-02],
        [ 9.2228e-02,  7.1666e-03,  2.6968e-03],
        [ 8.6324e-02,  4.5834e-02,  6.5226e-03],
        [ 9.3816e-02, -5.5608e-04,  1.1137e-03],
        [ 9.1443e-02,  3.0913e-02,  2.2048e-03],
        [ 9.4526e-02, -2.7899e-03,  8.6293e-04],
        [ 9.4266e-02,  2.3531e-04,  1.1355e-03],
        [ 9.5960e-02,  7.8869e-03,  5.1370e-04],
        [ 9.7501e-02, -3.0509e-02,  2.0003e-04],
        [ 9.7543e-02, -2.8173e-02,  1.8153e-04],
        [ 9.9309e-02, -9.6977e-02,  1.8805e-05],
        [ 9.9185e-02, -7.9257e-02,  3.2634e-05],
        [ 9.9325e-02, -1.0651e-01,  2.2739e-05],
        [ 9.9346e-02, -8.3341e-02,  1.6868e-05],
        [ 9.8829e-02,  1.7440e-02,  4.8250e-05],
        [ 9.5335e-02,  3.4502e-02,  1.1434e-03],
        [ 9.6822e-02, -5.8166e-02,  8.0991e-04],
        [ 9.7643e-02, -1.2628e-01,  3.0416e-04],
        [ 9.7885e-02, -1.0128e-01,  3.7372e-04],
        [ 9.9486e-02, -3.6216e-01,  1.3322e-05],
        [ 9.9723e-02, -3.6853e-01,  9.2685e-06],
        [ 9.9002e-02, -1.9517e-01,  1.4573e-04],
        [ 9.9827e-02, -3.7634e-01,  4.4703e-06],
        [ 9.8784e-02,  1.0065e-01,  1.0207e-04],
        [ 9.7055e-02,  1.8139e-01,  4.1422e-04],
        [ 9.6198e-02,  1.5453e-01,  1.0417e-03],
        [ 9.9798e-02, -3.4027e-01,  8.1360e-06],
        [ 9.8777e-02, -1.8061e-01,  2.9525e-04],
        [ 9.9417e-02, -2.0087e-01,  9.5785e-05],
        [ 9.8393e-02, -2.5986e-02,  5.9018e-04],
        [ 9.8784e-02,  1.3951e-01,  2.5281e-04],
        [ 9.4474e-02,  1.8881e-01,  2.9503e-03],
        [ 9.4957e-02,  1.0117e-01,  2.6280e-03],
        [ 8.6996e-02,  7.5297e-02,  2.2664e-02],
        [ 4.0124e-02,  1.7677e-01,  6.4631e-01],
        [ 7.2756e-02, -1.2962e-02,  3.2241e-02],
        [ 7.9473e-02,  4.1967e-03,  1.7246e-02],
        [ 8.4898e-02, -1.2142e-02,  9.9795e-03],
        [ 9.5113e-02, -1.0346e-01,  1.6822e-03],
        [ 9.5482e-02, -1.0790e-01,  1.2553e-03],
        [ 9.3101e-02,  1.1581e-02,  2.4890e-03],
        [ 9.3028e-02, -2.0424e-02,  2.6971e-03],
        [ 9.0584e-02,  4.8645e-02,  4.1064e-03],
        [ 8.8592e-02,  1.0726e-01,  3.6337e-03],
        [ 9.3320e-02,  5.1092e-02,  1.1240e-03],
        [ 9.0160e-02,  7.8321e-02,  5.4319e-03],
        [ 8.9207e-02,  5.6577e-02,  7.6381e-03],
        [ 8.5836e-02,  6.4237e-02,  1.2751e-02],
        [ 8.3385e-02,  6.1432e-02,  1.7537e-02],
        [ 8.9141e-02,  4.2933e-02,  8.8243e-03],
        [ 9.1116e-02,  1.8988e-02,  3.3412e-03],
        [ 9.2085e-02,  3.3127e-02,  3.1203e-03],
        [ 8.7368e-02,  7.6308e-02,  8.4893e-03],
        [ 9.7222e-02, -9.0045e-04,  9.4593e-04],
        [ 9.8591e-02, -2.9522e-01,  1.7291e-04],
        [ 9.9664e-02, -3.5334e-01,  8.3745e-06],
        [ 9.8467e-02, -2.4634e-01,  1.1927e-04],
        [ 9.9187e-02, -2.8043e-01,  3.4750e-05],
        [ 9.8633e-02, -2.1524e-01,  7.1496e-05],
        [ 9.8960e-02, -1.7836e-01,  3.8207e-05],
        [ 9.9438e-02, -3.1135e-01,  1.4246e-05],
        [ 9.8968e-02, -1.6808e-01,  5.2333e-05],
        [ 9.9172e-02, -2.0199e-01,  3.7014e-05],
        [ 9.9936e-02, -3.9115e-01,  8.0466e-07],
        [ 9.9875e-02, -3.7413e-01,  1.9968e-06],
        [ 9.9691e-02, -3.1343e-01,  8.5831e-06],
        [ 9.9638e-02, -2.7622e-01,  1.3292e-05],
        [ 9.9466e-02, -2.1300e-01,  2.5839e-05],
        [ 9.9682e-02, -3.2759e-01,  7.9572e-06],
        [ 9.9121e-02, -2.4981e-01,  7.1943e-05],
        [ 9.8237e-02, -1.1185e-02,  1.1451e-03],
        [ 9.7773e-02,  9.0932e-02,  1.4658e-03],
        [ 9.4113e-02,  2.1226e-01,  4.8434e-03],
        [ 9.3801e-02,  1.5239e-01,  6.6420e-03],
        [ 8.8201e-02,  7.8380e-02,  1.7030e-02],
        [ 9.3344e-02, -7.5425e-02,  9.1800e-03],
        [ 8.9434e-02,  3.6531e-02,  2.8710e-02],
        [ 9.9567e-02, -3.6578e-01,  2.2650e-05],
        [ 9.7742e-02, -2.4778e-01,  6.9019e-04],
        [ 9.5043e-02, -1.8178e-02,  4.2832e-03],
        [ 9.4843e-02, -1.7018e-01,  4.6900e-03],
        [ 9.7343e-02, -1.7787e-01,  1.0451e-03],
        [ 9.8283e-02, -2.0011e-01,  5.7310e-04],
        [ 9.7358e-02, -1.7657e-01,  1.4116e-03],
        [ 9.8600e-02, -2.0107e-01,  3.7095e-04],
        [ 9.8146e-02, -1.4185e-01,  8.5545e-04],
        [ 9.9519e-02, -3.1099e-01,  8.5622e-05],
        [ 9.9579e-02, -3.7480e-01,  9.3073e-05],
        [ 9.7948e-02, -6.3778e-02,  8.1441e-04],
        [ 9.8023e-02, -1.0514e-01,  6.1911e-04],
        [ 9.5184e-02,  1.3190e-01,  1.4278e-03],
        [ 9.5991e-02,  2.1951e-02,  1.4189e-03],
        [ 8.8714e-02,  2.0012e-02,  1.4785e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 72
Episode Length = 77
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1289,  1.1283,  1.1176,  1.1185,  1.1184, -4.0000,  0.0000,  0.0000,
         0.1267,  1.1361,  1.1307,  1.1332,  1.1312,  1.1180, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1335,  1.1268,  1.1255, -4.0000,  0.0000,  0.0000,
         0.1524,  1.1314,  1.1414,  1.1444,  1.1386,  1.1385,  1.1445, -8.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q_episode tensor([ 1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,
         0.0000,  0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,
         0.0000, -0.5826, -1.6659, -2.8062, -4.0065, -5.2700, -6.6000, -8.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
target_q tensor([ 1.1289,  1.1283,  1.1176,  1.1185,  1.1184, -4.0000,  0.0000,  0.0000,
         0.1267,  1.1361,  1.1307,  1.1332,  1.1312,  1.1180, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1335,  1.1268,  1.1255, -4.0000,  0.0000,  0.0000,
         0.1524,  1.1314,  1.1414,  1.1444,  1.1386,  1.1385,  1.1445, -8.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.6079e-02, -1.2030e-02,  8.2740e-04],
        [ 9.5634e-02, -2.1003e-02,  8.8423e-04],
        [ 9.6850e-02, -5.7006e-02,  5.5394e-04],
        [ 9.8539e-02, -6.2006e-02,  1.4514e-04],
        [ 9.9118e-02, -1.0060e-01,  4.9233e-05],
        [ 9.8383e-02, -5.9352e-02,  1.6055e-04],
        [ 9.9345e-02, -1.0574e-01,  2.7359e-05],
        [ 9.9285e-02, -4.9221e-02,  3.3021e-05],
        [ 9.8783e-02,  1.4383e-02,  8.9049e-05],
        [ 9.8745e-02, -2.2398e-02,  9.9212e-05],
        [ 9.7566e-02,  2.7759e-02,  3.4136e-04],
        [ 9.9001e-02, -2.4883e-02,  5.2333e-05],
        [ 9.8020e-02, -3.7440e-03,  1.8141e-04],
        [ 9.8897e-02, -2.0639e-02,  6.6400e-05],
        [ 9.9027e-02, -4.8764e-02,  4.9412e-05],
        [ 9.8911e-02, -3.4222e-02,  7.8380e-05],
        [ 9.9202e-02, -4.7756e-02,  5.0902e-05],
        [ 9.9364e-02, -6.0705e-02,  3.3170e-05],
        [ 9.9405e-02, -1.2376e-01,  2.9564e-05],
        [ 9.9612e-02, -2.0566e-01,  1.7464e-05],
        [ 9.9744e-02, -2.4583e-01,  8.8811e-06],
        [ 9.9934e-02, -3.4794e-01,  9.8348e-07],
        [ 9.9959e-02, -3.6623e-01,  3.5763e-07],
        [ 9.9989e-02, -3.9040e-01,  2.9802e-08],
        [ 9.9998e-02, -3.9851e-01,  0.0000e+00],
        [ 9.9974e-02, -3.8957e-01,  8.9407e-08],
        [ 9.9990e-02, -3.9435e-01,  2.9802e-08],
        [ 9.9999e-02, -3.9988e-01,  0.0000e+00],
        [ 9.9958e-02, -3.8689e-01,  3.5763e-07],
        [ 9.9792e-02, -3.5450e-01,  5.9009e-06],
        [ 9.9903e-02, -3.7000e-01,  9.5367e-07],
        [ 9.8627e-02, -1.1948e-02,  1.1086e-04],
        [ 9.8338e-02,  7.7825e-02,  6.0341e-04],
        [ 9.4732e-02,  2.2223e-01,  2.2116e-03],
        [ 9.3170e-02,  2.1533e-01,  3.5237e-03],
        [ 7.9758e-02,  1.8771e-01,  4.5178e-02],
        [ 5.9601e-02,  1.5717e-01,  2.7517e-01],
        [ 1.5107e-02,  1.4296e-01,  8.9407e-01],
        [ 9.4982e-02, -4.8264e-02,  8.6260e-04],
        [ 9.7862e-02, -4.8440e-02,  2.4852e-04],
        [ 9.7982e-02, -6.4489e-02,  2.3106e-04],
        [ 9.7989e-02, -1.2883e-01,  2.9358e-04],
        [ 9.9314e-02, -1.8299e-01,  4.3750e-05],
        [ 9.9835e-02, -2.7313e-01,  2.2948e-06],
        [ 9.9802e-02, -2.7192e-01,  3.9935e-06],
        [ 9.9658e-02, -1.7481e-01,  9.9838e-06],
        [ 9.8979e-02,  9.1153e-02,  7.1734e-05],
        [ 9.9237e-02,  9.8729e-02,  4.2498e-05],
        [ 9.9057e-02,  1.1751e-01,  3.4273e-05],
        [ 9.8860e-02,  1.2099e-01,  5.5432e-05],
        [ 9.8122e-02,  3.0341e-02,  2.1559e-04],
        [ 9.8933e-02,  8.3664e-03,  6.7085e-05],
        [ 9.8341e-02,  1.8003e-02,  2.1020e-04],
        [ 9.8988e-02, -1.0965e-01,  1.2302e-04],
        [ 9.9615e-02, -2.8761e-01,  2.2560e-05],
        [ 9.9307e-02, -6.9721e-03,  4.8816e-05],
        [ 9.9765e-02, -2.4601e-01,  6.2883e-06],
        [ 9.9735e-02, -2.9674e-01,  1.0073e-05],
        [ 9.9781e-02, -3.0622e-01,  4.9174e-06],
        [ 9.9938e-02, -3.7666e-01,  7.1526e-07],
        [ 9.9334e-02,  4.4746e-02,  2.9594e-05],
        [ 9.9508e-02,  6.4283e-02,  2.2918e-05],
        [ 9.9974e-02, -3.9068e-01,  1.1921e-07],
        [ 9.9974e-02, -3.8244e-01,  2.0862e-07],
        [ 9.9454e-02, -1.6967e-01,  2.8729e-05],
        [ 9.9525e-02, -2.7889e-01,  2.9832e-05],
        [ 9.9772e-02, -2.9047e-01,  7.5996e-06],
        [ 9.9949e-02, -3.8947e-01,  5.9605e-07],
        [ 9.9969e-02, -3.9700e-01,  2.6822e-07],
        [ 9.9922e-02, -3.8738e-01,  2.2352e-06],
        [ 9.8337e-02, -1.4881e-01,  6.7589e-04],
        [ 9.9337e-02, -3.0227e-01,  6.8456e-05],
        [ 9.9576e-02, -3.1922e-01,  2.7031e-05],
        [ 9.9030e-02, -2.6187e-01,  1.0550e-04],
        [ 9.5890e-02,  3.8452e-02,  3.9075e-03],
        [ 9.4430e-02,  1.2393e-01,  8.2382e-03],
        [ 9.2224e-02,  1.4061e-01,  1.2830e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 73
Episode Length = 100
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1259,  1.1284,  1.1327,  1.1290, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1222,  1.1231,  1.1297,  1.1378, -4.0000,  0.0000,  0.0000,
         0.1152,  1.1283,  1.1382,  1.1340, -4.0000,  0.0000,  0.0000,  0.1517,
         1.1391,  1.1307,  1.1339,  1.1361,  1.1287, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1430,  1.1425,  1.1449,  1.1377,  1.1494,  1.1480, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1303,  1.1290,  1.1346,  1.1340,
         1.1282,  1.1291,  1.1390,  1.1370,  1.1356, -4.0000,  0.0000,  0.0000,
         0.1388,  1.0000], device='cuda:0')
target_q_episode tensor([-1.1772, -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,
         0.0000, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,
         0.6555, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000, -0.1183, -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.0779,  3.2399,  2.3578,
         1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,
         0.0000,  1.0000], device='cuda:0')
target_q tensor([ 1.1259,  1.1284,  1.1327,  1.1290, -6.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.1222,  1.1231,  1.1297,  1.1378, -4.0000,  0.0000,  0.0000,
         0.1152,  1.1283,  1.1382,  1.1339, -4.0000,  0.0000,  0.0000,  0.1517,
         1.1391,  1.1307,  1.1339,  1.1361,  1.1287, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1430,  1.1425,  1.1449,  1.1377,  1.1494,  1.1480, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1303,  1.1290,  1.1346,  1.1340,
         1.1282,  1.1291,  1.1390,  1.1370,  1.1356, -4.0000,  0.0000,  0.0000,
         0.1388,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 8.2320e-02, -2.0647e-02,  1.3545e-02],
        [ 8.4145e-02, -3.5173e-02,  9.7567e-03],
        [ 9.1420e-02, -5.4956e-02,  4.0715e-03],
        [ 9.1154e-02, -3.6068e-02,  3.7740e-03],
        [ 9.2609e-02, -5.2597e-02,  2.7438e-03],
        [ 9.4191e-02,  1.1723e-02,  1.2120e-03],
        [ 9.7662e-02,  8.4377e-03,  2.0829e-04],
        [ 9.6251e-02,  2.3700e-02,  7.6392e-04],
        [ 9.6706e-02,  5.3139e-02,  6.2734e-04],
        [ 9.5576e-02,  5.9774e-02,  1.0187e-03],
        [ 9.5497e-02,  7.4397e-02,  9.5597e-04],
        [ 9.5037e-02,  5.0366e-03,  1.2620e-03],
        [ 9.7656e-02, -4.8522e-02,  2.1204e-04],
        [ 9.6866e-02,  5.5077e-03,  3.4279e-04],
        [ 9.7132e-02, -1.6200e-02,  2.9874e-04],
        [ 9.7501e-02,  8.4019e-03,  1.9506e-04],
        [ 9.9390e-02, -1.0019e-01,  1.5885e-05],
        [ 9.9070e-02, -4.6373e-02,  3.5316e-05],
        [ 9.9637e-02, -7.9458e-02,  6.9141e-06],
        [ 9.9535e-02, -1.4931e-01,  1.4573e-05],
        [ 9.9523e-02, -7.1274e-02,  1.8716e-05],
        [ 9.9781e-02, -1.1708e-01,  4.4405e-06],
        [ 9.9747e-02, -1.3855e-01,  5.1856e-06],
        [ 9.9726e-02, -9.3417e-02,  4.9472e-06],
        [ 9.9752e-02, -8.2803e-02,  4.5896e-06],
        [ 9.9797e-02, -9.9535e-02,  3.6061e-06],
        [ 9.9490e-02, -2.0282e-02,  1.6659e-05],
        [ 9.9716e-02, -1.2955e-01,  6.7353e-06],
        [ 9.9484e-02, -3.5417e-02,  1.8477e-05],
        [ 9.9717e-02, -5.2642e-03,  9.3877e-06],
        [ 9.9651e-02, -4.2950e-02,  1.1414e-05],
        [ 9.9591e-02,  6.8744e-02,  1.3441e-05],
        [ 9.9759e-02, -5.6909e-02,  1.1265e-05],
        [ 9.9760e-02, -7.9879e-02,  9.7156e-06],
        [ 9.9730e-02, -1.4279e-02,  1.1235e-05],
        [ 9.9154e-02,  6.4329e-02,  1.3161e-04],
        [ 9.8635e-02,  6.4013e-02,  3.3805e-04],
        [ 9.7310e-02,  6.5203e-02,  1.6524e-03],
        [ 9.7948e-02, -6.9456e-03,  1.0696e-03],
        [ 9.2502e-02,  5.1042e-02,  1.1347e-02],
        [ 7.4668e-02,  1.3244e-01,  1.5958e-01],
        [ 4.4008e-02,  1.3064e-01,  5.9700e-01],
        [ 6.9717e-02, -3.5673e-03,  3.9324e-02],
        [ 6.5248e-02,  2.5822e-02,  5.1722e-02],
        [ 9.4367e-02, -4.9107e-02,  1.0713e-03],
        [ 9.6185e-02, -1.1791e-01,  6.8098e-04],
        [ 9.7251e-02, -4.3416e-02,  3.9709e-04],
        [ 9.0621e-02,  1.1205e-02,  3.7276e-03],
        [ 9.3402e-02,  3.4210e-02,  2.7975e-03],
        [ 9.8245e-02, -1.1112e-01,  3.0643e-04],
        [ 9.7133e-02, -7.6495e-02,  5.5268e-04],
        [ 9.7537e-02, -4.7830e-02,  5.4637e-04],
        [ 9.9408e-02, -9.2696e-02,  5.1111e-05],
        [ 9.7918e-02,  8.5254e-03,  3.2291e-04],
        [ 9.8827e-02, -5.9527e-02,  1.7154e-04],
        [ 9.7168e-02,  2.5794e-02,  5.2723e-04],
        [ 9.5302e-02,  1.0831e-01,  8.0466e-04],
        [ 9.1459e-02,  1.5489e-01,  2.4758e-03],
        [ 9.7700e-02,  6.9463e-02,  5.8830e-04],
        [ 9.9509e-02, -3.3968e-01,  1.7613e-05],
        [ 9.9997e-02, -3.9995e-01,  0.0000e+00],
        [ 9.9995e-02, -3.9988e-01,  0.0000e+00],
        [ 9.9992e-02, -3.9843e-01,  2.9802e-08],
        [ 9.9995e-02, -3.9954e-01,  0.0000e+00],
        [ 9.9998e-02, -3.9980e-01,  0.0000e+00],
        [ 9.9997e-02, -3.9984e-01,  0.0000e+00],
        [ 9.9989e-02, -3.9850e-01,  2.9802e-08],
        [ 9.9974e-02, -3.9776e-01,  8.9407e-08],
        [ 9.9841e-02, -3.8800e-01,  3.6061e-06],
        [ 9.9881e-02, -3.8661e-01,  1.7881e-06],
        [ 9.9831e-02, -3.5488e-01,  4.4405e-06],
        [ 9.9836e-02, -3.4941e-01,  4.7982e-06],
        [ 9.9939e-02, -3.9112e-01,  6.2585e-07],
        [ 9.9898e-02, -3.6658e-01,  5.3644e-06],
        [ 9.9651e-02, -2.5878e-02,  9.3579e-06],
        [ 9.7554e-02,  2.3714e-01,  7.8765e-04],
        [ 9.6240e-02,  1.4235e-01,  5.8476e-03],
        [ 9.2993e-02,  8.8658e-02,  1.4103e-02],
        [ 8.6902e-02,  1.0621e-01,  4.6339e-02],
        [ 8.4193e-02,  3.2658e-02,  7.9501e-02],
        [ 8.6045e-02,  3.2631e-02,  6.9672e-02],
        [ 9.4619e-02, -7.8025e-02,  2.2615e-02],
        [ 9.5125e-02, -2.1664e-01,  8.2296e-03],
        [ 9.4647e-02, -1.4437e-01,  7.3771e-03],
        [ 9.0863e-02, -6.5645e-02,  3.5611e-02],
        [ 8.7113e-02,  1.0564e-01,  4.9679e-02],
        [ 8.9893e-02,  5.2862e-02,  2.3628e-02],
        [ 9.2636e-02,  1.4050e-01,  9.9640e-03],
        [ 8.6520e-02,  1.1526e-01,  3.8009e-02],
        [ 9.1801e-02,  3.7876e-03,  1.4934e-02],
        [ 9.7433e-02, -4.2604e-02,  1.0922e-03],
        [ 9.7708e-02, -5.7739e-02,  6.2981e-04],
        [ 9.6264e-02, -3.4604e-02,  3.1855e-03],
        [ 9.7092e-02, -1.1351e-01,  1.8698e-03],
        [ 9.4381e-02,  4.2095e-02,  3.8695e-03],
        [ 9.3188e-02, -3.1061e-03,  5.6251e-03],
        [ 9.6170e-02, -8.4049e-02,  2.3167e-03],
        [ 9.8840e-02, -1.0733e-01,  5.4702e-04],
        [ 8.7950e-02,  9.7153e-02,  4.3513e-02],
        [ 8.9993e-02, -1.6272e-04,  2.6621e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 74
Episode Length = 93
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([  1.1229,   1.1277,   1.1230,   1.1315,   1.1250, -10.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.1398,   1.1250,   1.1281,   1.1315,   1.1243,   1.1262,   1.1292,
          1.1366,   1.1402,   1.1281,   1.1287,   1.1318,   1.1255,  -4.0000,
          0.0000,   0.0000,   0.1328,   1.1327,   1.1440,   1.1414,   1.1349,
          1.1417,   1.1411,   1.1401,  -4.0000,   0.0000,   0.0000,   0.1362,
          1.1396,   1.1538,   1.1375,   1.1403,   1.1342,   1.1341,   1.1396,
         -6.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
       device='cuda:0')
target_q_episode tensor([ -3.2134,  -4.4352,  -5.7213,  -7.0750,  -8.5000, -10.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.0000,   7.0314,   6.3488,   5.6303,   4.8740,   4.0779,   3.2399,
          2.3578,   1.4293,   0.4518,  -0.5770,  -1.6600,  -2.8000,  -4.0000,
          0.0000,   0.0000,   0.0000,   3.2399,   2.3578,   1.4293,   0.4519,
         -0.5770,  -1.6600,  -2.8000,  -4.0000,   0.0000,   0.0000,   0.0000,
          1.8432,   0.8876,  -0.1183,  -1.1772,  -2.2917,  -3.4650,  -4.7000,
         -6.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
       device='cuda:0')
target_q tensor([  1.1229,   1.1277,   1.1230,   1.1315,   1.1250, -10.0000,   0.0000,
          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
          0.1398,   1.1250,   1.1281,   1.1315,   1.1243,   1.1262,   1.1292,
          1.1366,   1.1402,   1.1281,   1.1287,   1.1318,   1.1255,  -4.0000,
          0.0000,   0.0000,   0.1328,   1.1327,   1.1440,   1.1414,   1.1349,
          1.1417,   1.1411,   1.1401,  -4.0000,   0.0000,   0.0000,   0.1362,
          1.1396,   1.1538,   1.1375,   1.1402,   1.1342,   1.1341,   1.1396,
         -6.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],
       device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.7434e-02, -4.5463e-02,  3.8156e-04],
        [ 9.6863e-02, -2.1948e-02,  5.1960e-04],
        [ 9.8261e-02, -5.6723e-02,  1.8531e-04],
        [ 9.8223e-02, -4.2419e-02,  1.7744e-04],
        [ 9.9336e-02, -8.6088e-02,  2.8312e-05],
        [ 9.9566e-02, -1.1912e-01,  1.3053e-05],
        [ 9.9543e-02, -1.1663e-01,  1.8328e-05],
        [ 9.9694e-02, -9.5438e-02,  8.7023e-06],
        [ 9.9115e-02, -5.4322e-03,  5.9456e-05],
        [ 9.9722e-02, -1.1194e-01,  5.6922e-06],
        [ 9.9597e-02, -4.9031e-02,  1.0908e-05],
        [ 9.9314e-02,  1.5878e-04,  2.5362e-05],
        [ 9.9037e-02, -3.0696e-03,  4.6462e-05],
        [ 9.9401e-02, -6.5818e-02,  2.2352e-05],
        [ 9.9305e-02, -3.8192e-02,  2.4676e-05],
        [ 9.9640e-02, -8.3194e-02,  7.8082e-06],
        [ 9.9761e-02, -1.6469e-01,  6.3479e-06],
        [ 9.9785e-02, -1.3541e-01,  4.7982e-06],
        [ 9.9831e-02, -2.5021e-01,  3.4571e-06],
        [ 9.9938e-02, -3.0004e-01,  6.8545e-07],
        [ 9.9960e-02, -3.5304e-01,  2.6822e-07],
        [ 9.9971e-02, -3.7568e-01,  1.7881e-07],
        [ 9.9995e-02, -3.9671e-01,  0.0000e+00],
        [ 9.9997e-02, -3.9906e-01,  0.0000e+00],
        [ 9.9998e-02, -3.9921e-01,  0.0000e+00],
        [ 9.9996e-02, -3.9925e-01,  0.0000e+00],
        [ 9.9997e-02, -3.9917e-01,  0.0000e+00],
        [ 9.9999e-02, -3.9997e-01,  0.0000e+00],
        [ 9.9999e-02, -3.9996e-01,  0.0000e+00],
        [ 9.9971e-02, -3.9808e-01,  2.3842e-07],
        [ 9.9947e-02, -3.7890e-01,  4.1723e-07],
        [ 9.9668e-02, -3.0365e-01,  8.8811e-06],
        [ 9.9527e-02, -1.8962e-01,  6.8247e-05],
        [ 9.8359e-02,  1.2039e-01,  3.1736e-04],
        [ 9.4748e-02,  1.6369e-01,  3.1535e-03],
        [ 8.6393e-02,  1.1801e-01,  2.5641e-02],
        [ 7.4847e-02,  1.3836e-01,  1.3470e-01],
        [ 7.8397e-03,  1.4134e-01,  9.4862e-01],
        [ 9.7721e-02, -4.8721e-02,  3.0491e-04],
        [ 9.8374e-02, -7.8138e-02,  1.5503e-04],
        [ 9.9329e-02, -1.2924e-01,  4.2915e-05],
        [ 9.8893e-02, -1.7030e-02,  7.0274e-05],
        [ 9.8175e-02, -3.7187e-02,  2.1034e-04],
        [ 9.7982e-02, -1.0550e-02,  1.8936e-04],
        [ 9.8188e-02, -7.4786e-03,  1.4657e-04],
        [ 9.9355e-02, -1.9978e-01,  3.1829e-05],
        [ 9.7101e-02, -6.9763e-02,  4.4250e-04],
        [ 9.9527e-02, -1.5879e-01,  2.9653e-05],
        [ 9.3158e-02,  2.8020e-02,  2.5365e-03],
        [ 9.5796e-02,  8.1447e-02,  1.0943e-03],
        [ 9.1936e-02,  4.9797e-02,  3.4199e-03],
        [ 9.3033e-02,  4.2559e-02,  2.7429e-03],
        [ 8.7353e-02,  4.2742e-02,  9.1769e-03],
        [ 9.7624e-02, -1.7929e-01,  4.8706e-04],
        [ 9.9301e-02, -1.4483e-01,  5.8144e-05],
        [ 9.9499e-02, -2.0486e-01,  3.3200e-05],
        [ 9.9389e-02, -2.0536e-01,  5.0902e-05],
        [ 9.9831e-02, -1.5917e-01,  4.3511e-06],
        [ 9.9899e-02, -2.9538e-01,  1.6689e-06],
        [ 9.9938e-02, -3.1811e-01,  7.4506e-07],
        [ 9.9749e-02, -2.5433e-01,  1.0699e-05],
        [ 9.9701e-02, -3.6091e-02,  1.0014e-05],
        [ 9.9928e-02, -2.7059e-01,  8.3447e-07],
        [ 9.9905e-02, -2.3916e-01,  1.1921e-06],
        [ 9.9763e-02, -1.1418e-01,  7.4506e-06],
        [ 9.9976e-02, -3.6631e-01,  1.7881e-07],
        [ 9.9866e-02, -2.9865e-01,  2.0862e-06],
        [ 9.9963e-02, -3.9101e-01,  1.4901e-07],
        [ 9.9985e-02, -3.9564e-01,  1.4901e-07],
        [ 9.9967e-02, -3.9551e-01,  3.2783e-07],
        [ 9.9950e-02, -3.9231e-01,  8.0466e-07],
        [ 9.9930e-02, -3.9534e-01,  1.5497e-06],
        [ 9.9340e-02, -3.5455e-01,  1.0720e-04],
        [ 9.9705e-02, -3.7697e-01,  2.3931e-05],
        [ 9.9732e-02, -3.7557e-01,  2.4766e-05],
        [ 9.9649e-02, -3.7039e-01,  3.8058e-05],
        [ 9.9881e-02, -3.9551e-01,  3.3677e-06],
        [ 9.9626e-02, -3.7795e-01,  3.0339e-05],
        [ 9.9783e-02, -3.6803e-01,  1.0133e-05],
        [ 9.8876e-02, -2.4165e-01,  2.8178e-04],
        [ 9.9836e-02, -3.2531e-01,  8.4937e-06],
        [ 9.8617e-02, -4.0513e-02,  4.9463e-04],
        [ 9.4833e-02,  1.7237e-01,  4.1637e-03],
        [ 8.3683e-02,  1.7825e-01,  6.2304e-02],
        [ 7.7664e-02,  1.8075e-01,  1.1425e-01],
        [ 7.1622e-02,  1.0192e-01,  2.1607e-01],
        [ 6.0853e-02,  8.6954e-02,  4.0214e-01],
        [ 7.4152e-02,  4.0054e-02,  2.1596e-01],
        [ 7.3578e-02,  4.6211e-02,  2.1211e-01],
        [ 6.2007e-02,  7.5244e-02,  3.5705e-01],
        [ 7.5504e-02,  2.2871e-02,  2.7086e-01],
        [ 8.3820e-02,  6.1144e-03,  1.2913e-01],
        [ 8.8007e-02, -2.9283e-02,  6.5711e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 75
Episode Length = 96
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1237,  1.1273,  1.1166,  1.1224,  1.1215,  1.1249,  1.1217, -4.0000,
         0.0000,  0.0000,  0.1245,  1.1164,  1.1249,  1.1235,  1.1207, -4.0000,
         0.0000,  0.0000,  0.1271,  1.1262,  1.1189,  1.1196,  1.1277,  1.1315,
         1.1239,  1.1272, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1491,
         1.1259, -5.0000,  0.0000,  0.0000,  0.0000,  0.1512,  1.1180,  1.1206,
         1.1278,  1.1228, -5.0000,  0.0000,  0.0000,  0.0000,  0.1270,  1.1220,
         1.1320,  1.1205, -4.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([ 3.2399,  2.3578,  1.4293,  0.4518, -0.5770, -1.6600, -2.8000, -4.0000,
         0.0000,  0.0000,  0.0000,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,
         0.0000,  0.0000,  0.0000,  1.8432,  0.8876, -0.1183, -1.1772, -2.2917,
        -3.4650, -4.7000, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3627, -1.4344,
        -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.5770,
        -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1237,  1.1273,  1.1166,  1.1224,  1.1215,  1.1249,  1.1217, -4.0000,
         0.0000,  0.0000,  0.1245,  1.1164,  1.1249,  1.1235,  1.1207, -4.0000,
         0.0000,  0.0000,  0.1271,  1.1262,  1.1189,  1.1196,  1.1277,  1.1315,
         1.1239,  1.1272, -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1491,
         1.1259, -5.0000,  0.0000,  0.0000,  0.0000,  0.1512,  1.1180,  1.1206,
         1.1278,  1.1228, -5.0000,  0.0000,  0.0000,  0.0000,  0.1270,  1.1220,
         1.1320,  1.1205, -4.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.6712e-02, -1.0423e-01,  1.0453e-03],
        [ 9.4824e-02, -9.2799e-03,  1.6894e-03],
        [ 9.5886e-02, -1.8601e-02,  1.2892e-03],
        [ 9.4479e-02,  3.5194e-02,  1.9155e-03],
        [ 9.6846e-02,  4.1757e-02,  6.5941e-04],
        [ 9.8084e-02, -3.9978e-02,  2.8712e-04],
        [ 9.7136e-02,  7.7316e-02,  6.1572e-04],
        [ 9.8013e-02, -1.5286e-02,  2.7111e-04],
        [ 9.8559e-02, -3.2337e-02,  1.2350e-04],
        [ 9.5441e-02,  7.6162e-02,  6.6489e-04],
        [ 9.7337e-02,  2.2921e-02,  3.2365e-04],
        [ 9.7791e-02,  2.4835e-02,  1.7011e-04],
        [ 9.7889e-02,  7.5651e-03,  1.6052e-04],
        [ 9.7962e-02,  8.6908e-03,  1.3706e-04],
        [ 9.8334e-02,  1.9594e-02,  1.0949e-04],
        [ 9.9198e-02, -2.8544e-02,  2.5123e-05],
        [ 9.9294e-02, -1.5180e-02,  2.3782e-05],
        [ 9.9041e-02, -1.6030e-02,  3.8832e-05],
        [ 9.9398e-02, -8.7311e-02,  2.4110e-05],
        [ 9.9487e-02, -4.8285e-02,  1.5229e-05],
        [ 9.9482e-02, -5.5161e-02,  1.2606e-05],
        [ 9.9877e-02, -2.1330e-01,  1.1027e-06],
        [ 9.7615e-02,  3.6358e-02,  2.6411e-04],
        [ 9.7545e-02, -2.5045e-02,  6.1679e-04],
        [ 9.9080e-02, -2.1513e-01,  6.2227e-05],
        [ 9.9668e-02, -2.8764e-01,  1.0610e-05],
        [ 9.9953e-02, -3.9843e-01,  1.1921e-07],
        [ 9.9972e-02, -3.9692e-01,  2.3842e-07],
        [ 9.9934e-02, -3.8731e-01,  1.6391e-06],
        [ 9.9976e-02, -3.9782e-01,  2.3842e-07],
        [ 9.9240e-02,  3.7156e-02,  4.0144e-05],
        [ 9.8214e-02,  8.4572e-02,  1.8558e-04],
        [ 9.7857e-02,  1.2572e-01,  4.2507e-04],
        [ 9.9985e-02, -3.9605e-01,  1.7881e-07],
        [ 9.8886e-02, -2.7561e-01,  4.0177e-04],
        [ 9.9964e-02, -3.8677e-01,  7.7486e-07],
        [ 9.9660e-02, -1.9006e-01,  4.4346e-05],
        [ 9.8800e-02,  8.5211e-02,  5.0414e-04],
        [ 9.6628e-02,  1.2529e-01,  1.4000e-03],
        [ 9.5365e-02,  7.7321e-02,  2.8063e-03],
        [ 9.2732e-02, -3.0106e-02,  1.0416e-02],
        [ 2.8887e-02,  1.3247e-01,  8.3468e-01],
        [ 7.5134e-02,  1.3787e-03,  2.4930e-02],
        [ 7.7961e-02,  2.3104e-02,  2.1317e-02],
        [ 9.7852e-02, -1.0642e-01,  2.9391e-04],
        [ 9.4513e-02,  2.5034e-02,  2.0985e-03],
        [ 9.9298e-02, -2.3991e-01,  6.9618e-05],
        [ 9.9137e-02, -1.3585e-01,  8.5086e-05],
        [ 9.8647e-02, -1.0161e-01,  1.7267e-04],
        [ 9.5658e-02,  2.0038e-02,  1.0091e-03],
        [ 9.9640e-02, -2.9329e-01,  1.9431e-05],
        [ 9.9314e-02, -1.6372e-01,  5.2452e-05],
        [ 9.7880e-02,  8.0816e-02,  2.9603e-04],
        [ 9.7923e-02,  4.2812e-03,  1.6937e-04],
        [ 9.5682e-02,  1.1916e-01,  5.7054e-04],
        [ 9.7900e-02,  4.3797e-02,  2.5678e-04],
        [ 9.7275e-02,  5.0120e-02,  4.1050e-04],
        [ 9.7599e-02, -1.3597e-02,  4.7684e-04],
        [ 9.7173e-02,  1.1349e-02,  7.5054e-04],
        [ 9.9032e-02, -8.1204e-02,  7.8857e-05],
        [ 9.7438e-02,  3.1909e-03,  4.0010e-04],
        [ 9.5679e-02,  8.1213e-02,  1.1386e-03],
        [ 9.3988e-02,  6.9881e-02,  3.0269e-03],
        [ 9.5207e-02,  6.2268e-02,  1.1114e-03],
        [ 9.9378e-02, -1.0743e-01,  1.7822e-05],
        [ 9.8644e-02, -8.0190e-02,  1.3921e-04],
        [ 9.9432e-02, -1.5213e-01,  3.5703e-05],
        [ 9.9132e-02, -4.3226e-02,  6.7711e-05],
        [ 9.9209e-02, -8.2078e-02,  5.7369e-05],
        [ 9.8659e-02, -4.3607e-02,  1.2979e-04],
        [ 9.9562e-02, -1.2038e-01,  1.7434e-05],
        [ 9.7438e-02,  4.7755e-03,  3.8198e-04],
        [ 9.7681e-02, -2.6374e-02,  5.9146e-04],
        [ 9.4781e-02, -7.7657e-02,  1.9718e-03],
        [ 9.9145e-02, -3.3353e-01,  6.3926e-05],
        [ 9.9824e-02, -3.9143e-01,  2.7716e-06],
        [ 9.9825e-02, -3.9168e-01,  2.7120e-06],
        [ 9.9957e-02, -3.9796e-01,  2.3842e-07],
        [ 9.9955e-02, -3.9643e-01,  1.0431e-06],
        [ 9.9997e-02, -3.9994e-01,  0.0000e+00],
        [ 9.9964e-02, -3.9431e-01,  6.2585e-07],
        [ 9.9408e-02, -1.3077e-01,  2.7061e-05],
        [ 9.9568e-02, -8.0711e-02,  4.2379e-05],
        [ 9.9440e-02, -2.4221e-01,  4.8459e-05],
        [ 9.9248e-02, -1.0375e-01,  8.3864e-05],
        [ 9.8204e-02, -4.3836e-02,  4.8059e-04],
        [ 9.7132e-02, -1.2920e-02,  9.5704e-04],
        [ 9.8913e-02, -1.3916e-01,  2.4176e-04],
        [ 9.6634e-02,  2.9707e-02,  2.8963e-03],
        [ 9.6084e-02, -5.5592e-02,  1.8111e-03],
        [ 9.5819e-02, -4.8119e-02,  2.1369e-03],
        [ 9.7329e-02, -1.1283e-01,  1.8831e-03],
        [ 9.5148e-02, -7.6613e-02,  5.1155e-03],
        [ 9.5753e-02, -2.2625e-02,  3.8609e-03],
        [ 9.3481e-02, -8.6625e-03,  8.7565e-03],
        [ 8.7550e-02,  3.1103e-02,  6.7092e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 76
Episode Length = 90
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1301,  1.1210,  1.1278, -4.0000,  0.0000,  0.0000,  0.1179,  1.1243,
         1.1277,  1.1270, -5.0000,  0.0000,  0.0000,  0.0000,  0.1196,  1.1237,
         1.1364, -5.0000,  0.0000,  0.0000,  0.0000,  0.1171,  1.1206,  1.1305,
         1.1368,  1.1405,  1.1344, -5.0000,  0.0000,  0.0000,  0.0000,  0.1137,
         1.1259,  1.1277,  1.1344,  1.1352,  1.1327,  1.1339, -4.0000,  0.0000,
         0.0000,  0.1474,  1.1271,  1.1284,  1.1324,  1.1365, -6.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([-0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000, -1.4344,
        -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -2.5625,
        -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6555, -0.3627,
        -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         2.3578,  1.4293,  0.4519, -0.5770, -1.6600, -2.8000, -4.0000,  0.0000,
         0.0000,  0.0000, -1.1772, -2.2917, -3.4650, -4.7000, -6.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1301,  1.1210,  1.1278, -4.0000,  0.0000,  0.0000,  0.1179,  1.1243,
         1.1277,  1.1270, -5.0000,  0.0000,  0.0000,  0.0000,  0.1196,  1.1237,
         1.1364, -5.0000,  0.0000,  0.0000,  0.0000,  0.1171,  1.1206,  1.1305,
         1.1368,  1.1405,  1.1344, -5.0000,  0.0000,  0.0000,  0.0000,  0.1137,
         1.1259,  1.1277,  1.1344,  1.1352,  1.1327,  1.1339, -4.0000,  0.0000,
         0.0000,  0.1474,  1.1271,  1.1284,  1.1324,  1.1365, -6.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.6815e-02, -4.1151e-02,  5.7968e-04],
        [ 9.6765e-02, -2.7333e-02,  5.0774e-04],
        [ 9.7993e-02, -4.8714e-02,  2.1654e-04],
        [ 9.9062e-02, -6.7886e-02,  7.3582e-05],
        [ 9.8924e-02, -7.7752e-02,  6.8247e-05],
        [ 9.9708e-02, -8.7947e-02,  7.9274e-06],
        [ 9.9533e-02, -1.3180e-01,  1.7762e-05],
        [ 9.9517e-02, -1.1595e-01,  1.8775e-05],
        [ 9.9059e-02, -2.3861e-02,  5.2810e-05],
        [ 9.8941e-02, -3.1686e-02,  6.8545e-05],
        [ 9.9662e-02, -5.3422e-02,  8.1360e-06],
        [ 9.9043e-02,  7.9276e-03,  4.5627e-05],
        [ 9.9266e-02, -5.4337e-02,  3.4660e-05],
        [ 9.9440e-02, -4.8138e-02,  1.8299e-05],
        [ 9.9664e-02, -1.4585e-01,  7.6890e-06],
        [ 9.9474e-02, -1.0212e-01,  1.8984e-05],
        [ 9.9570e-02, -1.3439e-01,  1.2666e-05],
        [ 9.9843e-02, -2.3297e-01,  2.5928e-06],
        [ 9.9847e-02, -2.4505e-01,  2.1458e-06],
        [ 9.9933e-02, -3.4810e-01,  8.3447e-07],
        [ 9.9951e-02, -3.4382e-01,  4.4703e-07],
        [ 9.9974e-02, -3.8605e-01,  1.4901e-07],
        [ 9.9990e-02, -3.9503e-01,  2.9802e-08],
        [ 9.9980e-02, -3.9133e-01,  5.9605e-08],
        [ 9.9999e-02, -3.9988e-01,  0.0000e+00],
        [ 9.9999e-02, -3.9981e-01,  0.0000e+00],
        [ 9.9999e-02, -3.9990e-01,  0.0000e+00],
        [ 9.9999e-02, -3.9993e-01,  0.0000e+00],
        [ 9.9997e-02, -3.9986e-01,  0.0000e+00],
        [ 9.9968e-02, -3.9820e-01,  2.6822e-07],
        [ 9.9941e-02, -3.9125e-01,  4.1723e-07],
        [ 9.9666e-02, -2.7019e-01,  7.3910e-06],
        [ 9.9583e-02, -2.5681e-01,  5.9634e-05],
        [ 9.8375e-02,  6.7465e-02,  2.9585e-04],
        [ 9.6798e-02,  9.8642e-02,  1.0732e-03],
        [ 9.2221e-02,  6.8837e-02,  7.8407e-03],
        [ 8.4826e-02,  8.5947e-02,  3.7088e-02],
        [ 4.7100e-02,  8.3810e-02,  7.7815e-01],
        [ 9.8258e-02, -1.0234e-01,  2.1613e-04],
        [ 9.8640e-02, -8.3786e-02,  1.1927e-04],
        [ 9.8040e-02, -9.4544e-03,  1.9246e-04],
        [ 9.6567e-02, -3.1248e-02,  5.4145e-04],
        [ 9.6061e-02, -7.5010e-02,  7.0173e-04],
        [ 9.7804e-02, -2.5090e-02,  2.3785e-04],
        [ 9.9050e-02, -2.5389e-02,  4.5627e-05],
        [ 9.9579e-02, -2.2251e-01,  1.7822e-05],
        [ 9.9672e-02, -1.7694e-01,  1.6481e-05],
        [ 9.9724e-02, -7.4406e-02,  5.5134e-06],
        [ 9.9106e-02, -1.6825e-03,  3.4750e-05],
        [ 9.9104e-02, -1.2966e-01,  3.6478e-05],
        [ 9.9721e-02, -2.5178e-01,  5.3048e-06],
        [ 9.9062e-02,  4.5562e-02,  3.7104e-05],
        [ 9.9283e-02, -1.9313e-02,  3.9816e-05],
        [ 9.9450e-02, -1.5535e-01,  3.6031e-05],
        [ 9.9254e-02,  6.9987e-03,  5.0813e-05],
        [ 9.9377e-02, -7.8908e-02,  3.6180e-05],
        [ 9.9584e-02, -1.9226e-01,  1.5020e-05],
        [ 9.9764e-02, -2.8376e-01,  4.6790e-06],
        [ 9.9686e-02, -9.4760e-02,  6.7651e-06],
        [ 9.9719e-02, -2.3243e-01,  1.2547e-05],
        [ 9.9851e-02, -2.9478e-01,  4.0233e-06],
        [ 9.9883e-02, -2.9790e-01,  2.5034e-06],
        [ 9.9893e-02, -3.0101e-01,  2.8014e-06],
        [ 9.9843e-02, -2.0125e-01,  3.8743e-06],
        [ 9.9891e-02, -3.0103e-01,  1.1325e-06],
        [ 9.9997e-02, -3.9965e-01,  0.0000e+00],
        [ 9.9996e-02, -3.9955e-01,  0.0000e+00],
        [ 9.9940e-02, -3.9288e-01,  8.0466e-07],
        [ 9.9998e-02, -3.9993e-01,  0.0000e+00],
        [ 9.9993e-02, -3.9786e-01,  0.0000e+00],
        [ 9.9976e-02, -3.8953e-01,  1.4901e-07],
        [ 9.9353e-02, -3.0479e-01,  6.9112e-05],
        [ 9.9037e-02, -2.5807e-01,  1.2159e-04],
        [ 9.9984e-02, -3.9892e-01,  5.9605e-08],
        [ 9.9985e-02, -3.9888e-01,  2.9802e-08],
        [ 9.9999e-02, -3.9999e-01,  0.0000e+00],
        [ 9.9999e-02, -3.9999e-01,  0.0000e+00],
        [ 1.0000e-01, -4.0000e-01,  0.0000e+00],
        [ 9.9997e-02, -3.9992e-01,  0.0000e+00],
        [ 9.9987e-02, -3.9937e-01,  2.3842e-07],
        [ 9.9833e-02, -3.9173e-01,  5.8711e-06],
        [ 9.9422e-02, -3.4005e-01,  1.0946e-04],
        [ 9.9717e-02, -3.6521e-01,  3.2127e-05],
        [ 9.9226e-02, -2.9304e-01,  1.2931e-04],
        [ 9.9760e-02, -3.6923e-01,  3.2246e-05],
        [ 9.8356e-02, -1.5517e-01,  1.1863e-03],
        [ 9.7548e-02,  2.8165e-02,  2.1137e-03],
        [ 9.2799e-02,  4.4426e-02,  1.2272e-02],
        [ 8.5481e-02,  8.9493e-02,  4.9769e-02],
        [ 8.9283e-02,  4.6891e-03,  4.9785e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Run No. 77
Episode Length = 100
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1153,  1.1184,  1.1144, -4.0000,  0.0000,  0.0000,  0.1251,  1.1187,
         1.1188,  1.1139,  1.1172,  1.1251, -5.0000,  0.0000,  0.0000,  0.0000,
         0.1236,  1.1210,  1.1256,  1.1304,  1.1267, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1201,  1.1213,  1.1257,  1.1195,  1.1209,  1.1192,  1.1193,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1224,  1.1196,
         1.1173,  1.1152,  1.1296, -8.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1180,  1.1217,  1.1197,  1.1216, -3.0000,  0.0000,
         0.1200,  1.0000], device='cuda:0')
target_q_episode tensor([-0.5770, -1.6600, -2.8000, -4.0000,  0.0000,  0.0000,  0.0000,  0.6555,
        -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,  0.0000,
         0.0000, -0.3627, -1.4344, -2.5625, -3.7500, -5.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1525, -0.8921, -1.9917, -3.1491, -4.3675, -5.6500,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -2.8062,
        -4.0065, -5.2700, -6.6000, -8.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.2804, -0.7575, -1.8500, -3.0000,  0.0000,
         0.0000,  1.0000], device='cuda:0')
target_q tensor([ 1.1153,  1.1184,  1.1144, -4.0000,  0.0000,  0.0000,  0.1251,  1.1187,
         1.1188,  1.1139,  1.1172,  1.1251, -5.0000,  0.0000,  0.0000,  0.0000,
         0.1236,  1.1210,  1.1256,  1.1304,  1.1267, -5.0000,  0.0000,  0.0000,
         0.0000,  0.1201,  1.1213,  1.1257,  1.1195,  1.1209,  1.1192,  1.1193,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1224,  1.1196,
         1.1173,  1.1152,  1.1296, -8.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.1180,  1.1217,  1.1197,  1.1216, -3.0000,  0.0000,
         0.1200,  1.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.5285e-02, -4.9498e-02,  1.0993e-03],
        [ 9.5981e-02, -4.2587e-02,  7.4664e-04],
        [ 9.7338e-02, -7.2532e-02,  3.6377e-04],
        [ 9.6686e-02, -9.6775e-02,  5.6496e-04],
        [ 9.8258e-02, -1.1547e-01,  1.9079e-04],
        [ 9.8460e-02, -3.4559e-02,  8.7619e-05],
        [ 9.9125e-02, -3.3913e-02,  4.0770e-05],
        [ 9.9188e-02, -1.3106e-01,  5.5999e-05],
        [ 9.9311e-02, -6.6178e-02,  4.8399e-05],
        [ 9.9108e-02, -2.0423e-02,  6.6876e-05],
        [ 9.9503e-02, -8.7631e-02,  2.4974e-05],
        [ 9.9549e-02, -1.2890e-01,  1.8269e-05],
        [ 9.9866e-02, -2.0679e-01,  1.4603e-06],
        [ 9.9571e-02, -1.0144e-01,  1.0163e-05],
        [ 9.9635e-02, -7.8475e-02,  6.8247e-06],
        [ 9.9851e-02, -1.7637e-01,  1.4007e-06],
        [ 9.9852e-02, -1.2070e-01,  9.5367e-07],
        [ 9.9849e-02, -1.6441e-01,  1.6987e-06],
        [ 9.9908e-02, -2.1057e-01,  6.5565e-07],
        [ 9.9878e-02, -1.3655e-01,  1.0431e-06],
        [ 9.9923e-02, -1.9962e-01,  6.8545e-07],
        [ 9.9879e-02, -1.2013e-01,  1.4305e-06],
        [ 9.9941e-02, -2.1877e-01,  3.5763e-07],
        [ 9.9940e-02, -2.2323e-01,  4.1723e-07],
        [ 9.9884e-02, -1.6157e-01,  1.4603e-06],
        [ 9.9934e-02, -1.8613e-01,  5.3644e-07],
        [ 9.9881e-02, -1.6467e-01,  1.9372e-06],
        [ 9.9928e-02, -2.0753e-01,  7.7486e-07],
        [ 9.9864e-02, -1.2441e-01,  2.3544e-06],
        [ 9.9943e-02, -1.7862e-01,  5.9605e-07],
        [ 9.9859e-02, -8.7220e-02,  2.4140e-06],
        [ 9.9835e-02, -4.9363e-02,  3.7849e-06],
        [ 9.9767e-02, -5.6824e-02,  9.6858e-06],
        [ 9.9901e-02, -1.6738e-01,  2.5332e-06],
        [ 9.9883e-02, -1.6258e-01,  5.8711e-06],
        [ 9.9484e-02, -9.2008e-02,  6.9916e-05],
        [ 9.9608e-02, -7.5705e-02,  5.6922e-05],
        [ 9.9166e-02, -2.2133e-02,  1.9413e-04],
        [ 9.9282e-02, -4.6841e-02,  1.7616e-04],
        [ 9.5363e-02,  2.5347e-02,  5.8934e-03],
        [ 9.0220e-02,  3.7986e-02,  2.8350e-02],
        [ 4.4575e-02,  7.3972e-02,  7.1174e-01],
        [ 9.7463e-02, -1.2015e-01,  4.2236e-04],
        [ 9.9501e-02, -2.5910e-01,  2.6286e-05],
        [ 9.8342e-02, -7.7960e-02,  2.0647e-04],
        [ 9.9354e-02, -2.1303e-01,  5.6058e-05],
        [ 9.9259e-02, -2.1084e-01,  7.9900e-05],
        [ 9.9916e-02, -3.6191e-01,  2.2054e-06],
        [ 9.8781e-02, -5.5556e-02,  9.7871e-05],
        [ 9.8578e-02,  3.7015e-03,  1.0213e-04],
        [ 9.8945e-02, -1.2473e-01,  5.6118e-05],
        [ 9.8414e-02, -1.9510e-02,  1.2121e-04],
        [ 9.8048e-02, -2.5672e-02,  2.2233e-04],
        [ 9.8207e-02, -3.4499e-02,  1.7652e-04],
        [ 9.9126e-02, -6.0553e-02,  6.1363e-05],
        [ 9.8934e-02, -1.4106e-01,  9.7305e-05],
        [ 9.8639e-02, -6.3563e-02,  9.4801e-05],
        [ 9.9438e-02, -1.5999e-01,  2.3097e-05],
        [ 9.8810e-02, -8.4655e-02,  1.0931e-04],
        [ 9.9235e-02, -9.6592e-02,  5.6028e-05],
        [ 9.8201e-02, -3.0476e-02,  2.2095e-04],
        [ 9.8840e-02, -8.4699e-02,  1.0169e-04],
        [ 9.9333e-02, -1.7487e-01,  4.5240e-05],
        [ 9.7065e-02,  5.0572e-02,  9.3585e-04],
        [ 9.6909e-02,  1.1126e-02,  8.6656e-04],
        [ 9.7612e-02,  8.6095e-02,  3.0372e-04],
        [ 9.9702e-02, -2.8144e-01,  1.1683e-05],
        [ 9.9804e-02, -3.3504e-01,  1.1593e-05],
        [ 9.9232e-02, -1.4552e-01,  1.2445e-04],
        [ 9.9584e-02, -2.7813e-01,  3.8803e-05],
        [ 9.9605e-02, -2.4927e-01,  2.5004e-05],
        [ 9.9544e-02, -4.5666e-02,  1.7494e-05],
        [ 9.9661e-02, -8.0358e-02,  8.8215e-06],
        [ 9.9304e-02, -1.5795e-01,  4.8518e-05],
        [ 9.9523e-02, -1.3728e-01,  4.2289e-05],
        [ 9.9321e-02, -2.4042e-01,  1.2332e-04],
        [ 9.9825e-02, -3.5576e-01,  1.4037e-05],
        [ 9.9259e-02, -2.1196e-01,  2.4110e-04],
        [ 9.9811e-02, -3.3723e-01,  1.4782e-05],
        [ 9.9533e-02, -2.2650e-01,  3.6806e-05],
        [ 9.8909e-02, -1.6911e-02,  1.0312e-04],
        [ 9.7959e-02, -1.8001e-03,  3.5954e-04],
        [ 9.6314e-02,  4.9760e-02,  1.7101e-03],
        [ 9.6538e-02, -5.0549e-02,  1.6756e-03],
        [ 9.8824e-02, -9.7809e-02,  1.2431e-04],
        [ 9.9803e-02, -2.4597e-01,  4.1127e-06],
        [ 9.9690e-02, -2.2752e-01,  1.4007e-05],
        [ 9.9886e-02, -2.7714e-01,  2.1756e-06],
        [ 9.9807e-02, -2.3135e-01,  5.3048e-06],
        [ 9.9644e-02, -1.4795e-01,  2.3574e-05],
        [ 9.9836e-02, -1.9431e-01,  4.4405e-06],
        [ 9.9772e-02, -1.5604e-01,  1.1265e-05],
        [ 9.9943e-02, -2.5576e-01,  7.7486e-07],
        [ 9.9780e-02, -2.4712e-01,  1.0490e-05],
        [ 9.9714e-02, -2.3250e-01,  1.8060e-05],
        [ 9.9853e-02, -2.7194e-01,  4.6194e-06],
        [ 9.9864e-02, -2.7829e-01,  4.5598e-06],
        [ 9.9831e-02, -2.6195e-01,  6.8843e-06],
        [ 9.9789e-02, -2.5240e-01,  1.5855e-05],
        [ 9.9712e-02, -2.8360e-01,  3.5107e-05]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 11. Optimize actor
# 12. Update target networks
Run No. 78
Episode Length = 99
# 1. Compute target actions from target actor P'(s(t+1))
# 2. Compute Q-value of next state using the  target critics Q'(s(t+1), P'(s(t+1)))
# 3. Use smaller Q-value as the Q-value target
# 4. Compute current Q-value with the reward
target_q_critic tensor([ 1.1226, -4.0000,  0.0000,  0.0000,  0.1125,  1.1147,  1.1192,  1.1223,
        -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1133,  1.1091,  1.1109,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1175, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1186,  1.1176, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1191,  1.1153,  1.1154,  1.1221, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1386,  1.1193,  1.1161,  1.1188,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1383,  1.1181,  1.1230, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q_episode tensor([-2.8000, -4.0000,  0.0000,  0.0000,  0.0000, -2.2917, -3.4650, -4.7000,
        -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -4.3675, -5.6500,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -3.7500, -5.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -3.1491, -4.3675, -5.6500, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.4344, -2.5625, -3.7500,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.0000, -3.4650, -4.7000, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
target_q tensor([ 1.1226, -4.0000,  0.0000,  0.0000,  0.1125,  1.1147,  1.1192,  1.1223,
        -6.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1133,  1.1091,  1.1109,
        -7.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1175, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1186,  1.1176, -5.0000,  0.0000,
         0.0000,  0.0000,  0.1191,  1.1153,  1.1154,  1.1221, -7.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1386,  1.1193,  1.1161,  1.1188,
        -5.0000,  0.0000,  0.0000,  0.0000,  0.1383,  1.1181,  1.1230, -6.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')
# 5.1 Compute Q-value from critics Q(s_t, a_t)
# 6.1 Compute MSE loss for the critics
# 7.1 Optimize critic
# 5.2 Compute Q-value from critics Q(s_t, a_t)
# 6.2 Compute MSE loss for the critics
# 7.2 Optimize critic
# 8. Compute actor actions
actor actions tensor([[ 9.5516e-02,  1.8586e-02,  1.0459e-03],
        [ 9.6440e-02,  1.8353e-02,  7.0062e-04],
        [ 9.7626e-02, -1.8200e-02,  3.5170e-04],
        [ 9.9326e-02, -5.6494e-02,  3.4362e-05],
        [ 9.9247e-02, -1.5600e-02,  4.5717e-05],
        [ 9.8621e-02, -4.4371e-03,  1.0568e-04],
        [ 9.9158e-02, -4.5974e-02,  4.9949e-05],
        [ 9.9131e-02, -2.0406e-02,  6.0439e-05],
        [ 9.9522e-02, -6.7157e-02,  2.2501e-05],
        [ 9.9027e-02,  1.5352e-02,  6.4075e-05],
        [ 9.8796e-02,  4.2430e-02,  7.5638e-05],
        [ 9.9506e-02,  5.0389e-02,  1.8388e-05],
        [ 9.9224e-02,  3.1659e-02,  3.3081e-05],
        [ 9.9487e-02, -4.9253e-02,  1.8179e-05],
        [ 9.9451e-02, -4.8955e-02,  2.0534e-05],
        [ 9.9694e-02, -6.9968e-02,  8.6427e-06],
        [ 9.9728e-02, -1.0139e-01,  7.5996e-06],
        [ 9.9546e-02, -1.0296e-01,  1.8954e-05],
        [ 9.9895e-02, -3.0071e-01,  1.5199e-06],
        [ 9.9821e-02, -2.6580e-01,  4.9174e-06],
        [ 9.9935e-02, -3.4183e-01,  1.0133e-06],
        [ 9.9983e-02, -3.9010e-01,  5.9605e-08],
        [ 9.9991e-02, -3.9648e-01,  2.9802e-08],
        [ 9.9988e-02, -3.9252e-01,  2.9802e-08],
        [ 1.0000e-01, -3.9995e-01,  0.0000e+00],
        [ 1.0000e-01, -3.9998e-01,  0.0000e+00],
        [ 9.9999e-02, -3.9982e-01,  0.0000e+00],
        [ 1.0000e-01, -4.0000e-01,  0.0000e+00],
        [ 9.9995e-02, -3.9981e-01,  0.0000e+00],
        [ 9.9993e-02, -3.9968e-01,  2.9802e-08],
        [ 9.9972e-02, -3.9415e-01,  1.1921e-07],
        [ 9.9385e-02, -2.2152e-01,  3.9041e-05],
        [ 9.9525e-02, -2.8715e-01,  8.9288e-05],
        [ 9.8202e-02,  1.7190e-02,  4.4054e-04],
        [ 9.7517e-02,  6.2398e-02,  1.0393e-03],
        [ 9.2745e-02,  3.9923e-02,  8.3351e-03],
        [ 8.6144e-02,  8.6391e-02,  3.2042e-02],
        [ 5.7869e-02,  9.0479e-02,  6.6644e-01],
        [ 9.7580e-02, -2.4778e-02,  4.0677e-04],
        [ 9.6748e-02, -1.4263e-02,  6.0320e-04],
        [ 9.6193e-02,  2.6415e-02,  6.1586e-04],
        [ 9.6704e-02,  5.2226e-02,  6.7613e-04],
        [ 9.8697e-02, -1.5386e-02,  1.2967e-04],
        [ 9.9515e-02, -1.3466e-01,  2.9743e-05],
        [ 9.9311e-02, -1.6546e-01,  4.3750e-05],
        [ 9.9663e-02, -1.4987e-01,  1.3351e-05],
        [ 9.9232e-02,  2.2276e-02,  3.7253e-05],
        [ 9.8642e-02,  1.1903e-01,  8.8930e-05],
        [ 9.9326e-02,  3.2306e-02,  3.0220e-05],
        [ 9.9153e-02,  8.0831e-03,  4.9502e-05],
        [ 9.8977e-02,  1.4253e-02,  8.7827e-05],
        [ 9.8172e-02,  9.0266e-02,  2.0301e-04],
        [ 9.9357e-02, -1.2419e-01,  6.4462e-05],
        [ 9.9330e-02, -1.6219e-01,  5.2154e-05],
        [ 9.9516e-02, -1.7136e-01,  2.6822e-05],
        [ 9.9752e-02, -2.4227e-01,  1.1653e-05],
        [ 9.9178e-02, -2.8708e-02,  7.5102e-05],
        [ 9.9692e-02, -5.5305e-03,  7.6890e-06],
        [ 9.9303e-02,  8.4581e-02,  3.1799e-05],
        [ 9.9333e-02,  1.3570e-01,  2.9832e-05],
        [ 9.9438e-02,  1.0172e-01,  2.9415e-05],
        [ 9.9466e-02, -1.1014e-01,  4.1574e-05],
        [ 9.9583e-02, -1.0992e-01,  1.6868e-05],
        [ 9.9448e-02, -1.1565e-01,  5.0843e-05],
        [ 9.9454e-02, -1.0831e-01,  4.1455e-05],
        [ 9.9709e-02, -7.1154e-02,  1.4067e-05],
        [ 9.9770e-02, -1.7446e-01,  7.8976e-06],
        [ 9.9819e-02, -2.4219e-01,  5.1558e-06],
        [ 9.9902e-02, -3.2977e-01,  1.8477e-06],
        [ 9.9502e-02, -1.6621e-01,  3.6538e-05],
        [ 9.9886e-02, -3.1577e-01,  4.0829e-06],
        [ 9.9585e-02, -2.5538e-01,  3.1978e-05],
        [ 9.9687e-02, -1.7187e-01,  1.9282e-05],
        [ 9.9956e-02, -3.6284e-01,  5.6624e-07],
        [ 9.9967e-02, -3.9286e-01,  2.9802e-07],
        [ 9.9948e-02, -3.8655e-01,  1.1027e-06],
        [ 9.9553e-02, -2.8719e-01,  4.6104e-05],
        [ 9.9990e-02, -3.9873e-01,  5.9605e-08],
        [ 9.9994e-02, -3.9949e-01,  2.9802e-08],
        [ 9.9982e-02, -3.9777e-01,  8.9407e-08],
        [ 9.9995e-02, -3.9975e-01,  0.0000e+00],
        [ 1.0000e-01, -4.0000e-01,  0.0000e+00],
        [ 9.9999e-02, -3.9999e-01,  0.0000e+00],
        [ 1.0000e-01, -4.0000e-01,  0.0000e+00],
        [ 9.9987e-02, -3.9964e-01,  1.1921e-07],
        [ 9.9993e-02, -3.9980e-01,  5.9605e-08],
        [ 9.9997e-02, -3.9994e-01,  0.0000e+00],
        [ 9.9983e-02, -3.9925e-01,  2.0862e-07],
        [ 9.9992e-02, -3.9986e-01,  2.9802e-08],
        [ 9.9987e-02, -3.9972e-01,  1.1921e-07],
        [ 9.9932e-02, -3.8914e-01,  2.2650e-06],
        [ 9.9461e-02, -3.4432e-01,  7.9274e-05],
        [ 9.9378e-02, -2.5391e-01,  1.4830e-04],
        [ 9.9062e-02, -2.5876e-01,  5.9226e-04],
        [ 9.6904e-02, -5.6124e-02,  5.4156e-03],
        [ 9.7911e-02, -2.8714e-02,  1.8274e-03],
        [ 9.7451e-02, -3.9513e-03,  2.2230e-03],
        [ 9.4512e-02,  3.3363e-04,  3.0188e-02],
        [ 9.3098e-02,  1.7011e-03,  2.9902e-02]], device='cuda:0',
       grad_fn=<AddBackward0>)
# 9. Compute actor loss
# 10. Compute the negative critic values using the real critic
# 11. Optimize actor
# 12. Update target networks
Saving checkpoint
Saving model
Max epochs reached
KeyboardInterrupt
[1m---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[1mKeyboardInterrupt
>>> >>>